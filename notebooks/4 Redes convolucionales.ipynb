{"cells":[{"cell_type":"markdown","metadata":{"id":"qoNnOpojCrxR"},"source":["# Módulo 4. Redes convolucionales\n","\n","¡Bienvenidos al cuarto módulo! Tras haber visto en el módulo anterior las diferentes implementaciones de Gradient Descent, las funciones de activación y de pérdidas y la inicialización de pesos, comenzamos hoy con las redes neuronales convolucionales, ¡el buque insignia del deep learning!\n","\n","Como se puede observar del módulo de anterior, el perceptrón multicapa utilizado permite resolver con satisfacción la tarea de clasificación propuesta. Sin embargo, en la mayoría de problemas de clasificación de imagen, no es suficiente con crear un modelo de predicción basado en un perceptron multicapa. Para problemas de cierta dificultad, este tipo de arquitectura no ofrece una solución precisa. Por este motivo se propusieron las **redes neuronales convolucionales**. Dichas arquitecturas de red **extraen la información relevante automáticamente** de la imagen por medio de la operación convolución de manera local (en la práctica dicha operación es la correlación cruzada). \n","\n","El índice que seguiremos hoy será el siguiente:\n","\n","1. **Introducción a las redes neuronales convolucionales**\n","\n","2. **Concepto de convolución**\n","\n","3. **Redes neuronales convolucionales y principales capas**\n","\n","4. **Efecto modificación de capas: GlobalMaxPoling y GlobalMeanPoling frente Flatten**\n","\n","5. **Overfitting: Técnicas de regularización y Dropout**"]},{"cell_type":"markdown","metadata":{"id":"bUx4EViyC_Hg"},"source":["## 1. Introducción a las Redes Neuronales Convolucionales\n","\n","En las sesiones anteriores, hemos visto que una red neuronal es basicamente un aproximador de funciones universal, ¿lo recordáis? Lo que quiere decir es que en esencia, lo que hacemos con las redes neuronales es solucionar problemas tratando de encontrar la mejor aproximación posible a una función que permite solucionar nuestro problema.\n","\n","Para ello, disponemos de una serie de parámetros (los pesos y la bias) que vamos actualizando haciendo uso del algoritmo de backpropagation, que está basado en el gradient descent. \n","\n","Gracias a nuestras etiquetas, somos capaces de calcular el error en cada iteración y modificar los pesos para reducirlo progresivamente.\n","\n","Vale, genial. ¿Y qué es una red neuronal **convolucional**? O lo que es más importante, **¿qué problemas permite solucionar?**\n","\n","Pues básicamente, **todos los que se puedan expresar en forma de imagen**.\n","\n","\n","Por ejemplo, supongo que la mayoría de vosotros tendréis FaceBook o lo conoceréis, os habéis fijado en que cuando vais a etiquetar a alguien os sugiere personas? Y que normalmente, acierta => **convnets al poder!**\n","\n","<img src=\"https://image.ibb.co/kROQSd/fb_label_face.png\" alt=\"fb_label_face\" border=\"0\" height=\"350\">\n","\n","O los que tengáis un iPhone (no sé si con Android será igual), habéis visto la carpeta \"Personas\" dentro de la galería? WTF!!! cómo hacen eso? son capaces de encontrar la cara en una imagen, y no contentos con eso, también son capaces de agrupar todas las caras que pertenecen a una determinada persona!! Pues, ¿sabéis qué?? => **convnets al poder!**\n","\n","<img src=\"https://image.ibb.co/dOY3DJ/ip_face_recog.png\" alt=\"ip_face_recog\" border=\"0\" height=\"350\">\n","\n","O quizás hayáis oído hablar de los coches autónomos, que son capaces de \"leer\" las señales de tráfico, incluso detectar si hay una persona cruzando la calle. ¿A que no lo adivináis? => **convnets al poder!**\n","\n","<img src=\"https://image.ibb.co/e9cify/self_driving_cars_detection.jpg\" alt=\"self_driving_cars_detection\" border=\"0\" height=\"350\">\n","\n","Y estos, son solo algunos ejemplos con los que tratáis día a día, pero existen muchos más. Por ejemplo, yo estoy trabajando en detección de cáncer en imágenes de histopatológicas.\n","\n","De hecho, las *CNN* están muy de moda para resolver problemas de imagen médica. Esto se debe a una característica que tienen las CNNs y que las hacen perfectas para este cometido (y otros muchos). Esta característica es que son capaces, por sí solas, de encontrar las características adecuadas para posteriormente clasificar las imágenes correctamente.\n","\n","Cualquiera de vosotros que le guste un poco el tema y haya mirado sabrá que dentro del ámbito de la visión por computador el deep learning ha supuesto un antes y un después, y si no os lo creéis, mirad esta imagen:\n","\n","<img src=\"https://image.ibb.co/k48yfy/imagenet_cv_vs_dl.jpg\" alt=\"imagenet_cv_vs_dl\" border=\"0\">\n","\n","Vale, estupendo. Pero **¿qué es exactamente una CNN**?\n","\n","Pues es una red neuronal en la que se introducen nuevos tipos de capas, donde la más importante es **la convolucional**.\n","\n","**Y, ¿qué es la convolución?**\n","\n","¡¡Vamos a verlo!!"]},{"cell_type":"markdown","metadata":{"id":"PSuIxxEdVfXF"},"source":["## 2. La convolución\n","\n","Estrictamente, la convolución se utiliza sobretodo en tratamiento de señal, y es una operación matemática que permite combinar dos señales. En tratamiento digital de la señal, se emplea para conocer qué le va a pasar a una señal después de \"pasar\" por un determinado dispositivo. Por ejemplo, para saber cómo cambia nuestra voz tras haber pasado por el micrófono de nuestro móvil, podríamos calcular la convolucion de nuestra voz con la respuesta al impulso del micrófono.\n","\n","Si sentís curiosidad, aquí tenéis un muy buen recurso: http://includeblogh.blogspot.com.es/2010/12/convolucion-pero-si-es-muy-facil-parte.html\n","\n","Fuera de lo estrictamente técnico, las redes neuronales convolucionales se han hecho *famosas* gracias a su capacidad para detectar patrones que después clasifican. Pues bien, esos **detectores de patrones son las convoluciones**.\n","\n","Vamos a ver cómo entiende un ordenador una imagen:\n","\n","<img src=\"https://image.ibb.co/eXT60y/img_rep.png\" alt=\"img_rep\" border=\"0\" width=\"400\">\n","<img src=\"https://image.ibb.co/dG5m0y/img_rep_2.png\" alt=\"img_rep_2\" border=\"0\" width=\"600\">\n","\n","Como podéis ver, una imagen en color se representa como una matriz de 3 dimensiones: **Ancho** x **Alto** x **Canales**. Existen varias formas de representar las imágenes, pero la más común es usando el espacio de colores RGB. Estgo quiere decir que un ordenador al final ve 3 matrices de Ancho x Alto, donde la primera le indica las cantidades de rojo que tiene la imagen, la segunda, de verde, y la tercera, de azul.\n","\n","Si la imagen fuese en escala de grises, el ordenador la vería como una sola matriz bidimensional de Ancho x Alto.\n","\n","Por último, los valores que pueden tomar los elementos de la matriz dependen del tipo de variable utilizada. Las más comunes son:\n","\n","* si usamos enteros de 8 bits: pueden ir de 0 a 255\n","* si usamos floats: de 0 a 1\n","\n","Me interesa que entendáis muy bien esto, así que si hay alguna duda podéis decirmelo ahora o al acabar la clase, pero no os quedéis con ella!\n","\n","\n","Pues bien, sabiendo que la imagen es una matriz, lo que hace la convolución es definir un **filtro** o **kernel** por el que va a multiplicar a la matriz de la imagen. Fijaos en la siguiente imagen:\n","\n","<img src=\"https://image.ibb.co/czOQSd/convolution_kernel.png\" alt=\"convolution_kernel\" border=\"0\">\n","\n","Se define un kernel, de 3x3 pixels, y se multiplica a la input_image. ¿Qué es lo que pasa? Que el kernel es mucho más pequeño que la imagen, por lo que para poder multiplicar a toda la imagen, primero situamos el kernel sobre los primeros 3x3 pixels, luego lo movemos uno hacia la derecha, luego otro, luego otro... y vamos calculando **la suma de la multiplicación de cada elemento del kernel por cada pixel correspondiente de la imagen**. El resultado de esta operación se almacena en la imagen de salida, como podéis observar.\n","\n","Aquí podéis verlo más claro:\n","\n","<img src=\"https://image.ibb.co/e0GSqy/convolution.png\" alt=\"convolution\" border=\"0\">\n","\n","Y ahora con un ejemplo animado para que veáis el proceso:\n","\n","<img src=\"https://image.ibb.co/eqGy0y/cnn_stride1.gif\" alt=\"cnn_stride1\" border=\"0\">\n","\n","<!--\n","Y por último, un ejemplo con una imagen en color, es decir, que tiene 3 canales, R, G y B, con lo cual, tiene 3 matrices bidimensionales, una para cada canal. En este caso, como podéis ver, la convolución se aplica a cada canal por separado y así se obtiene como resultado una matriz de 3 dimensiones, con el resultado de la convolución para cada canal.\n","\n","**En el caso de las capas convolucionales, los resultados de los diferentes canales se suman**, además de la bias, con lo que el resultado es una imagen de un solo canal (una matriz bidimensional):\n","\n","<img src=\"https://image.ibb.co/bHU4Ly/convolution_rgb.gif\" alt=\"convolution_rgb\" border=\"0\">\n","\n","En este enlace podéis verlo más en detalle: http://cs231n.github.io/assets/conv-demo/index.html\n","-->\n","\n","Vale, ya sabéis la teoría, pero os he dicho que son detectores de patrones y de momento con esto no estamos detectando nada, simplemente multiplicando y sumando cosas, ¿no?\n","\n","Vamos a ver unos ejemplos a ver qué es lo que pasa cuando hacemos estas mutiplicaciones y sumas ;-)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wJUmDnCnfxuY"},"outputs":[],"source":["# Hacemos los imports necesarios\n","import numpy as np\n","from scipy import signal\n","from scipy import misc\n","ascent = ## Code ##\n","kernel = ## Code ##\n","grad = ## Code ##"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0WTOyBPUgjQB"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# función para mostrar dos imágenes juntas\n","def plot_two(img_orig, img_conv):\n","  fig, (ax_orig, ax_mag) = plt.subplots(1, 2, figsize=(20, 50))\n","  ax_orig.imshow(img_orig, cmap='gray')\n","  ax_orig.set_title('Original')\n","  ax_orig.set_axis_off()\n","  ax_mag.imshow((img_conv), cmap='gray')\n","  ax_mag.set_title('Gradiente')\n","  ax_mag.set_axis_off()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tj7L1R5Ijcw_"},"outputs":[],"source":["plot_two(ascent, grad)"]},{"cell_type":"markdown","metadata":{"id":"pxCbsX3kheqe"},"source":["¿Cómo lo véis? Parece que estamos detectando algunos bordes, ¿verdad? Y qué son los bordes, sino líneas? Vaya! Parece que tenemos un detector de líneas verticales!! ;-)\n","\n","¿Cómo podríamos conseguir uno de líneas horizontales?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ol-RuXzrh6CR"},"outputs":[],"source":["kernel = ## Code ##\n","grad_v = ## Code ##\n","plot_two(ascent, grad_v)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KTS-A-Xx5jE6"},"outputs":[],"source":["kernel = ## Code ##\n","grad_v = ## Code ##\n","plot_two(ascent, grad_v)"]},{"cell_type":"markdown","metadata":{"id":"UPKGRpwY1mq8"},"source":["**Estos son algunos de los kernels más utilizados en CV tradicional:**\n","\n","<img src=\"https://image.ibb.co/jcgw0y/kernels.png\" alt=\"kernels\" border=\"0\">\n","\n","Vamos a ver los ejemplos nosotros mismos:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9NZabZeW7YGW"},"outputs":[],"source":["# Cargamos y mostramos la imagen original\n","url_img = 'https://upload.wikimedia.org/wikipedia/commons/5/50/Vd-Orig.png'\n","from urllib.request import urlopen \n","from io import BytesIO\n","from PIL import Image\n","file = ## Code ##\n","img = ## Code ##\n","plt.imshow(img)\n","plt.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-lCvEyox9yt3"},"outputs":[],"source":["def convolve3d(img, kernel):\n","  img_out = np.zeros(img.shape)\n","  for i in range(img.shape[-1]):\n","     img_out[:,:,i] = ## Code ##\n","  return img_out.astype('uint8')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XlrpDp2p8Y9k"},"outputs":[],"source":["# Probamos con el kernel identidad\n","kernel = ## Code ##\n","img_ki = convolve3d(img, kernel)\n","plot_two(img, img_ki)"]},{"cell_type":"markdown","metadata":{"id":"Ve3b2obUkff2"},"source":["Más ejemplos: http://aishack.in/tutorials/image-convolution-examples/"]},{"cell_type":"markdown","metadata":{"id":"1gbCyeztHD3g"},"source":["Vale, muy guays estas transformaciones, pero...\n","\n","## ¿Cómo es capaz la convolución de detectar un determinado patrón?\n","\n","<!-- https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/ -->\n","\n","### Ejemplo detección patrones\n","\n","**Nuestro filtro:**\n","\n","<img src=\"https://image.ibb.co/iMo97d/conv_patt_det_1.png\" alt=\"conv_patt_det_1\" border=\"0\">\n","\n","**Nuestra imagen:**\n","\n","<img src=\"https://image.ibb.co/jNkYYJ/conv_patt_det_2.png\" alt=\"conv_patt_det_2\" border=\"0\">\n","\n","**¿Qué pasa si nuestro filtro cae en la \"espalda\" de la rata?**\n","\n","<img src=\"https://image.ibb.co/nugJ0y/conv_patt_det_3.png\" alt=\"conv_patt_det_3\" border=\"0\">\n","\n","$Resultado = 30·0 + 30·50 + 30·20 + 30·50 + 30·50 + 30·50=6600$ es un número muy alto!!\n","\n","**¿Qué pasa si nuestro filtro cae en la \"cabeza\" de la rata?**\n","\n","<img src=\"https://image.ibb.co/hmp5fy/conv_patt_det_4.png\" alt=\"conv_patt_det_4\" border=\"0\">\n","\n","$Resultado = 30·0 + 30·0 + 30·0 + 30·0 + 30·0 + 30·0=0$ es un número muy bajo!! ¡No existe respuesta para este receptive field!\n","\n","\n","### Así es como la convolución es capaz de detectar patrones."]},{"cell_type":"markdown","metadata":{"id":"kaU6gWFuVkJ2"},"source":["## 3. Redes neuronales convolucionales y principales capas\n","\n","Ahora que ya sabéis lo que es la convolución, vamos a ver qué son las redes neuronales convolucionales y cómo funcionan.\n","\n","<img src=\"https://image.ibb.co/kXj0cd/cnn_feat_class.jpg\" alt=\"cnn_feat_class\" border=\"0\">\n","<img src=\"https://image.ibb.co/fKGU7d/cnn_intro.png\" alt=\"cnn_intro\" border=\"0\">\n","\n","En estas imagenes podéis ver la **arquitectura típica de una red neuronal convolucional**.\n","\n","Como entrada, tenemos la imagen que queremos clasificar, en este caso, de nuestro gato negro. Como ya sabéis, esto no es otra cosa que una matriz de Ancho x Alto x 3 (porque es RGB). \n","\n","Después, empiezan los \"bloques convolucionales\". Estos bloques están compuestos normalmente por:\n","\n","* Capas **convolucionales**, que ya hemos visto como funcionan\n","* Capas de **pooling**, que lo que hacen es *diezmar* el contenido de la salida de la capa convolucional\n","\n","Antes hemos visto como funciona la convolución: definimos un kernel o filtro que sirve para resaltar determinadas estructuras de la imagen. Y os estaréis preguntando: ¿cómo defino yo un filtro que me permita averiguar qué la imagen de entrada tiene un gato negro?\n","\n","Pues aquí está la **magia** de las CNNs!! Nosotros **no tenemos que definir ningún filtro, los aprende la red automáticamente gracias al backpopagation!!**\n","\n","Por otra parte, ¿os dáis cuenta de que nuestra **CNN tiene dos etapas**: **feature extractor** y **classifier**? Esto se debe a que la red, primero extrae unos determinados patrones haciendo uso de la primera etapa (base model), que son los que mejor le vienen al posterior clasificador (top model) para hacer su trabajo con la mayor precisión posible.\n","\n","La etapa de **feature extraction** va de menos a más, es decir, las primeras capas convolucionales detectan lineas en diferentes orientaciones, las siguientes detectan ya formas y colores, las siguientes patrones más complejos, etc. Fijaos en estas imágenes:\n","\n","<img src=\"https://image.ibb.co/dz5DFy/vis_cnn_layer2.png\" alt=\"vis_cnn_layer2\" border=\"0\" height=\"300\">\n","\n","<img src=\"https://image.ibb.co/kQ4UoJ/vis_cnn_layer3.png\" alt=\"vis_cnn_layer3\" border=\"0\" height=\"300\">\n","\n","<img src=\"https://image.ibb.co/n69Jhd/vis_cnn_layer4.png\" alt=\"vis_cnn_layer4\" border=\"0\">\n","\n","\n","**Así que al final, lo que tenemos, es una red que aprende sola, con la que no hace falta que nos preocupemos de qué características escogemos para clasificar, ya que las elige ella sola.**\n","\n","¿Y cómo va aprendiendo? De la misma forma que una red neuronal tradicional.\n","\n","<img src=\"https://image.ibb.co/fYyhqy/cnn_learning.png\" alt=\"cnn_learning\" border=\"0\">\n","\n","De hecho, la segunda etapa, la de clasificador, está compuesta por capas **densas**, que si recordáis lo que dijimos anteriormente, son las capas que se usan en las redes neuronales tradicionales. Por lo que finalmente podría entenderse una CNN como un conjunto de etapas convolucionales acopladas a una red neuronal tradicional, que es la que clasifica los patrones extraídos por las convoluciones y devuelve unas probabilidades para cada clase."]},{"cell_type":"markdown","metadata":{"id":"RWkzDDUOSZpA"},"source":["A continuación, vamos a estudiar los tipos de capas más comunes en una CNN:\n","\n","\n","\n","*   **Convoluciones**\n","\n","\n","\n","\n","Estas capas son las encargadas de aplicar la convolución a nuestras imágenes de entrada para encontrar los patrones que más tarde permitirán clasificarla.\n","\n","Para ello, se define:\n","\n","1.   El número de filtros/kernels a aplicar a la imagen: el número de   matrices por las que se van a convolucionar las imágenes de entrada\n","2.   El tamaño de estos filtros: 99% de las veces son cuadrados, de 3x3, 5x5, etc.\n","\n","Aquí podéis ver el esquema general, en el que se ve como una imagen de entrada dada se convoluciona por cada filtro, y la salida son mapas de activación 2D. Esto quiere decir que si la imagen de entrada es RGB, tendrá 3 canales. Por lo tanto, convolucionaremos cada filtro por cada canal, y luego sumaremos los resultados, para reducir de 3 canales a 1 solo.\n","\n","<img src=\"https://image.ibb.co/bXBQTJ/conv_layer_1.png\" alt=\"conv_layer_1\" border=\"0\">\n","\n","En este demo podéis ver lo que os acabo de explicar:\n","\n","<img src=\"https://image.ibb.co/bHU4Ly/convolution_rgb.gif\" alt=\"convolution_rgb\" border=\"0\">\n","\n","Como la entrada tiene 3 canales, R, G y B, esto significa que nuestra imagen de entrada viene definida como 3 matrices bidimensionales, una para cada canal. Así que lo que hace la capa convolucional es aplicar la convolución por separado a cada canal, obtiene el resultado de cada canal, y luego los suma para obtener una única matriz 2D que es llamada mapa de activaciones.\n","\n","En este enlace podéis verlo más en detalle: http://cs231n.github.io/assets/conv-demo/index.html\n","\n","Ahora imaginaos que nuestra capa tiene 4 filtros:\n","\n","<img src=\"https://image.ibb.co/nb0DYJ/conv_layer_2.png\" alt=\"conv_layer_2\" border=\"0\">\n","\n","Además del número de filtros y el tamaño, las capas convolucionales tiene otro parámetro importante: **el stride**.\n","\n","Fijaos en el cambio:\n","\n","<img src=\"https://image.ibb.co/eqGy0y/cnn_stride1.gif\" alt=\"cnn_stride1\" border=\"0\" height=\"250\">\n","<img src=\"https://image.ibb.co/cXL2Sd/cnn_stride2.gif\" alt=\"cnn_stride2\" border=\"0\" height=\"250\">\n","\n","Por último, es **importante** que conozcáis el concepto de **receptive field**.\n","\n","<img src=\"https://image.ibb.co/cAYgnd/recept_field.jpg\" alt=\"recept_field\" border=\"0\">\n","<img src=\"https://image.ibb.co/cFsfDJ/receptive_field.png\" alt=\"receptive_field\" border=\"0\">\n","\n","En el caso de las capas convolucionales, las neuronas de la salida se hallan conectadas solo a una región local de la imagen de entrada. Así que, en este ejemplo, el campo receptivo es de 5x5x3, porque el kernel es de 5x5x3 (la imagen es RGB). Se puede entender como \"lo que ve\" la red.\n","\n","Con las capas densas ocurre lo contrario, todas las neuronas se hayan conectadas con todos los elementos anteriores. Sin embargo, las neuronas siguen funcionando exactamente igual, lo único es que en la entrada \"ven\" la imagen completa, en vez de una región de la misma.\n","\n","MÁS INFO: http://cs231n.github.io/convolutional-networks/#layers\n","\n","**Por tanto, los parámetros que vamos a tener que ajustar en una capa convolucional son: tamaño del kernel, stride y número de filtros.**\n","\n","* **Capas de Pooling**\n","\n","Las capas de pooling se utilizan para ir reduciendo el tamaño de nuestros mapas de activaciones, ya que de otra forma no sería posible ejecutarlos en GPUs. Además, también ayuda a reducir el overfitting.\n","\n","Los dos tipos de pooling más comunes son:\n","* max-pooling: calcula el máximo de los elementos\n","* averag-pooling: calcula la media de los elementos\n","\n","Hay que tener en cuenta que esto se realiza para cada mapa de activaciones de nuestro volumen, es decir, no interviene para nada la dimensión depth en los cálculos.\n","\n","Veamos un ejemplo de un max-pooling con diferentes strides:\n","\n","<img src=\"https://image.ibb.co/b6tTYJ/cnn_pooling.png\" alt=\"cnn_pooling\" border=\"0\">\n","\n","\n","* **Capas de Normalización**\n","\n","Realizan operaciones sobre los mapas de activaciones. La más común es la de BatchNormalization, que veremos más adelante.\n","\n","\n","* **Fully-connected o densas**\n","\n","Las de siempre.\n","\n","* **BONUS: Locally-connected Layers**\n","\n","Ya sabéis como van las capas convolucionales, verdad? Imaginad que tenemos una imagen de entrada de 32x32, y nuestra red tiene 5 capas convolucionales, cada una con 5 filtros de tamaño 3x3.\n","\n","De acuerdo, pues entonces nuestra red aprenderá, para cada capa, 5 matrices 3x3. Esto es así porque el filtro **recorre la imagen**. Esto se basa en la asunción de que si un determinado filtro es bueno para detectar algo en la posición (x, y) de la imagen, también debería ser bueno para la posición (x2,y2), verdad?\n","\n","Pues bien, esta asunción es válida casi siempre, porque normalmente no sabemos dónde van a estar nuestras características situadas en la imagen.\n","\n","No obstante, si por ejemplo tuviesemos un dataset en las que aparecen caras centradas en la imagen, podríamos querer que los filtros fuesen diferentes para las zonas de los ojos que para las de la nariz o la boca, verdad? Mirad:\n","\n","<img src=\"https://image.ibb.co/iM6w3J/locally_connected_layers_conv.png\" alt=\"locally_connected_layers_conv\" border=\"0\">\n","<img src=\"https://image.ibb.co/ce5Zqy/locally_connected_layers.png\" alt=\"locally_connected_layers\" border=\"0\">\n","\n","\n","En este caso, si sabemos dónde van a estar localizadas nuestras características, tiene más sentido tener un filtro para cada zona, no? Pues sí, pero ¿qué pasa? \n","\n","Que donde antes teníamos que aprender 5 filtros de 3x3 por capa, lo que nos da un total de $5·3·3=45$ parámetros, ahora tendríamos que aprender: $32·32·5·3·3=46080$ parámetros. Fijáos qué diferencia. Con lo cual, a no ser que sepamos dónde queremos buscar los patrones y que van a ser diferentes y siempre van a estar en la misma posición, merece la pena que usemos capas convolucionales en vez de localmente conectadas.\n","\n","Por cierto, mirad la imagen a continuación: las capas que más parámetros tienen son las densas!!! Tiene sentido, ¿verdad? En ellas, todas las neuronas se interconnectan con todas las de la siguiente capa.\n","\n","<img src=\"https://image.ibb.co/jbCaxd/comparison_weight_sharing.png\" alt=\"comparison_weight_sharing\" border=\"0\">\n","\n"," "]},{"cell_type":"markdown","metadata":{"id":"DOQ-u51pHdOQ"},"source":["Después de tanta explicación, ¡¡vamos a por nuestra primera red convolucional!!!\n","\n","### Ejemplo 1\n","\n","**Vamos a implementar una red que permita diferenciar entre 10 tipos de objetos**. Para ello, emplearemos el dataset CIFAR-10, que consta de 60.000 imágenes en color, de 32x32 píxels, repartidas en las 10 clases que podéis apreciar a continuación. El dataset está dividido en 50.000 imágenes para entrenamiento y 10.000 para test.\n","\n","<img src=\"https://image.ibb.co/dnFmKf/cifar10.png\" alt=\"cifar10\" border=\"0\" width=\"400\">\n","\n","Como hemos visto al principio de esta sesión, para esta implementación no vamos a utilizar TensorFlow, sino Keras. A partir de ahora, utilizaremos la versión de Tensorflow que viene por defecto en Google Colab."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mmXXq8MVHZLR"},"outputs":[],"source":["# Vamos a implementar una red que permita diferenciar entre 10 tipos de objetos\n","# Dataset original e info: https://www.cs.toronto.edu/~kriz/cifar.html for more information\n","\n","# Imports necesarios\n","import numpy as np\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.utils import to_categorical\n","\n","# Para hacerlo reproducible\n","np.random.seed(42)\n","\n","# Cargamos el dataset\n","(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n","# Dividimos los datos\n","X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.15, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-xdbRdbsNPgw"},"outputs":[],"source":["# Vamos a ver algunas imágenes de cada clase\n","import matplotlib.pyplot as plt\n","class_names = ['airplane','automobile','bird','cat','deer',\n","               'dog','frog','horse','ship','truck']\n","fig = plt.figure(figsize=(8,3))\n","for i in range(len(class_names)):\n","  ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n","  idx = np.where(Y_train[:]==i)[0]\n","  features_idx = X_train[idx,::]\n","  img_num = np.random.randint(features_idx.shape[0])\n","  im = features_idx[img_num,::]\n","  ax.set_title(class_names[i])\n","  #im = np.transpose(features_idx[img_num,::], (1, 2, 0))\n","  plt.imshow(im)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pV4P7G_dRddx"},"outputs":[],"source":["# Inicializamos el modelo\n","model = Sequential()\n","\n","# Definimos una capa convolucional\n","## Code ##\n","\n","# Definimos una segunda capa convolucional\n","## Code ##\n","\n","# Definimos una tercera capa convolucional\n","## Code ##\n","\n","# Añadimos nuestro clasificador\n","## Code ##\n","## Code ##\n","## Code ##\n","\n","# Compilamos el modelo\n","## Code ##\n","\n","# Entrenamos el modelo\n","## Code ##\n","\n","# Evaluamos el modelo\n","## Code ##\n","\n","print('Loss: %.3f' % scores[0])\n","print('Accuracy: %.3f' % scores[1])"]},{"cell_type":"markdown","metadata":{"id":"0grJgaG0jft2"},"source":["Acabamos de obtener un 61.4% de accuracy en test. No está mal, pero está lejos de ser perfecto. ¿Se os ocurre alguna cosa que podría mejorarlo?\n","\n","Os doy una pista: está relacionado con la **materia prima.**"]},{"cell_type":"markdown","metadata":{"id":"CtTHmMEQj3zD"},"source":["### Pre-procesamiento de las imágenes de entrada\n","\n","Lo primero de todo es preprocesar los datos para facilitarle la faena lo más posible a nuestra red. Si no, puede pasarnos como lo que nos acaba de pasar, que al tener datos que van de 0 a 255, la red nunca llegue a aprender nada.\n","\n","Para llevar a cabo este preprocesamiento, se suelen hacer dos cosas:\n","\n","* **Centrar los datos**: calcular la media del dataset y restársela. Cuando trabajamos con imágenes, se puede calcular la media completa del dataset y restársela directamente, o se puede calcular la media de cada canal de la imagen y restárselo a cada canal.\n","\n","* **Normalizar los datos**: esto se hace para conseguir que todos los datos tengan aproximadamente la misma escala. Las dos formas más comunes de hacerlo son:\n"," * Dividir cada dimensión por su desviación estándar, después de haber sido centrados los datos (restado la media)\n"," * Normalizar de forma que el minimo y el máximo de cada dimensión sean -1 y 1. Esto solo tiene sentido si partimos de unos datos con diferentes escalas pero que nosotros sabemos que deberían ser parecidas, es decir, que tienen una importancia parecida para el algoritmo. En el caso de las imágenes, sabemos que los valores que pueden tomar van de 0 a 255, con lo cual no es estrictamente necesario normalizar, ya que los valores ya están en una escala similar.\n","\n","<center><img src=\"https://image.ibb.co/e765Ay/cnn_preprocessing.jpg\" alt=\"cnn_preprocessing\" border=\"0\" height=\"230\"></center>\n","\n","### IMPORTANTÍSIMO:\n","\n","**La normalización se debe calcular solo con el conjunto de entrenamiento. Es decir, debemos calcular la media y la desviación estándar del conjunto de entrenamiento, y usar esos valores con el conjunto de validación y de set.**\n","\n","\n","Vamos a ver qué tal funciona nuestra red con las medidas que acabamos de ver:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qsn97yeQcOVE"},"outputs":[],"source":["# Centramos los datos (le restamos la media)\n","X_train_mean = ## Code ##\n","X_train_cent = ## Code ##\n","\n","# Normalizamos\n","X_train_std = ## Code ##\n","X_train_norm = ## Code ##"]},{"cell_type":"markdown","metadata":{"id":"W8QDiv8QlQVs"},"source":["Ahora, preparamos nuestro validation y test set (recordad que aunque en este caso :"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oWGm9LhKmCU1"},"outputs":[],"source":["X_test_norm = ## Code ##\n","X_val_norm = ## Code ##"]},{"cell_type":"markdown","metadata":{"id":"C44QLMbinzcN"},"source":["Ya lo tenemos todo listo! Vamos a probar nuestra red de nuevo con los datos normalizados:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zu7BmdoYb7vL"},"outputs":[],"source":["# Inizializamos el modelo\n","model = Sequential()\n","\n","# Definimos una capa convolucional\n","## Code ##\n","\n","# Definimos una segunda capa convolucional\n","## Code ##\n","\n","# Definimos una tercera capa convolucional\n","## Code ##\n","\n","# Añadimos nuestro clasificador\n","## Code ##\n","## Code ##\n","## Code ##\n","\n","# Compilamos el modelo\n","## Code ##\n","# Entrenamos el modelo\n","## Code ## # aquí deberíamos usar un conjunto distinto al de test!!!\n","\n","# Evaluamos el modelo\n","## Code ##\n","\n","print('Loss: %.3f' % scores[0])\n","print('Accuracy: %.3f' % scores[1])"]},{"cell_type":"markdown","metadata":{"id":"FQ-V-zy7WSo7"},"source":["Perfecto!! Por fin funciona!! Ya tenemos nuestra primera CNN entrenada con una precisión de **~0.99 en training y ~0.7 en test**!!\n","\n","Ehh... espera, esto esta lejos de ser perfecto. ¿Cómo puede ser que haya esa **diferencia** entre training y test?\n","\n","Pues sí amigos, como todos estaréis pensando ya, en deep learning también existe el **over-fitting**, de hecho, incluso de una forma más pronunciada que en otras técnicas.\n","\n","Para aquellos que no os acordéis de qué es el overfitting, pensad en esto:\n","\n","Tenéis una red capaz de detectar perfectamente qué personaje aparece en cada momento en el capítulo 4x08 de FRIENDS. Funciona perfectamente, a las mil maravillas, para cada frame, es capaz de decir qué personajes hay en escena con un 99.3% de precisión. Es increíble!! Funciona tan bien, que os venís arriba y decidís probarlo con el 5x01. Y el resultado es que no acierta más que en un 71.2%. \n","\n","Pues bien, este fenómeno es al que se conoce como **overfitting**, y consiste en que creamos un algoritmo que **funciona muy bien en nuestro conjunto de datos, pero al que se le da tremendamente mal generalizar.**\n","\n","Fijaos en la gráfica que representa la precisión en base a las épocas:\n","\n","<img src=\"http://cs231n.github.io/assets/nn3/accuracies.jpeg\" border=\"0\" width=\"400\">\n","(Fuente: http://cs231n.github.io/neural-networks-3/#accuracy)\n","\n","Y mirad este ejemplo:\n","\n","<img src=\"http://cs231n.github.io/assets/nn1/layer_sizes.jpeg\" border=\"0\" height=\"300\">\n","\n","¿Con cual os quedaríais?\n","\n","Claramente, la capa con 20 capas funciona mejor que la que tiene 3 verdad? Sin embargo, lo que normalmente buscamos es que tenga una buena capacidad de generalización y que funcione bien cuando se encuentre datos nuevos. Cuál creéis que funcionará mejor en el caso de ver datos nuevos?\n","\n","Por sorprendente que parezca, la de la izquierda.\n","\n","Volvamos a nuestro ejemplo. En nuestro caso, seguro que a todos nos gustaría mucho más que en vez de ~99 vs ~70, consiguiesemos ~90 vs ~85, verdad?\n","\n","¿Cómo podemos lograr esto? Una de las tareas más sencillas es reduciendo el número de parámetros entrenables de una red. Además, se aplican técnicas como la ** regularización y el dropout**.\n","\n","**NOTA**: en la práctica, el único preprocesamiento que se suele hacer con las imágenes es dividir entre 255 todos sus valores. Con esto suele ser suficiente para que la red funcione correctamente, y así, no dependemos de ningún parámetro relacionado con nuestro conjunto de training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-JQcjoE5NhyS"},"outputs":[],"source":["# https://gist.github.com/giuseppebonaccorso/e77e505fc7b61983f7b42dc1250f31c8\n","# http://parneetk.github.io/blog/cnn-cifar10/"]},{"cell_type":"markdown","source":["#4. **Efecto modificación de capas: GlobalMaxPoling y GlobalMeanPoling frente Flatten**\n","\n","Como habéis podido comprobar anteriormente, la operación flatten nos permite pasar de un volumen de características a un vector sobre el que hacer la tarea de clasificación. Sin embargo, mediante esta operación el número de parámetros se eleva considerablemente. Como alternativa a esta capa, se suelen utilizar otras como GlobalMaxPooling y GlobalAveragePooling que permiten reducir el número de parámetros.\n","\n","<img src=\"https://i.ibb.co/nbyT8fn/Falleten-global-Max.png\" border=\"0\" height=\"300\">"],"metadata":{"id":"oidRaLhNWuj9"}},{"cell_type":"code","source":["from tensorflow.keras.layers import "],"metadata":{"id":"iI27p2P2W2bo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Inizializamos el modelo\n","model = Sequential()\n","\n","# Definimos una capa convolucional\n","model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n","\n","# Definimos una segunda capa convolucional\n","model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","\n","# Definimos una tercera capa convolucional\n","model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","\n","# Añadimos nuestro clasificador\n","## Code ##\n","\n","# Compilamos el modelo (podemos aumentar el lr)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(lr=## Code ##, decay=1e-6),\n","              metrics=['accuracy'])\n","\n","# Entrenamos el modelo\n","model.fit(X_train_norm, to_categorical(Y_train),\n","          batch_size=128,\n","          shuffle=True,\n","          epochs=10,\n","          validation_data=(X_val_norm, to_categorical(Y_val))) # aquí deberíamos usar un conjunto distinto al de test!!!\n","\n","# Evaluamos el modelo\n","scores = model.evaluate(X_test_norm, to_categorical(Y_test))\n","\n","#Observamos el número de parámetros\n","model.summary()\n","\n","print('Loss: %.3f' % scores[0])\n","print('Accuracy: %.3f' % scores[1])"],"metadata":{"id":"OSf_6F3wW3GO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xg29WPGeV95b"},"source":["## 5. **Overfitting: Técnicas de regularización y Dropout**\n","\n","Además de intentar reducir el número de parémtros entrenables en nuestro modelo, existen varias formas de reducir al máximo el over-fitting y así tener un algoritmo capaz de generalizar más.\n","\n","### 5.1 Batch-Normalization\n","\n","La técnica conocida como Batch Normalization es una técnica desarrollada por Ioffe y Szegedy que pretende reducir el cambio de covariables interno o *Internal Covariate Shift*, lo que hace la red más robusta a malas inicializaciones.\n","\n","El Internal Covariate Shift se define como el cambio en la distribucion de las activaciones de las redes debido a que la distribución de los datos de entrada es diferente entre mini-batches. Cuanto menor sea esta diferencia entre mini-batches, más similares serán los datos que llegan a los filtros de la red, más parecidos los mapas de activación también, y mejor funcionará el entrenamiento de la red.\n","\n","Esto lo consigue forzando las activaciones de la red a tener un valor escogido de una distribución gaussiana unitaria al principio del entrenamiento. Este proceso es posible gracias a que la normalización es una operación diferenciable.\n","\n","Normalmente se inserta justo antes de que se ejecute la función de activación:\n","\n","`model.add(Conv2D(128, kernel_size=(3, 3), input_shape=(32, 32, 3)))`\n","\n","`model.add(BatchNormalization())`\n","\n","`model.add(Activation('relu'))`\n","\n","En términos mátematicos, lo que hacemos es centrar y normalizar cada mini-batch que le llega a nuestra red con una media y desviación estandard calculadas con el mini-batch, para luego reescalar y descentrar los datos de nuevo con parámetros aprendidos por la red a través del entrenamiento.\n","\n","<center><img src=\"https://cdn-images-1.medium.com/max/1600/1*Hiq-rLFGDpESpr8QNsJ1jg.png\"><br>Fuente: https://arxiv.org/pdf/1502.03167v3.pdf</center>\n","\n","Además, como estamos calculando la media y la desviación típica para cada mini-batch, en vez de para todo el dataset, bath norm también introduce cierto ruido que actúa como regularización y ayuda a reducir el overfitting.\n","\n","Esta técnica se ha mostrado muy eficiente para entrenar redes más rápidamente (necesitando menos épocas)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yN-muEVQvI9R"},"outputs":[],"source":["# importamos la capa BatchNormalization\n","from tensorflow.keras.layers import BatchNormalization, Activation\n","\n","# Inizializamos el modelo\n","model = Sequential()\n","\n","# Definimos una capa convolucional\n","## Code ##\n","## Code ##\n","## Code ##\n","\n","# Definimos una segunda capa convolucional\n","## Code ##\n","## Code ##\n","## Code ##\n","\n","# Definimos una tercera capa convolucional\n","## Code ##\n","## Code ##\n","## Code ##\n","\n","# Añadimos nuestro clasificador\n","\n","## Code ##\n","## Code ##\n","## Code ##\n","\n","# Compilamos el modelo\n","\n","## Code ##\n","## Code ##\n","## Code ##\n","\n","# Entrenamos el modelo\n","## Code ## # aquí deberíamos usar un conjunto distinto al de test!!!\n","\n","# Evaluamos el modelo\n","scores = ## Code ##\n","\n","\n","print('Loss: %.3f' % scores[0])\n","print('Accuracy: %.3f' % scores[1])"]},{"cell_type":"markdown","metadata":{"id":"r5-04X3xhngr"},"source":["Bueno, parece que ha mejorado mínimamente, aproximadamente un 2%. Esto que puede parecer poquísimo, en cuanto superamos el 90-95% aumentar un 1-2% se convierte en un paso de gigante.\n","\n","Vamos a ver cómo podemos mejorarlo aún más con la **Regularización**."]},{"cell_type":"markdown","metadata":{"id":"vL20IN1jvLP2"},"source":["### 5.2 Regularización\n","\n","La regularización consiste en penalizar de alguna forma las predicciones que hace nuestra red durante el entrenamiento, de forma que no piense que el training set es la verdad absoluta y así sepa generalizar mejor cuando ve otros datasets.\n","\n","Fijáos en esta gráfica:\n","\n","<img src=\"https://image.ibb.co/b8SR2d/regularization.png\" alt=\"regularization\" border=\"0\">\n","\n","En esta gráfica podemos ver un ejemplo de overfitting, otro de underfitting y otro que es capaz de generalizar correctamente.\n","\n","¿Cuál es cual?\n","\n","Azul: over-fitting\n","\n","Verde: buen modelo con capacidad de generalización\n","\n","Naranja: under-fitting\n","\n","Fijaos ahora en este ejemplo siguiendo con el de antes de las 3 redes con diferente número de neuronas. Lo que vemos ahora es la red de 20 neuronas con diferentes niveles de regularización.\n","\n","<img src=\"http://cs231n.github.io/assets/nn1/reg_strengths.jpeg\" border=\"0\" height=\"300\">\n","\n","Podéis jugar con estos parámetros aquí:\n","\n","https://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html\n","\n","y aquí uno mucho más completo:\n","\n","https://playground.tensorflow.org/\n","\n","Al final, es mucho mejor tener una red con muchas capas y aplicarle regularización, que tener una pequeña por evitar el overfitting. Esto se debe a que las redes pequeñas son funciones más sencillas que tienen menos mínimos locales, con lo cual el descenso del gradiente llega a uno u a otro dependiendo mucho de la inicialización, por lo que las pérdidas conseguidas suelen tener una gran varianza dependiendo de la inicialización. Sin embargo, las redes con muchas capas son funciones mucho más complicadas con muchos más mínimos locales que, aunque son más difíciles de alcanzar, suelen tener todos unas pérdidas similares y mejores. Si os interesa el tema: http://cs231n.github.io/neural-networks-1/#arch.\n","\n","Existen muchos métodos de regularización. Aquí vamos a ver los más comunes:"]},{"cell_type":"markdown","metadata":{"id":"e8Dv8Eqz9Uck"},"source":["* **Regularización L2 (Lasso regularization)**\n","\n","La regularización L2 es la más común posiblemente.\n","\n","Consiste en penalizar la función de pérdidas añadiendo el término $\\frac{1}{2}\\lambda w^2$ para cada peso, lo que resulta en $\\frac{1}{2}\\lambda \\sum_i \\sum_jw_{i,j}^2$.\n","\n","El $\\frac{1}{2}$ es simplemente por términos de comodidad cuando calculamos las derivadas, ya que de esta forma nos queda $\\lambda w$ en vez de $2\\lambda w$.\n","\n","Lo que quiere decir esto es que penalizamos los pesos muy altos o dispares, y preferimos que sean todos ellos de magnitudes parecidas. Si recordáis, lo que implican los pesos es la importancia de cada neurona en el cómputo final de la predicción. Por lo tanto, haciendo esto, conseguimos que todas las neuronas importen más o menos por igual, es decir, que la red usará todas sus neuronas para hacer la predicción.\n","\n","Por el contrario, si existiesen pesos muy altos para determinadas neuronas, el cálculo de la predicción tendría mucho más en cuenta a éstas, por lo que acabaríamos con una red con neuronas *muertas* que no sirven para nada.\n","\n","Además, si os fijáis, introduciendo el término $\\frac{1}{2}\\lambda w^2$ en nuestra función de pérdidas hace que durante el descenso del gradiente se intente aproximar los pesos a cero, decayendo linealmente: $W += -\\lambda \\cdot W$.\n","\n","Vamos a ver si conseguimos mejorar nuestra red aplicando la regularización L2:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4rF4QkY7vL__"},"outputs":[],"source":["# Regularización L2\n","\n","# importamos la capa regularización\n","from tensorflow.keras.regularizers import l2\n","\n","# Inizializamos el modelo\n","model = Sequential()\n","\n","# Copiamos del anterior #\n","# Definimos una capa convolucional\n","\n","\n","# Definimos una segunda capa convolucional\n","\n","\n","# Definimos una tercera capa convolucional\n","\n","\n","# Añadimos nuestro clasificador\n","#Copiamos del anterior\n","\n","# Compilamos el modelo\n","#Copiamos del anterior\n","\n","# Entrenamos el modelo\n","#Copiamos del anterior\n","\n","# Evaluamos el modelo\n","scores = #Copiamos del anterior\n","\n","print('Loss: %.3f' % scores[0])\n","print('Accuracy: %.3f' % scores[1])"]},{"cell_type":"markdown","metadata":{"id":"ka5cgOQ55xF5"},"source":["* **Regularización L1 (Ridge regularization)**\n","\n","La L1 también es bastante común. En esta ocasión, añadimos el término $\\lambda |w|$ a nuestra función de pérdidas.\n","\n","También podemos combinar la regularización L1 con la L2 en lo que se conoce como *Elastic net regularization*: $\\lambda_1|w| + \\frac{1}{2}\\lambda_2w^2$.\n","\n","La regularización L1 consigue convertir la matriz de pesos $W$ en una matriz de pesos dispersa o *sparse* (muy cercana a cero, excepto por unos pocos elementos).\n","\n","Esto implica que, al revés que con L2, lo que se consigue es dar mucha más importancia a unas neuronas que a otras, con lo que la red se convierte en más robusta frente a posible ruido.\n","\n","Por lo general, si no estáis muy seguros, la L2 suele dar mejores resultados. La L1 la podéis usar si tenéis imágenes en las que sabéis que hay un número determinado de características que os van a dar una buena clasificación y no queréis que la red se fije en el ruido.\n","\n","Probemos con la L1, y luego con la L1+L2:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8BX7QJnt52nq"},"outputs":[],"source":["# Prueba con regularización L1\n","\n","# importamos la capa regularización\n","from keras.regularizers import l1\n","\n","# Inizializamos el modelo\n","model = Sequential()\n","\n","# Definimos una capa convolucional\n","model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n","\n","# Definimos una segunda capa convolucional\n","model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","\n","# Definimos una tercera capa convolucional\n","model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","\n","# Añadimos nuestro clasificador\n","model.add(Flatten())\n","model.add(Dense(1024, activation='relu', kernel_regularizer=l1(0.01)))\n","model.add(Dense(10, activation='softmax'))\n","\n","# Compilamos el modelo\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(lr=0.0001, decay=1e-6),\n","              metrics=['accuracy'])\n","\n","# Entrenamos el modelo\n","model.fit(X_train_norm, to_categorical(Y_train),\n","          batch_size=128,\n","          shuffle=True,\n","          epochs=10,\n","          validation_data=(X_val_norm, to_categorical(Y_val))) # aquí deberíamos usar un conjunto distinto al de test!!!\n","\n","# Evaluamos el modelo\n","scores = model.evaluate(X_test_norm, to_categorical(Y_test))\n","\n","print('Loss: %.3f' % scores[0])\n","print('Accuracy: %.3f' % scores[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"75o0GvAb54az"},"outputs":[],"source":["# Prueba con regularización elástica (L1 + L2, Elastic net regularization)\n","\n","# importamos la capa regularización\n","from tensorflow.keras.regularizers import l1_l2\n","\n","# Inizializamos el modelo\n","model = Sequential()\n","\n","# Definimos una capa convolucional\n","model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n","\n","# Definimos una segunda capa convolucional\n","model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","\n","# Definimos una tercera capa convolucional\n","model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","\n","# Añadimos nuestro clasificador\n","model.add(Flatten())\n","model.add(Dense(1024, activation='relu', kernel_regularizer=l1_l2(0.01, 0.01)))\n","model.add(Dense(10, activation='softmax'))\n","\n","# Compilamos el modelo\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(lr=0.0001, decay=1e-6),\n","              metrics=['accuracy'])\n","\n","# Entrenamos el modelo\n","model.fit(X_train_norm, to_categorical(Y_train),\n","          batch_size=128,\n","          shuffle=True,\n","          epochs=10,\n","          validation_data=(X_val_norm, to_categorical(Y_val))) # aquí deberíamos usar un conjunto distinto al de test!!!\n","\n","# Evaluamos el modelo\n","scores = model.evaluate(X_test_norm, to_categorical(Y_test))\n","\n","print('Loss: %.3f' % scores[0])\n","print('Accuracy: %.3f' % scores[1])"]},{"cell_type":"markdown","metadata":{"id":"mRf25vat59tV"},"source":["* **Regularización por restricción (Max norm constraints)**\n","\n","Otro tipo de regularización es la que se basa en restricciones. Por ejemplo, podríamos establecer un máximo que los pesos no pueden superar.\n","\n","En la práctica, esto se implementa usando el gradient descent para calcular el nuevo valor de los pesos como lo haríamos normalmente, solo que después se calcula la norma 2 de cada vector de pesos para cada neurona y se pone como condición que no pueda superar a $c$, es decir: $||W||_2 \\lt c$. Normalmente, $c$ es igual a 3 o 4. \n","\n","Lo que conseguimos con esta normalización es que la red no \"explote\", es decir, que los pesos no crezcan desmesuradamente (recordad que esto era lo que pasaba cuando usábamos un learning rate muy alto).\n","\n","Veamos esta regularización qué tal va:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_wG5PZhJ6D76"},"outputs":[],"source":["# Prueba con regularización maxnorm\n","\n","# importamos la capa max_norm\n","from tensorflow.keras.constraints import max_norm\n","\n","# Inizializamos el modelo\n","model = Sequential()\n","\n","# Copiamos del anterior y añadimos max_norm\n","\n","# Definimos una capa convolucional\n","\n","# Definimos una segunda capa convolucional\n","\n","# Definimos una tercera capa convolucional\n","\n","# Añadimos nuestro clasificador\n","\n","\n","# Compilamos el modelo\n","\n","\n","# Entrenamos el modelo\n","\n","\n","# Evaluamos el modelo\n","scores = \n","\n","print('Loss: %.3f' % scores[0])\n","print('Accuracy: %.3f' % scores[1])"]},{"cell_type":"markdown","metadata":{"id":"kQuGxg8L6Gda"},"source":[" * **Regularización por Dropout**\n","\n","La regularización por Dropout es una técnica desarrollada por Srivastava et al. en su artículo \"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\" que complementa los otros tipos de normalización (L1, L2, maxnorm).\n","\n","Es una técnica extremadamente efectiva y simple, que consiste en mantener una neurona activa o ponerla a 0 durante el entrenamiento con una probabilidad $p$.\n","\n","Lo que conseguimos con esto es cambiar la arquitectura de la red en tiempo de entrenamiento, lo que significa que no habrá una sola neurona responsable de activarse ante un determinado patrón, sino que tendremos múltiples neuronas redundantes capaces de reaccionar ante ese patrón.\n","\n","<img src=\"https://image.ibb.co/ep0fdJ/dropout.png\" alt=\"dropout\" border=\"0\" height=\"300\">\n","\n","Veamos qué tal se porta nuestra red con Dropout:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pQED18H09hkF"},"outputs":[],"source":["# Prueba con Dropout\n","\n","# importamos la capa Dropout\n","from tensorflow.keras.layers import Dropout\n","\n","# Inizializamos el modelo\n","model = Sequential()\n","\n","## Copiamos del anterior añadiendo Dropout\n","\n","# Definimos una capa convolucional\n","\n","\n","# Definimos una segunda capa convolucional\n","\n","\n","# Definimos una tercera capa convolucional\n","\n","\n","# Añadimos nuestro clasificador\n","\n","\n","# Compilamos el modelo\n","\n","\n","# Entrenamos el modelo\n","\n","\n","# Evaluamos el modelo\n","scores =\n","\n","print('Loss: %.3f' % scores[0])\n","print('Accuracy: %.3f' % scores[1])"]},{"cell_type":"markdown","metadata":{"id":"8xr_KFR66KvJ"},"source":["Y ahora, veamos con Max norm + Dropout:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PQvYyn-D6Nmn"},"outputs":[],"source":["# Prueba con Dropout y Maxnorm\n","\n","from tensorflow.keras.constraints import max_norm\n","from tensorflow.keras.layers import Dropout\n","\n","# Inizializamos el modelo\n","model = Sequential()\n","\n","##Copiamos del anterior y añadimos max_norm\n","\n","# Definimos una capa convolucional\n","\n","# Definimos una segunda capa convolucional\n","\n","\n","# Definimos una tercera capa convolucional\n","\n","\n","# Añadimos nuestro clasificador\n","\n","\n","# Compilamos el modelo\n","\n","\n","# Entrenamos el modelo\n","\n","\n","# Evaluamos el modelo\n","scores = \n","\n","print('Loss: %.3f' % scores[0])\n","print('Accuracy: %.3f' % scores[1])"]},{"cell_type":"markdown","metadata":{"id":"00P6_N2-CPya"},"source":["### ¿Y si usásemos, además, la capa MaxPooling?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6U2BfbUpCGre"},"outputs":[],"source":["# Prueba con Dropout, Maxnorm y Maxpooling\n","\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.constraints import max_norm\n","from tensorflow.keras.layers import MaxPooling2D\n","\n","# Inizializamos el modelo\n","model = Sequential()\n","\n","## Copiamos del anteior y añadimos maxPooling\n","# Definimos una capa convolucional\n","\n","\n","# Definimos una segunda capa convolucional\n","\n","\n","# Definimos una tercera capa convolucional\n","\n","\n","# Añadimos nuestro clasificador\n","\n","\n","# Compilamos el modelo\n","\n","\n","# Entrenamos el modelo\n","\n","\n","# Evaluamos el modelo\n","scores = \n","\n","print('Loss: %.3f' % scores[0])\n","print('Accuracy: %.3f' % scores[1])"]},{"cell_type":"markdown","metadata":{"id":"TbM-qdTZClju"},"source":["Como podéis comprobar ha entrenado mucho más rápido. Esto se debe a que cada capa MaxPooling diezma por 2 el número de elementos del mapa de activaciones.\n","\n","A la vez, la precisión también ha sido menor. Probablemente si lo dejásemos un mayor número de épocas conseguiríamos unos resultados comparables a los de antes.\n","\n","### ¿Y aumentando el strides a (2,2) en las convolucionales, en vez de añadir MaxPooling?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rKHoe2E6B2Ic"},"outputs":[],"source":["# Prueba con Dropout, Maxnorm y strides = 4 en las convolucionales\n","\n","from tensorflow.keras.constraints import max_norm\n","from tensorflow.keras.layers import Dropout\n","\n","# Inizializamos el modelo\n","model = Sequential()\n","\n","# Definimos una capa convolucional\n","model.add(Conv2D(128, kernel_size=(3, 3), strides=##Code##, activation='relu', input_shape=(32, 32, 3)))\n","model.add(Dropout(0.25))\n","\n","# Definimos una segunda capa convolucional\n","model.add(Conv2D(128, kernel_size=(3, 3), strides=##Code##, activation='relu'))\n","model.add(Dropout(0.25))\n","\n","# Definimos una tercera capa convolucional\n","model.add(Conv2D(128, kernel_size=(3, 3), strides=##Code##, activation='relu'))\n","model.add(Dropout(0.25))\n","\n","# Añadimos nuestro clasificador\n","model.add(Flatten())\n","model.add(Dense(1024, activation='relu', kernel_constraint=max_norm(3.)))\n","model.add(Dropout(0.5))\n","model.add(Dense(10, activation='softmax'))\n","\n","# Compilamos el modelo\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(lr=0.0001, decay=1e-6),\n","              metrics=['accuracy'])\n","\n","# Entrenamos el modelo\n","model.fit(X_train_norm, to_categorical(Y_train),\n","          batch_size=128,\n","          shuffle=True,\n","          epochs=10,\n","          validation_data=(X_val_norm, to_categorical(Y_val))) # aquí deberíamos usar un conjunto distinto al de test!!!\n","\n","# Evaluamos el modelo\n","scores = model.evaluate(X_test_norm, to_categorical(Y_test))\n","\n","print('Loss: %.3f' % scores[0])\n","print('Accuracy: %.3f' % scores[1])"]},{"cell_type":"markdown","metadata":{"id":"cHPkgJokEBY-"},"source":["Los resultados son parecidos en términos de velocidad, pero la precisión es menor. En un artículo publicado en 2014 (https://arxiv.org/abs/1412.6806), los autores proponian dejar de usar las capas de pooling en pos de la simplicidad, y de hecho, hay arquitecturas como la ResNet, que avogan por esto. Sin embargo, siguen utilizándose bastante a día de hoy."]},{"cell_type":"markdown","metadata":{"id":"CyZigR9_OB44"},"source":["## BONUS: Curiosidad\n","\n","Aquí podéis ver una \"tabla de clasificación\" de los resultados de algunos de los problemas actuales más famosos, acompañados de un paper explicando la implementación que lo ha conseguido:\n","\n","http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["bUx4EViyC_Hg"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}