{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " 6 Optimización de hiper-parámetros.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpSt_OQ47_4P"
      },
      "source": [
        "# Módulo 6. Optimización de hiper-parámetros\n",
        "\n",
        "¡Bienvenidos al sexto módulo! Ahora que ya sabemos lo que son las redes neuronales, las redes convolucionales y todos sus parámetros y entresijos, vamos a ver cómo podemos optimizarlas al máximo.\n",
        "\n",
        "Para ello, en este módulo veremos:\n",
        "\n",
        "\n",
        "1. **Grid search**\n",
        "\n",
        "2. **Hyperopt**\n",
        "\n",
        "3. **Algoritmos genéticos**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvLzmsFm8bv9"
      },
      "source": [
        "## 1. Grid search\n",
        "\n",
        "El grid search es el método más sencillo que existe para encontrar los mejores parámetros dentro de un conjunto. Esencialmente se trata de fuerza bruta. Vamos a ver un ejemplo sencillo:\n",
        "\n",
        "Suponed que tenemos nuestra anterior red y queremos ver qué parámetros son los mejores. Tenemos:\n",
        "\n",
        "* dropout: puede variar de 0 a 0.5 en intervalos 0.1\n",
        "* learning rate: puede variar de 0.1 a 0.001 en intervalos de x10\n",
        "* número de filtros: puede variar de 64 a 256 en intervalos de 64\n",
        "* tamaños del filtro: puede variar desde 3 hasta 7 de 2 en 2 (filtros cuadrados siempre)\n",
        "\n",
        "Pues bien, lo que el grid search haría es los iguiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA05n2y9DGgj"
      },
      "source": [
        "# Definimos nuestra grid\n",
        "## Code ##\n",
        "\n",
        "# creamos una variable para guardar nuestras accuracies\n",
        "log_accuracies = []\n",
        "\n",
        "# para hacer esta prueba definimos una función que sustituye a nuestra red y \n",
        "# asigna un valor aleatorio cada vez\n",
        "# si lo hiciésemos con nuestra red de verdad, tardaría demasiado como para verlo\n",
        "# en clase\n",
        "from random import uniform\n",
        "def dummy_net(d, lr, nf, fs):\n",
        "  print('Ejecutando la red con d={}, lr={}, nf={}, fs={}'.format(d, lr, nf, fs))\n",
        "  return uniform(0,1)\n",
        "\n",
        "# contador\n",
        "i = 1\n",
        "\n",
        "# empezamos el grid search\n",
        "##Code##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3H4yePeLZTV"
      },
      "source": [
        "# y el mejor resultado sería\n",
        "import numpy as np\n",
        "idx_max = ## Cod e##\n",
        "print(idx_max)\n",
        "\n",
        "print('Best execution: {}. Accuracy: {}'.format(##Code##))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty5EDQgLJkkf"
      },
      "source": [
        "Y con esto sabríamos cuál es la mejor configuración de nuestra red. Mucho mejor que andar cambiando parámetros a mano, ¿verdad?\n",
        "\n",
        "¿Cuál es el problema de este método? Pues que tenemos 6 x 4 x 4 x 3 ejecuciones de nuestra red, lo que hacen un total de 288 ejecuciones, a un mínimo de 10 minutos por ejecución, son 48 horas, ¡¡¡2 días!!!\n",
        "\n",
        "Si queréis comprobarlo no tenéis más que meter dentro de dummy_net la arquitectura de la red y ejecutarlo ;-)\n",
        "\n",
        "Vamos a hacer una prueba con una red muy sencillita para que veáis qué tal funciona:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importamos los paquetes necesarios\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# cargamos los datos y pasamos de vector a imagen\n",
        "img_rows, img_cols = 28, 28\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# normalizamos\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "## Code ##\n",
        "## Code ##\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "num_classes = 10\n",
        "## Code ##\n",
        "## Code ##\n",
        "\n",
        "def net(do, lr, nf, fs):\n",
        "\n",
        "   ## Code ##\n",
        "\n",
        "  \n",
        "  print('Red con d={}, lr={}, nf={}, fs={}. Loss: {}. Acc: {}.'.format(d, lr, nf, fs, score[0], score[1]))      \n",
        "  return ## Code ##"
      ],
      "metadata": {
        "id": "TNHV376aOPXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWl0Fm0j2exL"
      },
      "source": [
        "# definimos nuestra grid\n",
        "##Code##\n",
        "\n",
        "# creamos una variable para guardar nuestras accuracies\n",
        "log_accuracies = []\n",
        "\n",
        "# contador\n",
        "i = 1\n",
        "\n",
        "# empezamos el grid search\n",
        "##Code##\n",
        "        \n",
        "# y el mejor resultado sería\n",
        "import numpy as np\n",
        "idx_max = ##Code##\n",
        "print(idx_max)\n",
        "print('Best execution: {}. Accuracy: {}'.format(##Code##))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lleM0ooV7xGQ"
      },
      "source": [
        "# definimos nuestra grid con mejores valores\n",
        "##Code##\n",
        "# creamos una variable para guardar nuestras accuracies\n",
        "log_accuracies = []\n",
        "\n",
        "# contador\n",
        "i = 1\n",
        "\n",
        "# empezamos el grid search\n",
        "##Code##\n",
        "        \n",
        "# y el mejor resultado sería\n",
        "import numpy as np\n",
        "idx_max = ##Code##\n",
        "print(idx_max)\n",
        "\n",
        "print('Best execution: {}. Accuracy: {}'.format(##Code##))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUZHM4_J2Zf5"
      },
      "source": [
        "Bueno, no está mal, ¿verdad?\n",
        "\n",
        "Aunque estaría genial que hubiesen métodos más rápidos o usando algo de heurística, ¿no? En vez de fuerza bruta...\n",
        "\n",
        "Pues estáis de suerte! Existen varios métodos de este tipo:\n",
        "\n",
        "* Spearmint (Python)\n",
        "* BayesOpt (C++ with Python and Matlab/Octave interfaces)\n",
        "* hyperopt (Python)\n",
        "* SMAC (Java)\n",
        "* REMBO (Matlab)\n",
        "* MOE (C++/Python)\n",
        "\n",
        "+INFO: http://fastml.com/optimizing-hyperparams-with-hyperopt/\n",
        "\n",
        "Y hoy vamos a ver **hyperopt**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywTCluaY8cLo"
      },
      "source": [
        "## 1.2 Hyper-opt\n",
        "\n",
        "Otra opción es utilizar hyperopt (Hyperopt: Distributed Asynchronous Hyper-parameter Optimization, https://github.com/hyperopt/hyperopt).\n",
        "\n",
        "Hyperopt es una librería escrita en Python que permite optimizar funciones de una forma rápida fijándose más en los valores que más probablemente van a dar una buena solución.\n",
        "\n",
        "Actualmente tiene dos algoritmos implementados para hacer esto:\n",
        "\n",
        "* Random Search\n",
        "* Tree of Parzen Estimators (TPE)\n",
        "\n",
        "Además, se pueden ejecutar en serie o en paralelo, haciendo uso de MongoDB.\n",
        "\n",
        "Vamos a ver un ejemplo de cómo utilizarlo.\n",
        "\n",
        "Vamos a encontrar el mínimo de $x^2$:\n",
        "(<a href=\"https://www.google.es/search?source=hp&ei=2ds5XO_jG6y_lwTvxp2QBQ&q=x**2&btnK=Google+Search&oq=x**2&gs_l=psy-ab.3...716.1584..1916...0.0..0.301.1084.1j0j3j1......0....1..gws-wiz.....0..0i131j0.cgRgMW95cQk\">click aqui para ver la funcion</a>)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDMGyMu2_t4n"
      },
      "source": [
        "from hyperopt import fmin, tpe, hp\n",
        "# con 10 iteraciones\n",
        "\n",
        "best = ##Code##\n",
        "\n",
        "print(best)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlBOKvSEAyOw"
      },
      "source": [
        "# con 100 iteraciones\n",
        "best = ##Code##\n",
        "print(best)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLdjuCSTBNnK"
      },
      "source": [
        "# con 1000 iteraciones\n",
        "best = ##Code##\n",
        "\n",
        "print(best)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XADBBMkk_-1g"
      },
      "source": [
        "Y ahora uno más complejo con redes neuronales:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHyu3hB95H-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70156ff-7c38-4084-a9f0-2dbf80b6f2f8"
      },
      "source": [
        "# instalamos los paquetes necesarios\n",
        "!pip install networkx==1.11 # para instala hyperopt correctamente, si no, da errores\n",
        "!pip install hyperopt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting networkx==1.11\n",
            "  Downloading networkx-1.11-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from networkx==1.11) (4.4.2)\n",
            "Installing collected packages: networkx\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 2.6.3\n",
            "    Uninstalling networkx-2.6.3:\n",
            "      Successfully uninstalled networkx-2.6.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.18.3 requires networkx>=2.0, but you have networkx 1.11 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed networkx-1.11\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt) (4.64.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt) (4.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.11)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt) (4.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-19aAqN713Q"
      },
      "source": [
        "# imports necesarios\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "#Cargamos y normalziamos los datos\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "validation_split = 0.1\n",
        "X_train, X_val, y_train, y_val = ## Code ##\n",
        "\n",
        "X_train = ##Code##\n",
        "X_val = ##Code##\n",
        "X_test = ##Code##\n",
        "\n",
        "# convertimos las etiquetas a one-hot encoding\n",
        "n_classes = 10\n",
        "y_train = ##Code##\n",
        "y_val = ##Code##\n",
        "y_test = ##Code##\n",
        "\n",
        "# definimos nuestro espacio de búsqueda\n",
        "# vamos a variar:\n",
        "# - el número de filtros en nuestras capas conv\n",
        "# - el porcentaje de dropout\n",
        "# - el número de neuronas en la capa dense\n",
        "\n",
        "space =  ## Code ##\n",
        "\n",
        "# nos definimos unos callbacks para que la red pare cuando no vea mejora \n",
        "\n",
        "def\tget_callbacks(pars):\n",
        "  callbacks\t= ## Code ##\n",
        "  return callbacks\n",
        "\n",
        "def mi_cnn(pars):\n",
        "  print ('Parameters: ', pars)\n",
        "  model = Sequential()\n",
        "  \n",
        "  \n",
        "  # Aquí va vuestra arquitectura # \n",
        "  \n",
        "  # Primer bloque convolucional\n",
        "  ##Code##\n",
        "  # Segundo bloque convolucional\n",
        "  ##Code##\n",
        "  # Tercer bloque convolucional\n",
        "  ##Code##\n",
        "  # Bloque clasificador\n",
        "  ##Code##\n",
        "  # Compilamos el modelo\n",
        "  ##Code##\n",
        "\n",
        "  # Entrenamos el modelo\n",
        "  ##Code##\n",
        "\n",
        "  best_epoch_loss = ##Code##\n",
        "  best_val_loss = ##Code##\n",
        "  best_val_acc = ##Code##\n",
        "  \n",
        "  print('Epoch {} - val acc: {} - val loss: {}'.format(best_epoch_loss, best_val_acc, best_val_loss))\n",
        "  sys.stdout.flush()\n",
        "  \n",
        "  return {'loss': best_val_loss, 'best_epoch': best_epoch_loss, 'eval_time': time.time(), 'status': STATUS_OK, 'model': model, 'history': history}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ejecutamos la optimización\n",
        "trials = # Code #\n",
        "best = # Code #\n",
        "print(best)"
      ],
      "metadata": {
        "id": "WjF51ETXWooJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnWTApwx8tP0"
      },
      "source": [
        "trials.trials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vi6qOtcBYqs"
      },
      "source": [
        "¿Por qué dice que best_epoch=4? Porque history está indexado en 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_omggaGAqx6"
      },
      "source": [
        "trials.trials[6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKUsa3IJ9O8j"
      },
      "source": [
        "trials.results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edAvMjPX9Qxi"
      },
      "source": [
        "trials.losses()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpK451ZLCF18"
      },
      "source": [
        "¿Qué os parece?  Así, podéis dejar vuestra configuración e iros a hacer algo más útil que andar variando parámetros hasta que encontréis la configuración adecuada.\n",
        "\n",
        "**¡Mejor que lo hagan por nosotros y que nos la encontremos automáticamente seleccionada!**\n",
        "\n",
        "Pero no tenemos por qué quedarnos aquí, podemos también variar el número de capas o si queremos conexiones residuales, por ejemplo! Sí, esto significa que podemos variar la **arquitectura** también.\n",
        "\n",
        "Aquí tenéis un ejemplo muy completo: https://github.com/Vooban/Hyperopt-Keras-CNN-CIFAR-100\n",
        "\n",
        "Y aquí otro que quizá os parezca interesante: \n",
        "\n",
        "<img src=\"http://cdn.lizamayliza.com/storage/cache/images/003/636/Daffy-Duck-Money-eyes-feature,xlarge.1480369578.jpg\" border=\"0\" height=\"200\">\n",
        "\n",
        "https://medium.com/machine-learning-world/neural-networks-for-algorithmic-trading-hyperparameters-optimization-cb2b4a29b8ee"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJBIyfkE8cl0"
      },
      "source": [
        "## 1.3 Algoritmos genéticos\n",
        "\n",
        "Quizás estéis pensando en que tras haber visto esto no necesitáis saber nada más, ¡ya habéis encontrado algo que es la repera! Pues atentos porque lo que viene, pese a ser algo muy sencillo, es potentísimo, y os va encantar. Sí, estoy hablando de **los algoritmos genéticos**.\n",
        "\n",
        "En esencia, los algoritmos genéticos son un método de búsqueda meta-heurística inspirados en la evolución natural. Pertenecen a los algoritmos evolutivos, concretamente a los Algoritmos de búsqueda aleatoria guiada (Guided Random Search algorithms (Evolutionary Alg.)).\n",
        "\n",
        "Esto que os puede parecer chino, es muy sencillo. Vamos a entenderlos con un ejemplo:\n",
        "\n",
        "<img src=\"https://image.ibb.co/cJcQYJ/ga_problem.png\" alt=\"ga_problem\" border=\"0\">\n",
        "\n",
        "Imaginad que tenemos un puzzle, y nos queda solo una pieza por encajar. Lo que pasa es que este puzzle es muy especial, porque nos permite fabricarnos nuestras propias piezas. Para ello, disponemos de varios mecanismos:\n",
        "\n",
        "* **Combinar** partes de piezas (**crossover** o recombinación).\n",
        "* **Modificar** determinadas partes de esas piezas (**mutación**).\n",
        "* **Escoger** las mejores piezas de todas las que hemos hecho, para a partir de ellas, construir nuevas que sean mejores (**selección**).\n",
        "\n",
        "Entonces imaginaos que decidimos cortar 10 trozos de carton, que son nuestras 10 piezas iniciales con las que vamos a probar a ver si alguna encaja perfectamnte. Las probamos todas, y de esas 10, 5 encajan más o menos. Así que seleccionamos esas 5 y fabricamos nuevas a partir de ellas mediante los mecanismos explicados arriba:\n",
        "\n",
        "* De las 5 seleccionadas, sacamos 5 más combinando partes de dos de esas 5 originales escogiéndolas aleatoriamente\n",
        "* De las 5 originales, y las nuevas 5 que nos hemos creado, sacamos 5 más modificando ligeramente una de las puntas de la pieza\n",
        "\n",
        "Ahora resulta que tenemos 15 piezas, y nosotros queremos tener siempre 10, porque si no a la 5 vez que hiciéramos esto tendríamos una barbaridad de piezas!! Así que:\n",
        "\n",
        "* Probamos nuestras 15 piezas y nos quedamos con la que mejor encaja, y luego 9 escogidas al azar\n",
        "\n",
        "Pues ya está, ¡eso es lo que hace un algoritmo genético! ¡Ya sabéis cómo funcionan! Sencillo, ¿verdad? Pues no os hacéis una idea de lo potentes que son :-)\n",
        "\n",
        "Vamos a verlo un poco más concreto siguiendo con nuestro ejemplo:\n",
        "\n",
        "<img src=\"https://image.ibb.co/b7ySfy/geneticos_puzzle.png\" alt=\"geneticos_puzzle\" border=\"0\">\n",
        "\n",
        "Como podéis ver:\n",
        "\n",
        "* Cada pieza de nuestro conjunto de piezas (población) es un **cromosoma**\n",
        "* Cada parte de nuestra pieza es un **gen**, por tanto, nuestro cromosoma tiene 4 genes\n",
        "* Los posibles valores o configuraciones que puede tener cada gen se llama **alelo**\n",
        "\n",
        "Esto es exactamente igual que en biología! No os dije que estaban inspirados en la evolución natural? :-)\n",
        "\n",
        "Vale, pues vamos a ir relacionando estas palabrejas con nuestro ejemplo:\n",
        "\n",
        "* Necesitamos encontrar la pieza correcta para nuestro hueco del puzzle\n",
        "* Tenemos un conjunto inicial de piezas (**población**) que pueden encajar bien o no, no lo sabemos\n",
        "* Comprobamos cómo de bien encajan estas piezas (usando la **función de fitness**)\n",
        "* Si ninguna de las piezas encaja como nos gustaría, modificamos las piezas (con los operadores: **crossover** y **mutación**)\n",
        "* Comprobamos como de bien encajan las piezas recien creadas (**función de fitness**)\n",
        "* Seleccionamos las piezas que queremos aguantar para la próxima iteración (**selección**)\n",
        "\n",
        "* Y volvemos a empezar! así, hasta que encontremos una pieza que encaje con la precisión que nosotros queremos\n",
        "\n",
        "Venga, vamos a ponernos un poco más serios. Veamos el pseudo-algoritmo:\n",
        "\n",
        "**START**\n",
        "\n",
        "Generate the initial population\n",
        "\n",
        "Compute fitness\n",
        "\n",
        "**REPEAT**\n",
        "    \n",
        "    Selection\n",
        "    \n",
        "    Crossover\n",
        "    \n",
        "    Mutation\n",
        "\n",
        "    Compute fitness\n",
        "\n",
        "**UNTIL** population has converged\n",
        "\n",
        "**STOP**\n",
        "\n",
        "¿Se entiende, no? ¡Es exactamente lo mismo que los pasos que acabamos de hablar con el puzzle!\n",
        "\n",
        "<img src=\"https://image.ibb.co/kQu7Ed/ga_workflow.png\" alt=\"ga_workflow\" border=\"0\" width=\"600\">\n",
        "\n",
        "Vale, y ahora llega lo interesante, ¿cómo funcionan realmente?\n",
        "\n",
        "Tenemos que entender varios conceptos:\n",
        "\n",
        "* Cómo se inicializa nuestra población\n",
        "* Cómo funciona el crossover\n",
        "* Cómo funciona la mutación\n",
        "* Cómo funciona la seleccion\n",
        "* Cómo podemos definir nuestra función de fitness\n",
        "\n",
        "¿Preparados? ¡Vamos allá!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbgSCrpOcbqt"
      },
      "source": [
        "Lo primero es entender que cuando tenemos un problema en el mundo real y queremos solucionarlo en un ordenador, necesitamos **codificarlo** para que el ordenador lo entienda.\n",
        "\n",
        "Así, por ejemplo:\n",
        "\n",
        "* En el mundo real, el cromosoma es la pieza del puzzle. En el ordenador, el cromosoma es un vector con 4 valores (uno para indicar el tamaño de cada punta, donde positivo significa punta, negativo significa hueco hacia dentro de la pieza)\n",
        "\n",
        "Esto es a lo que se llama la codificación.\n",
        "\n",
        "Una vez sabido esto, vamos a ver cómo funcionan los operadores. Antes de nada, debéis saber que xisten muchos tipos de crossover, mutación y selección, pero aquí vamos a ver solo los más sencillos por temas de tiempo. \n",
        "\n",
        "Si estáis interesados en conocerlos más profundamente, en internet hay muchísimo material disponible. Podéis empezar aquí: https://www.tutorialspoint.com/genetic_algorithms/index.htm\n",
        "\n",
        "\n",
        "<img src=\"https://image.ibb.co/hEwVHd/ga_operators.png\" alt=\"ga_operators\" border=\"0\">\n",
        "\n",
        "**El crossover de un único punto (single-point crossover)**\n",
        "\n",
        "Nuestro cromosoma es la pieza de puzzle, que tiene los 4 genes que veis en la imagen. Pues el crossover simple sencillamente escoge un punto aleatoriamente de los 4 genes, y combina las partes en nuevos cromosomas, como veis en la imagen.\n",
        "\n",
        "Es importante que entendáis que el crossover **produce nuevos cromosomas**, puesto que tenemos los originales y los **recombinados**.\n",
        "\n",
        "**La mutación uniforme**\n",
        "\n",
        "La mutación uniforme consiste en que para cada cromosoma, lanzamos una moneda al aire. Si sale cara, modificamos un gen escogido aleatoriamente. ¿Qué valor le asignamos? Uno aleatorio dentro del rango que permite dicho gen.\n",
        "\n",
        "**La selección**\n",
        "\n",
        "Para la selección lo que se suele hacer es usar las fitness de los cromosomas (también llamados posibles **soluciones**). En este caso, vamos a ver la Stochastic Universal Sampling, que consiste en que construímos una gráfica de tipo tarta donde cada cromosoma ocupa un espacio que corresponde con su fitness. Después, establecemos N puntos fijos alrededor de la \"tarta\", donde N son el número de cromomsomas que queremos **seleccionar**. Después, se \"gira la tarta\", como si fuese la ruleta de la suerte, y los cromosomas a los que apuntan los puntos fijos son los seleccionados y pasan a la siguiente iteración.\n",
        "\n",
        "Si os fijáis, **los cromosomas no están ordenados de mayor a menor fitness**!! \n",
        "\n",
        "Esto es importante, puesto que si no, las probabilidades de seleccionar un cromosoma con una fitness alta y otro con una fitness baja serían más altas que de seleccionar dos con la fitness alta, ya que al estar los puntos de selección uno enfrente del otro, sería muy complicado seleccionar dos cromosomas con fitness parecidas.\n",
        "\n",
        "Este operador tiene varias formas de funcionar. Siguiendo con nuestro ejemplo de población de 10 cromosomas, las formas son:\n",
        "\n",
        "* Seleccionamos $N=10$ cromosomas, es decir, sustituimos la anterior población por una completamente nueva\n",
        "* Seleccionamos $N=n$ cromosomas, donde n<10. Es decir, sustituímos solo una parte de los crosomomas antiguos. El resto siguen jugando ;-D\n",
        "\n",
        "Vale, pues si seleccionamos los 10 está claro, pero si seleccionamos $n$, cómo elegimos cuales quitamos?\n",
        "\n",
        "Pues las dos formas más comunes son:\n",
        "\n",
        "* Quitamos los cromosomas más antiguos\n",
        "* Quitamos los cromosomas con peor fitness\n",
        "\n",
        "Ya por último, hay veces que seleccionamos al mejor cromosoma (o a los $k$ mejors) para que pase si o si a la siguiente iteración, es decir, hay *elitismo*. Hay que ir con cuidado con esto, puesto que aunque a priori parezca que el elitismo es lo mejor y que solo deberíamos quedarnos con los mejores, si lo hiciésemos nos estaríamos cargando una de las mayores virtudes de los genéticos: **que son capaces de escapar a mínimos locales!!!**\n",
        "\n",
        "Fijaos, aquí podéis ver en plena acción a un genético intentando decidir cual es la mejor configuración para un vehículo de 2 ruedas: http://rednuht.org/genetic_cars_2/\n",
        "\n",
        "\n",
        "\n",
        "Vale, ¿pues ahora qué tal si implementamos un par de ejemplos nosotros?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nqbm0WeXHw-N"
      },
      "source": [
        "# Ejemplo simple de un GA donde tenemos que encontrar N números que sumen X\n",
        "# https://lethain.com/genetic-algorithms-cool-name-damn-simple\n",
        "\n",
        "from random import randint, random\n",
        "from operator import add\n",
        "from functools import reduce\n",
        "import numpy as np\n",
        "\n",
        "def individual(length, min, max):\n",
        "    # creamos un individuo\n",
        "    return ## Code ##\n",
        "\n",
        "def population(count, length, min, max):   \n",
        "    # creamos nuestra población\n",
        "    # count: numero de invidiuos en la población\n",
        "    # length: número de valores por individuo\n",
        "    # min: minimo permitido para cada valor del individuo\n",
        "    # max: maximo permitido para cada valor del individuo\n",
        "\n",
        "    return ## Code ##\n",
        "\n",
        "def fitness(individual, target):\n",
        "    # calculamos la fitness de un individuo: más bajo es mejor\n",
        "    \n",
        "    sum = ## Code ##\n",
        "    return abs(target-sum)\n",
        "\n",
        "def grade(pop, target):\n",
        "    # calculamos la media de la población entera\n",
        "    summed = ## Code ##\n",
        "    return summed / (len(pop) * 1.0)\n",
        "  \n",
        "def find_best_solution(pop, target):\n",
        "    # encuentra la mejor solución en la población actual y la imprime\n",
        "    res = [## Code ##\n",
        "    res_min = np.min(res)\n",
        "    res_min_idx = ## Code ##\n",
        "    for n in res_min_idx:\n",
        "        print('Individual: ', n, 'Valores: ', *pop[n], ' Result: ', np.sum(pop[n]), 'Target; ', target)\n",
        "    return res_min    \n",
        "\n",
        "def evolve(pop, target, retain=0.2, random_select=0.05, mutate=0.01):\n",
        "    graded = ## Code ##\n",
        "    graded = ## Code ##\n",
        "    retain_length = ## Code ##\n",
        "    parents = ## Code ##\n",
        "    \n",
        "    # añadimos individuos aleatoriamente para promover la diversidad genética\n",
        "    for individual in graded[retain_length:]:\n",
        "        if random_select > random():\n",
        "            parents.append(individual)\n",
        "    \n",
        "    # mutamos algunos\n",
        "    for individual in parents:\n",
        "        if mutate > random():\n",
        "            pos_to_mutate = randint(0, len(individual)-1)\n",
        "            individual[pos_to_mutate] = randint(i_min, i_max)\n",
        "    \n",
        "    # reproducimos (crossover) nuestros cromosomas (individuals, soluciones)\n",
        "    parents_length = len(parents)\n",
        "    desired_length = len(pop) - parents_length\n",
        "    children = []\n",
        "    while len(children) < desired_length:\n",
        "        male = randint(0, parents_length-1)\n",
        "        female = randint(0, parents_length-1)\n",
        "        if male != female:\n",
        "            male = parents[male]\n",
        "            female = parents[female]\n",
        "            half = round(len(male) / 2)\n",
        "            child = male[:half] + female[half:]\n",
        "            children.append(child)        \n",
        "    parents.extend(children)\n",
        "    return parents\n",
        "\n",
        "# Ejecutamos el GA\n",
        "\n",
        "## Code##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ1OBYY6DwGz"
      },
      "source": [
        "# Ejemplo un poco más complejo de un GA que tiene que encontrar la cadena 'Hello Word!'\n",
        "# http://www.obitko.com/tutorials/genetic-algorithms/ga-basic-description.php\n",
        "\n",
        "import random\n",
        "\n",
        "class GeneticAlgorithm(object):\n",
        "    def __init__(self, genetics):\n",
        "        self.genetics = genetics\n",
        "        pass\n",
        "\n",
        "    def run(self):\n",
        "        population = self.genetics.initial()\n",
        "        while True:\n",
        "            fits_pops = [(self.genetics.fitness(ch),  ch) for ch in population]\n",
        "            if self.genetics.check_stop(fits_pops): break\n",
        "            population = self.next(fits_pops)\n",
        "            pass\n",
        "        return population\n",
        "\n",
        "    def next(self, fits):\n",
        "        parents_generator = self.genetics.parents(fits)\n",
        "        size = len(fits)\n",
        "        nexts = []\n",
        "        while len(nexts) < size:\n",
        "            parents = next(parents_generator)\n",
        "            cross = random.random() < self.genetics.probability_crossover()\n",
        "            children = self.genetics.crossover(parents) if cross else parents\n",
        "            for ch in children:\n",
        "                mutate = random.random() < self.genetics.probability_mutation()\n",
        "                nexts.append(self.genetics.mutation(ch) if mutate else ch)\n",
        "                pass\n",
        "            pass\n",
        "        return nexts[0:size]\n",
        "    pass\n",
        "\n",
        "class GeneticFunctions(object):\n",
        "    def probability_crossover(self):\n",
        "        # returns rate of occur crossover(0.0-1.0)\n",
        "        return 1.0\n",
        "\n",
        "    def probability_mutation(self):\n",
        "        # returns rate of occur mutation(0.0-1.0)\n",
        "        return 0.0\n",
        "\n",
        "    def initial(self):\n",
        "        # returns list of initial population        \n",
        "        return []\n",
        "\n",
        "    def fitness(self, chromosome):\n",
        "        # returns domain fitness value of chromosome\n",
        "        return len(chromosome)\n",
        "\n",
        "    def check_stop(self, fits_populations):\n",
        "        # stop run if returns True\n",
        "        # - fits_populations: list of (fitness_value, chromosome)\n",
        "        return False\n",
        "\n",
        "    def parents(self, fits_populations):\n",
        "        r\"\"\"generator of selected parents\n",
        "        \"\"\"\n",
        "        gen = iter(sorted(fits_populations))\n",
        "        while True:\n",
        "            f1, ch1 = next(gen)\n",
        "            f2, ch2 = next(gen)\n",
        "            yield (ch1, ch2)\n",
        "            pass\n",
        "        return\n",
        "\n",
        "    def crossover(self, parents):\n",
        "        r\"\"\"breed children\n",
        "        \"\"\"\n",
        "        return parents\n",
        "\n",
        "    def mutation(self, chromosome):\n",
        "        r\"\"\"mutate chromosome\n",
        "        \"\"\"\n",
        "        return chromosome\n",
        "    pass\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    example: Mapped guess prepared Text\n",
        "    \"\"\"\n",
        "    class GuessText(GeneticFunctions):\n",
        "        def __init__(self, target_text,\n",
        "                     limit=200, size=400,\n",
        "                     prob_crossover=0.9, prob_mutation=0.2):\n",
        "            self.target = self.text2chromo(target_text)\n",
        "            self.counter = 0\n",
        "\n",
        "            self.limit = limit\n",
        "            self.size = size\n",
        "            self.prob_crossover = prob_crossover\n",
        "            self.prob_mutation = prob_mutation\n",
        "            pass\n",
        "\n",
        "        # GeneticFunctions interface impls\n",
        "        def probability_crossover(self):\n",
        "            return self.prob_crossover\n",
        "\n",
        "        def probability_mutation(self):\n",
        "            return self.prob_mutation\n",
        "\n",
        "        def initial(self):\n",
        "            return [self.random_chromo() for j in range(self.size)]\n",
        "\n",
        "        def fitness(self, chromo):\n",
        "            # larger is better, matched == 0\n",
        "            return -sum(abs(c - t) for c, t in zip(chromo, self.target))\n",
        "\n",
        "        def check_stop(self, fits_populations):\n",
        "            self.counter += 1\n",
        "            if self.counter % 10 == 0:\n",
        "                best_match = list(sorted(fits_populations))[-1][1]\n",
        "                fits = [f for f, ch in fits_populations]\n",
        "                best = max(fits)\n",
        "                worst = min(fits)\n",
        "                ave = sum(fits) / len(fits)\n",
        "                print(\n",
        "                    \"[G %3d] score=(%4d, %4d, %4d): %r\" %\n",
        "                    (self.counter, best, ave, worst,\n",
        "                     self.chromo2text(best_match)))\n",
        "                pass\n",
        "            return self.counter >= self.limit\n",
        "\n",
        "        def parents(self, fits_populations):\n",
        "            while True:\n",
        "                father = self.tournament(fits_populations)\n",
        "                mother = self.tournament(fits_populations)\n",
        "                yield (father, mother)\n",
        "                pass\n",
        "            pass\n",
        "\n",
        "        def crossover(self, parents):\n",
        "            father, mother = parents\n",
        "            index1 = random.randint(1, len(self.target) - 2)\n",
        "            index2 = random.randint(1, len(self.target) - 2)\n",
        "            if index1 > index2: index1, index2 = index2, index1\n",
        "            child1 = father[:index1] + mother[index1:index2] + father[index2:]\n",
        "            child2 = mother[:index1] + father[index1:index2] + mother[index2:]\n",
        "            return (child1, child2)\n",
        "\n",
        "        def mutation(self, chromosome):\n",
        "            index = random.randint(0, len(self.target) - 1)\n",
        "            vary = random.randint(-5, 5)\n",
        "            mutated = list(chromosome)\n",
        "            mutated[index] += vary\n",
        "            return mutated\n",
        "\n",
        "        # internals\n",
        "        def tournament(self, fits_populations):\n",
        "            alicef, alice = self.select_random(fits_populations)\n",
        "            bobf, bob = self.select_random(fits_populations)\n",
        "            return alice if alicef > bobf else bob\n",
        "\n",
        "        def select_random(self, fits_populations):\n",
        "            return fits_populations[random.randint(0, len(fits_populations)-1)]\n",
        "\n",
        "        def text2chromo(self, text):\n",
        "            return [ord(ch) for ch in text]\n",
        "        def chromo2text(self, chromo):\n",
        "            return \"\".join(chr(max(1, min(ch, 255))) for ch in chromo)\n",
        "\n",
        "        def random_chromo(self):\n",
        "            return [random.randint(1, 255) for i in range(len(self.target))]\n",
        "        pass\n",
        "\n",
        "    GeneticAlgorithm(GuessText(\"Hello World!\")).run()\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs1CFgGip95-"
      },
      "source": [
        "\n",
        "\n",
        "Y ahora, vamos a verlo aplicado a una red neuronal. Para ello, vamos a hacer uso de una implementación disponible en Github: https://github.com/jliphard/DeepEvolve\n",
        "\n",
        "Para ello, vamos a clonar un repositorio con git que tiene implementado un GA para evolucionar los hiperparámetros y arquitectura de una red neuronal:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLw7kZ3KHpMU",
        "outputId": "502c886e-1282-4ce4-bb26-9f5afca7d99b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm -rf DeepEvolve\n",
        "!git clone https://github.com/jliphard/DeepEvolve.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepEvolve'...\n",
            "remote: Enumerating objects: 163, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 163 (delta 0), reused 0 (delta 0), pack-reused 160\u001b[K\n",
            "Receiving objects: 100% (163/163), 1.52 MiB | 7.34 MiB/s, done.\n",
            "Resolving deltas: 100% (84/84), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRYp-2pXH3Kq",
        "outputId": "92a04689-3f62-4e33-a25f-52aa4de1a2ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepEvolve  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oN1-i1hIDlT",
        "outputId": "69b6b9d3-0568-4ac8-a230-10cb31e691ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtNOyWqfJk_t"
      },
      "source": [
        "Quiero que veáis los parámetros entre los que va a buscar hasta encontrar la mejor combinación posible:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UAgRuhIJjLl"
      },
      "source": [
        "dataset='mnist_cnn'\n",
        "if dataset == 'mnist_cnn':\n",
        "        generations = 8 # Number of times to evolve the population.\n",
        "        all_possible_genes = {\n",
        "            'nb_neurons': [16, 32, 64, 128],\n",
        "            'nb_layers':  [1, 2, 3, 4 ,5],\n",
        "            'activation': ['relu', 'elu', 'tanh', 'sigmoid', 'hard_sigmoid','softplus','linear'],\n",
        "            'optimizer':  ['rmsprop', 'adam', 'sgd', 'adagrad','adadelta', 'adamax', 'nadam']\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCNfBWJHGkLF"
      },
      "source": [
        "Y ahora ejecutamos nuestro algoritmo genético:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48cjQV0TH8vj"
      },
      "source": [
        "!python DeepEvolve/main.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeFaymLsHqZZ"
      },
      "source": [
        "Y os recomiendo que le echéis un ojo a estos dos enlaces en los que evolucionan una red neuronal con un GA. Aquí no nos da tiempo, pero son muy interesantes:\n",
        "\n",
        "### Ejemplo GA para evolucionar NN: \n",
        "\n",
        "* https://blog.coast.ai/lets-evolve-a-neural-network-with-a-genetic-algorithm-code-included-8809bece164\n",
        "* https://github.com/harvitronix/neural-network-genetic-algorithm"
      ]
    }
  ]
}