{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ygX408AWx_J"
      },
      "source": [
        "# Módulo 3. Redes neuronales avanzadas\n",
        "\n",
        "¡Bienvenidos al tercer módulo! Tras el último módulo donde aprendimos como funcionan realmente las redes neuronales (espero que todos recordeis el backpropagation), en este módulo vamos a implementar y optimizar la segunda red neuronal, además de adentrarnos a la libreria keras, que nos facilitará mucho el desarrollo de redes neuronales. El índice que seguiremos es el siguiente:\n",
        "\n",
        "1. **División de los datos**\n",
        "\n",
        "2. **Librería keras**\n",
        "\n",
        "3. **Teoría de optimización. Gradient Descent (GD, SGD, Mini-batch GD).**\n",
        "\n",
        "4. **Optimización de hiperparámetros**\n",
        " <ul>\n",
        "   3.1 Learning rate\n",
        "\n",
        "   3.2 Batch-size\n",
        "\n",
        "   3.3\tFunciones de activación (relu, reakly relu, sigmoide, softmax)\n",
        "\n",
        "   3.4\tFunciones de pérdidas \n",
        "\n",
        "   3.5 Inicialización de los pesos\n",
        "   </ul>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. División de los datos\n",
        "\n",
        "En general, los algoritmos de Machine Learning aprenden de los datos con los que los entrenamos. A partir de ellos, intentan encontrar o inferir el patrón que les permita predecir el resultado para un nuevo caso. Pero, para poder calibrar si un modelo funciona, necesitaremos probarlo con un conjunto de datos **diferente**. ¿Qué pasaría si entrenamos y validamos el modelo con los mismos datos? Tendríamos, unos muy buenos resultados en la validación, pero realmente, ¿el modelo sería capaz de generalizar tan bien?\n",
        "\n",
        "Por tanto, en todo proceso de aprendizaje automático, los datos se deben dividir en tres partes: datos de entrenamiento, datos de validación y datos test.\n",
        "\n",
        "* **Entrenamiento**: son utilizados para actualizar los pesos cada batch.\n",
        "* **Validación**: comprueba la capacidad de generalización de la red en cada época-> prueba con muestras que no ha visto durante el entrenamiento, sirve para monitorizar el entrenamiento de la red a titulo informativo, pero, ¡no interviene en ningún cálculo! Suele emplearse cuando se quieren ajustar los parámetros, siendo este conjunto el que indica qué parámetros es mejor utilizar. A más accuracy en validación, mejor set de parámetros tenemos. Por este motivo, no podemos confiar en este resultado para hacernos una idea de la capacidad de generalización de la red, porque hemos elegido la configuración de la red para que nos de un accuracy más alto. Por lo cual, debemos tener un conjunto extra que nos permita, ahora sí, decir si nuestra red es buena con muestras que no haya visto nunca o no: el de test.\n",
        "\n",
        "* **Test**: nos da una intuición de lo buena que es nuestra red al generalizar con un conjunto (más grande que el de validación) nunca visto.\n",
        "\n",
        "Veamos las proporciones que se suelen utilizar de cada tipo:\n",
        "\n",
        "<center> <a href=\"https://ibb.co/0XgNYBV\"><img src=\"https://i.ibb.co/1nDVRsJ/particion-datos.png\" alt=\"IA engloba ML, que a su vez engloba DL\" border=\"0\"> </center> </a>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Para las implementaciones de las redes neuronales que vamos a realizar hoy, vamos a seguir trabajando con el set de datos **MNIST**. Como ya sabéis, el set de datos **MNIST** es un conjunto de  70000 imágenes de $28 \\times 28$ pixels que contienen números manuscritos junto con la etiqueta solución del número codificado (i.e. nuestro ground truth). Cabe destacar que, por convención, MNIST dispone de una división específica en conjuntos de entrenamiento, validación y test.  Así que sin más dilación vamos a cargar los datos y a visuar las particiones llevadas a cabo:\n"
      ],
      "metadata": {
        "id": "W4s8uG9vM0ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports necesarios\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Importamos el dataset MNIST y cargamos los datos\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15)\n",
        "\n",
        "# Comprobar el tamaño del dataset\n",
        "print(\"El conjunto de entrenamiento tiene dimensiones: \", x_train.shape)\n",
        "print(\"El conjunto de validación tiene dimensiones: \",x_val.shape)\n",
        "print(\"El conjunto de test tiene dimensiones: \",x_test.shape)\n",
        "\n",
        "# Método para visualizar los datos de entrenamiento\n",
        "def display_digit(num):\n",
        "  # Seleccionar la imagen num de imagenes de train\n",
        "  image = x_train[num,:,:]\n",
        "  # Seleccionar el target num de y_train (Recuerda que esta en one-hot encoding, conviertelo a decimal con argmax)\n",
        "  label = y_train[num] #(X)\n",
        "  # Mostrar\n",
        "  plt.title('Example: %d  Label: %d' % (num, label))\n",
        "  plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
        "  plt.show()\n",
        "\n",
        "# Mostramos algunos ejemplos\n",
        "display_digit(np.random.randint(0, x_train.shape[0]))\n",
        "display_digit(np.random.randint(0, x_train.shape[0]))\n",
        "display_digit(np.random.randint(0, x_train.shape[0]))\n",
        "\n",
        "# Ejecuta el código varias veces y comprueba la variabilidad existente en los datos"
      ],
      "metadata": {
        "id": "ybWuUmKZM4rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez visualizadas ciertas muestras de nuestro conjunto de datos,  vamos a volver a entrenar el **perceptrón simple** de la sesión anterior teniendo en cuenta el conjunto de entrenamiento, validación y test. Recordad que en el perceptrón simple las entradas se ponderan por ciertos pesos y se suman en cada una de las neuronas de salida. Posteriormente emplearemos la función **Softmax** que hemos explicado en la sesión teórica, calculando las predicciones como $\\hat{Y}=softmax(X∗W+B)$ y minimizando la función de entropía cruzada o **cross-entropy** siguiendo la formula: \n",
        "\n",
        ">>>>>>>>$Coste = - \\displaystyle\\sum_j y_j log(p_j)$\n",
        "\n",
        "donde $y_j$ es el *ground truth* para la clase $j$ y $p_j$ el valor de probabilidad asignado a dicha clase a la salida."
      ],
      "metadata": {
        "id": "z6MsViQqH6t0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiper-parámetros de nuestra red\n",
        "lr = 0.01\n",
        "n_epochs = 20\n",
        "batch_size = 128\n",
        "\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255.\n",
        "x_val= x_val / 255.\n",
        "\n",
        "\n",
        "# 1. Convertimos las imágenes a vectores, dado que aún no hemos visto cómo podemos implementar un modelo que trabaje con imágenes\n",
        "x_train = tf.reshape(x_train, shape=(51000, -1)) # Nuestros datos ya están en formato [N_instancias, variables] (60000 instancias, 784 (28+28) pixels).\n",
        "x_val = tf.reshape(x_val, shape=(9000, -1)) # Nuestros datos ya están en formato [N_instancias, variables] (9000 instancias, 784 (28+28) pixels).\n",
        "x_test = tf.reshape(x_test, shape=(10000, -1)) # Nuestros datos ya están en formato [N_instancias, variables] (10000 instancias, 784 (28+28) pixels).\n",
        "\n",
        "\n",
        "# 2. Convertimos las etiquetas a one-hot y a float 64 ya que todos los datos deben estar en el mismo formato\n",
        "\n",
        "#Datos a one-hot-encoding\n",
        "y_train = tf.one_hot(y_train, depth=10)\n",
        "y_val = tf.one_hot(y_val, depth=10)\n",
        "y_test = tf.one_hot(y_test, depth=10)\n",
        "\n",
        "#Datos en el mismo formato\n",
        "y_train = tf.cast(y_train, 'float64')\n",
        "y_val= tf.cast(y_val, 'float64')\n",
        "y_test = tf.cast(y_test, 'float64')\n",
        "\n",
        "#3. Nos creamos ahora el iterador para que recorra nuestro dataset. Podéis leer más sobre tf.data aquí: https://www.tensorflow.org/guide/data\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_ds = train_ds.shuffle(10000).batch(batch_size)\n",
        "\n",
        "\n",
        "#4. Calculamos las iteraciones por época\n",
        "total_batch = x_train.shape[0] // batch_size\n",
        "\n",
        "#5. Creamos e inicializamos con ceros las variables W y b\n",
        "W = tf.zeros([784, 10], tf.double)\n",
        "b = tf.zeros([10], tf.double)\n",
        "\n",
        "# para almacenar el histórico de costes\n",
        "acc_epoch_tr = []\n",
        "acc_epoch_val = []\n",
        "loss_epoch_tr = []\n",
        "loss_epoch_val = []\n",
        "\n",
        "# entrenamiento de nuestra red\n",
        "for epoch in range(n_epochs):\n",
        "    avg_loss = 0.\n",
        "    avg_acc = 0.\n",
        "    \n",
        "    for batch_xs, batch_ys in train_ds:\n",
        "        # Empezamos con la optimización\n",
        "        # haremos uso de tf.GradientTape, que lleva un control de las variables\n",
        "        # para poder calcular sus gradientes\n",
        "        with tf.GradientTape() as tape:\n",
        "            # le indicamos que \"vigile\" las variables a optimizar\n",
        "            tape.watch(W)\n",
        "            tape.watch(b)\n",
        "            \n",
        "            # ejecutamos el modelo\n",
        "            pred = tf.nn.softmax(tf.matmul(batch_xs, W) + b)\n",
        "            # calculamos el accuracy (precisión)\n",
        "            correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(batch_ys, 1))\n",
        "            acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "            # Ahora, definimos nuestra función de pérdidas: esta vez, la cros-entropía\n",
        "            cost = tf.reduce_mean(-tf.reduce_sum(batch_ys*tf.math.log(pred), axis=1))\n",
        "            # calculamos los gradientes (gradient descent)\n",
        "            grad_W, grad_b = tape.gradient(cost, [W, b])\n",
        "\n",
        "            # definimos las operaciones para actualizar los pesos con los gradientes calculados\n",
        "            # y el learning rate\n",
        "            W = W - lr * grad_W\n",
        "            b = b - lr * grad_b\n",
        "\n",
        "        # calculamos las perdidas y el accuracy teniendo en cuenta los batches que hay\n",
        "        avg_loss += cost / total_batch\n",
        "        avg_acc += acc / total_batch\n",
        "        \n",
        "    # Validamos el modelo en cada época\n",
        "    ## Code ##\n",
        "    # calculamos el accuracy (precisión)\n",
        "    print(tf.argmax(pred, 1))\n",
        "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y_val, 1))\n",
        "    acc_val = ## Code ##\n",
        "    # Ahora, definimos nuestra función de pérdidas: esta vez, la cros-entropía\n",
        "    loss_val = ## Code ##\n",
        "    # guardamos nuestro coste en el histórico\n",
        "    loss_epoch_tr.## Code ##\n",
        "    acc_epoch_tr.## Code ##\n",
        "    loss_epoch_val.## Code ##\n",
        "    acc_epoch_val.## Code ##\n",
        "\n",
        "    # imprimimos las iteraciones\n",
        "    print(\"[INFO]: Época {} ---> Acc_train = {} - Loss_train = {} - Acc_val = {} - Loss_val = {}\".format(epoch, avg_acc, avg_loss, acc_val, loss_val))\n",
        "\n",
        "\n",
        "print(\"Entrenamiento finalizado!!\")\n",
        "\n",
        "\n",
        "# Comprobamos lo que ha aprendido nuestra red testeando el modelo\n",
        "pred = ## Code ##\n",
        "correct_prediction = ## Code ##\n",
        "\n",
        "# calculamos el accuracy (precisión)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(\"Accuracy en test:\", accuracy.numpy())\n",
        "\n",
        "# Gráficar losses por época\n",
        "plt.plot(np.arange(0, n_epochs), loss_epoch_tr)\n",
        "plt.plot(np.arange(0, n_epochs), loss_epoch_val)\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('Loss')"
      ],
      "metadata": {
        "id": "9ckCqCz8H0Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Librería Keras\n",
        "Después de trabajar durante estas sesiones con la librería de bajo nivel denominada TensorFlow, en el presente módulo se va a introducir un framework de alto nivel para el entrenamiento de redes neuronales denominado **Keras**. Esta librería fue desarrollada por **François Chollet** en 2015 con el objetivo de **simplificar la programación de algoritmos basados en aprendizaje profundo** ofreciendo un conjunto de abstracciones más intuitivas y de alto nivel. Keras hace uso de librerías de más bajo nivel o ***backend*** por detrás, concretamente se puede escoger entre **TensorFlow,  Microsoft Cognitive Toolkit o Theano**. Durante las siguientes sesiones haremos uso de la librería Keras con TensorFlow como backend.\n",
        "\n",
        "Cabe destacar que en keras, existen dos formas de generar la arquitectura de un modelo:\n",
        "\n",
        "*   **Modo (o API) secuencial**: Se instancia un objeto del tipo Model y a este se le van añadiendo las capas que conforman la arquitectura una\n",
        "detrás de otra.\n",
        "\n",
        "*   **Modo (o API) funcional**: Se define una entrada y a partir de las mismas\n",
        "se va definiendo la arquitectura indicando cuál es la entrada a cada\n",
        "capa) Una vez definida la arquitectura se crea el objeto modelo\n",
        "pasándole las entradas y las salidas (última capa definida).\n"
      ],
      "metadata": {
        "id": "8DdPJ1zcJQF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar y con el objetivo de familiarizarnos con esta nueva librería, el primer ejercicio de esta sección consistirá en replicar el perceptron simple desarrollado en el último ejercicio (pero esta vez **empleando Keras** en vez de TensorFlow.  Si recordaís  el objetivo que perseguía la práctica anterior era el de **clasificar el dataset de dígitos manuscritos denominado MNIST**, así que vamos a ello:"
      ],
      "metadata": {
        "id": "5dA0Mo1pJ4cm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como siempre, lo primero que tenemos que hacer es cargar los datos:"
      ],
      "metadata": {
        "id": "GIGXtLhuMQYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import ## Code ##\n",
        "\n",
        "# Importamos el dataset MNIST desde Keras datasets y cargamos los datos #(X)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_te, y_te) = mnist.load_data()\n",
        "# Normalizamos los datos en el rango de 0-1 para que computacionalmente sea más eficiente el proceso #(X)\n",
        "x_train, x_te = x_train / 255.0, x_te / 255.0\n",
        "# Pasamos a etiquetas one-hot encoded #(X)\n",
        "y_train = ## Code ##\n",
        "y_te = ## Code ##\n",
        "# Dividimos el conjunto de training en training y validation #(X)\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "pVLy0tDUJFPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A contiuación, vamos a entrenar un **perceptrón simple**  **empleando Keras**. Para está primera implementación utilizando el framework de Keras, emplearemos las siguientes herramientas:\n",
        "\n",
        "- Construcción de la arquitectura: API Sequential, Capa Flatten y capa Dense\n",
        "- Compilar modelo y entrenarlo empleando como optimizador el SGD: Métodos ```compile``` y ```fit``` del objeto de la clase Sequential.\n",
        "- Con el modelo ya entrenado, obtener las predicciones para el subset de test mediante la instrucción ```predict``` del objeto de la clase Sequential.\n",
        "- Evaluar el performance del modelo empleando el método ```classification_report``` de la librería **scikit-learn**.\n",
        "- Gráficar las curvas de entrenamiento (losses y accuracy) para monitorizar dicho proceso.\n"
      ],
      "metadata": {
        "id": "FKFa5kd3MaWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports necesarios\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import ## Code ##\n",
        "from tensorflow.keras.layers import ## Code ##\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Hiper-parámetros de nuestra red\n",
        "lr = 0.005\n",
        "n_epochs = 20\n",
        "batch_size = 128\n",
        "\n",
        "# Implementamos la red empleando Keras\n",
        "## Code ## # Instancia de modelo API secuencial #(X)\n",
        "## Code ## # Estiramos los datos en forma de vector como entrada a nuestro Perceptrón Simple #(X)\n",
        "## Code ## # Construimos nuestro Perceptrón simple con una única capa Dense #(X)\n",
        "\n",
        "# Compilamos y entrenamos el modelo SGD\n",
        "print(\"[INFO]: Entrenando red neuronal...\")\n",
        "## Code ##\n",
        "## Code ##\n",
        "\n",
        "# Evaluando el modelo de predicción con las imágenes de test\n",
        "print(\"[INFO]: Evaluando red neuronal...\")\n",
        "## Code ##\n",
        "print(classification_report(y_te.argmax(axis=1), predictions.argmax(axis=1)))\n",
        "\n",
        "# Muestro gráfica de accuracy y losses\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, n_epochs), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, n_epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, n_epochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, n_epochs), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "Og2BPdoUMXjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementamos la red empleando Keras (modelo funcional)\n",
        "# Imports necesarios\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.layers import ## Code ##\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Hiper-parámetros de nuestra red\n",
        "lr = 0.005\n",
        "n_epochs = 20\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "# Implementamos la red empleando Keras (modelo funcional)\n",
        "## Code ##\n",
        "## Code ##\n",
        "## Code ##\n",
        "\n",
        "# Compilamos y entrenamos el modelo SGD\n",
        "print(\"[INFO]: Entrenando red neuronal...\")\n",
        "## Code ##\n",
        "## Code ##\n",
        "\n",
        "# Evaluando el modelo de predicción con las imágenes de test\n",
        "print(\"[INFO]: Evaluando red neuronal...\")\n",
        "## Code ##\n",
        "print(classification_report(y_te.argmax(axis=1), predictions.argmax(axis=1)))\n",
        "\n",
        "# Muestro gráfica de accuracy y losses\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, n_epochs), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, n_epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, n_epochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, n_epochs), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "XKYCCyXRlJJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY275LXJXeTK"
      },
      "source": [
        "\n",
        "\n",
        "## 2 Teoría de optimización: Gradient Descent, Stochastic Gradient Descent, Mini-batch Gradient Descent\n",
        "\n",
        "Ayer estuvimos viendo cómo funciona el gradient descent, os acordáis, ¿verdad? En la clase de hoy, vamos a ver diferentes formas de utilizar el gradient descent para ganar velocidad.\n",
        "\n",
        "Para ello, vamos a recordar brevemente como funciona el descenso de gradiente:  1) Calculo del error de todas las muestras del set de training 2) actualizar los pesos en la dirección que indica el gradiente respecto a cada uno de ellos. Por tanto, necesitamos, **para cada época, calcular todas las predicciones (etapa forward), luego los errores, y luego propagar los errores hacia atrás para ver cuánto influye cada peso en ese error y actualizarlo en consecuencia.**\n",
        "\n",
        "Imaginaos que:\n",
        "\n",
        "* tenemos un dataset de **100.000 muestras**\n",
        "* que cada etapa forward tarda **2ms**\n",
        "* cada cálculo del error **1ms**\n",
        "* cada etapa de backpropagation tarda **3ms**\n",
        "\n",
        "Si hacemos el cálculo, tenemos que:\n",
        "\n",
        "**Tiempo por época** $= (2ms+1ms+3ms)·100.000$ muestras $= 600.000ms = 600$ segundos $=$ **10 minutos**\n",
        "\n",
        "De normal, una red puede requerir cientos, si no miles de épocas, para conseguir una convergencia adecuada. Pongamos que necesitamos 100 épocas, que es un número bajo. ¿Cuánto tardaría en total en entrenarse la red?\n",
        "\n",
        "**Tiempo total de entrenamiento** $=10$ minutos $· 100$ épocas $= 1.000$ minutos $=$ **16'6 horas !!!**\n",
        "\n",
        "No parece muy cómodo tener que esperar más de 16 horas para ver los resultados de una red, ¿verdad? Y hemos sido cautos suponiendo que teníamos solo 100.000 muestras. Como ya hemos visto anteriormente, ImageNet, por ejemplo, consta de 1.2 millones de imágenes, lo que nos costaría 2h por época, o lo que es lo mismo, 8.3 días, **más de una semana para ver el comportamiento de una red.** ¿Se os ocurre alguna forma de disminuir este tiempo?\n",
        "\n",
        "Una forma de reducir drásticamente el tiempo necesario sería utilizar una sola muestra escogida aleatoriamente cada vez que quisieramos actualizar los pesos. De esta forma, para actualizar los pesos simplemente tendríamos que calcular las predicciones, errores y backpropagation de una muestra. Esto reduciría nuestro tiempo total a:\n",
        "\n",
        "**Tiempo total de entrenamiento** $=(2ms+1ms+3ms)·1$ muestra $·100$ épocas $= 600ms = $ **0,6s**\n",
        "\n",
        "### ¡Qué maravilla! ¡Acabamos de arreglar el mundo!\n",
        "\n",
        "A este método se le conoce como **Stochastic Gradient Descent**, y estoy seguro de que todos vosotros os habéis dado cuenta de que tiene una **desventaja MUY IMPORTANTE**. ¿Quién me la dice?\n",
        "\n",
        "Os voy a dar una pista:\n",
        "\n",
        "### ¿Cuál creéis que es el camino seguido por el Gradient Descent, y cuál el seguido por el Stochastic Gradient Descent?\n",
        "<img src=\"https://image.ibb.co/hiK2BT/mountain_gd_sgd_mbsgd_hidden.png\" alt=\"mountain_gd_sgd_mbsgd_hidden\" border=\"0\">\n",
        "<!--\n",
        "<img src=\"https://image.ibb.co/n2RFWT/mountain_gd_sgd_mbsgd.png\" alt=\"mountain_gd_sgd_mbsgd\" border=\"0\">\n",
        "<!-- <img src=\"https://image.ibb.co/jZHNBT/contours_gd_sgd_mbsgd.png\" alt=\"contours_gd_sgd_mbsgd\" border=\"0\"> -->\n",
        "\n",
        "El camino rojo es el que sigue el gradient descent, que al calcular el gradiente usando todas las muestras del dataset consigue unas actualizaciones coherentes siempre en la dirección que permite minimizar el error.\n",
        "\n",
        "Y si! El camino magenta es el seguido por el SGD. ¿Qué es lo que está pasando? Cada actualización de los pesos se hace para minimizar el error teniendo en cuenta solo una muestra, así que lo que minimizamos es el error para esa muestra en particular. Por eso, tiene un comportamiento más caótico y le cuesta más converger, aunque, a cambio, se ejecuta mucho más rápido, por lo que en el tiempo que el GD necesita para ejecutar una época, el SGD puede ejecutar miles.\n",
        "\n",
        "**Como siempre, la virtud se encuentra en el término medio. ¿Véis la linea verde, verdad? ¡Esa es la buena! ¿Cómo llegamos a ella?**\n",
        "\n",
        "Bueno, vamos a pensar qué tenemos hasta ahora. Tenemos:\n",
        "\n",
        "* Un método que calcula las predicciones y errores de **todos** los elementos de nuestro training set: **(Vanilla) Gradient Descent**\n",
        "* Un método que calcula las predicciones y errores de **1 elemento** escogido aleatoriamente de nuestro training set: **Stochastic Gradient Descent**\n",
        "\n",
        "¿Qué os parecería que en vez de **1 solo elemento**, escogiésemos **N elementos**? De esta forma:\n",
        "\n",
        "* Aumentamos la **estabilidad** del algoritmo, ya que no solo nos fijamos en un solo elemento, sino en $k$ (es decir, disminuímos los cambios de dirección tan abruptos y caóticos que tiene la línea magenta).\n",
        "* Disminuimos el **tiempo de ejecución** con respecto al gradient descent tradicional, pues pasamos de las $N$ muestras que tiene nuestro training set, a $k$, donde $k << N$.\n",
        "\n",
        "Parece una alternativa interesante, ¿no creéis? Este método se conoce como **Mini-batch Stochastic Gradient Descent**, y es realmente el que se utiliza en la práctica.\n",
        "\n",
        "Normalmente, $k$ se elige para que sea una potencia de 2, ya que eso permite aprovechar algunas optimizaciones que tienen las GPUs implementadas para estos casos. Un $k$ típico podría ser $k=32$, pero al final esto lo limita la memoria de la GPU.\n",
        "\n",
        "Cuanto más bajo sea $k$, más se parecerá al SGD puro, y más épocas le costará converger, aunque también es verdad que las calculará más rápido.\n",
        "\n",
        "Y a la inversa, cuanto más alto sea $k$, más se parecerá al GD puro, y más le costará calcular cada época, pero necesitará menos para converger.\n",
        "\n",
        "### Pues con esto ya lo sabéis todo sobre el Gradient Descent y los diferentes tipos de implementaciones!\n",
        "\n",
        "Vamos a ver ahora qué es el learning rate y el batch size, y cómo influyen.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4xcQlXrEZIR"
      },
      "source": [
        "## 3 Optimización de hiperparámetros\n",
        "\n",
        "De entre todos los hiperparámetros, el learning rate y el batch size son dos parámetros directamente relacionados con el algoritmo del gradient descent. A continuación, vamos a explicar todos los hiperparámetros que influyen en el entrenamiento de una red neuronal y cómo afectan.\n",
        "\n",
        "### 3.1 Learning rate\n",
        "\n",
        "Como ya sabéis de la anterior sesión, la forma de actualizar los pesos es mediante estas fórmulas:\n",
        "\n",
        "<center><img src=\"https://image.ibb.co/jMmHRT/net_weights_update.png\" alt=\"net_weights_update\" border=\"0\" height=\"250\"></center>\n",
        "\n",
        "¿Os acordáis, verdad? Lo que multiplica al $\\frac{\\partial E_{total}}{\\partial w_n}$, llamado $\\eta$, es el **learning rate**, que es lo que indica **la importancia** que le damos al error para actualizar cada peso, es decir, la **rapidez** o cómo de abruptos son los cambios en los pesos.\n",
        "\n",
        "Así, un $\\eta$ muy alto, hará que los cambios en los pesos sean muy grandes de una iteración a otra, lo que tiene el problema de que podemos llegar a saltarnos nuestro mínimo.\n",
        "\n",
        "Fijaos, con esta imagen se ve estupendamente:\n",
        "\n",
        "<img src=\"https://image.ibb.co/ncnAY8/learning_rate_eta.png\" alt=\"learning_rate_eta\" border=\"0\" height=\"150\">\n",
        "\n",
        "Otra posibilidad es establecer un $\\eta$ muy bajo, lo que haría que nuestra red necesitara muchísimas épocas para llegar a un mínimo aceptable. Además, correríamos el riesgo de quedarnos atrapados en un mínimo peor del mejor que podríamos conseguir con un $\\eta$ más alto.\n",
        "\n",
        "<img src=\"https://image.ibb.co/frt3Lo/learning_rate_eta_low.gif\" alt=\"learning_rate_eta_low\" border=\"0\" height=\"200\">\n",
        "\n",
        "Vamos a hacer un pequeño inciso para hablar sobre los mínimos: lo que conseguimos con una **red neuronal**, normalmente, no es alcanzar el mínimo global de nuestra función, sino que **alcanzamos un mínimo local lo suficientemente bueno como para realizar correctamente la tarea que estamos desarrollando**.\n",
        "\n",
        "Tras haber aclarado esto, queda patente lo importante que es conseguir un learning rate adecuado, ¿verdad? Y, ¿cómo lo hacemos? Primero, ¿qué es lo que buscamos? Fijaos en esta imagen:\n",
        "\n",
        "<img src=\"https://image.ibb.co/heYQY8/learning_rate_eta_graph.png\" alt=\"learning_rate_eta_graph\" border=\"0\" height=\"250\">\n",
        "\n",
        "Lo que queremos es un *learning rate* óptimo, que nos permita ir reduciendo el error conforme van pasando las épocas, hasta llegar a nuestro mínimo buscado. En la gráfica, este *learning rate* sería la línea roja. ¿Y cómo conseguimos que nuestro learning rate sea el óptimo?\n",
        "\n",
        "Pues una opción muy utilizada es aplicar un **decrecimiento** o *decay* a nuestro learning rate **conforme más va disminuyendo la función de pérdidas** (lo que indica que estamos llegando al mínimo buscado).\n",
        "\n",
        "<img src=\"https://image.ibb.co/mdBUt8/learning_rate_eta_decreasing.png\" alt=\"learning_rate_eta_decreasing\" border=\"0\" height=\"250\">\n",
        "\n",
        "De esta forma, evitamos morirnos de viejos esperando a que converja por haber elegido un learning rate muy bajito, y evitamos saltarnos nuestro mínimo porque cuanto más cerca estamos de él más pequeños son los pasos que damos hacia él.\n",
        "\n",
        "Vamos a ver cómo se comportaría la última red que implementamos (la que trabajaba con el MNIST) con **diferentes learning rates**. \n",
        "\n",
        "Además vamos a aprovechar este ejercicio para convertir nuestro código dejado caer en un script a una función cuya cabecera será la siguiente:\n",
        "\n",
        "def train_network(learning_rate, batch_size, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fljl_4hQSw27"
      },
      "source": [
        "# Ejemplos learning rate\n",
        "\n",
        "# En primer lugar, hacemos los imports necesarios y después definimos una \n",
        "# función que creará y entrenará la red\n",
        "\n",
        "# Importamos el dataset MNIST desde Keras datasets y cargamos los datos #(X)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_te, y_te) = mnist.load_data()\n",
        "# Normalizamos los datos en el rango de 0-1 para que computacionalmente sea más eficiente el proceso #(X)\n",
        "x_train, x_te = x_train / 255.0, x_te / 255.0\n",
        "# Pasamos a etiquetas one-hot encoded #(X)\n",
        "y_train = to_categorical(y_train)\n",
        "y_te = to_categorical(y_te)\n",
        "# Dividimos el conjunto de training en training y validation #(X)\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTUePZxVMxEc"
      },
      "source": [
        "# Definimos la función para entrenar nuestra red con los parámetros deseados\n",
        "def train_network(learning_rate, batch_size, num_epochs):\n",
        "  \n",
        "  # Implementamos la red empleando Keras\n",
        "  model = Sequential() # Instancia de modelo API secuencial #(X)\n",
        "  model.add(Flatten()) # Estiramos los datos en forma de vector como entrada a nuestro Perceptrón Simple #(X)\n",
        "  model.add(Dense(10, input_shape=(784,), activation=\"softmax\")) # Construimos nuestro Perceptrón simple con una única capa Dense #(X)\n",
        "  # Compilamos y entrenamos el modelo SGD\n",
        "  print(\"[INFO]: Entrenando red neuronal...\")\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(learning_rate), metrics=[\"accuracy\"])  #(X)\n",
        "\n",
        "  # Entrenando la solución\n",
        "  H = model.fit(x_tr, y_tr, validation_data=(x_val, y_val), epochs=num_epochs, batch_size=batch_size)  #(X)\n",
        "\n",
        "  # Evaluando el modelo de predicción con las imágenes de test\n",
        "  print(\"[INFO]: Evaluando red neuronal...\")\n",
        "  predictions = model.predict(x_te, batch_size=batch_size)  #(X)\n",
        "  print(classification_report(y_te.argmax(axis=1), predictions.argmax(axis=1)))\n",
        "\n",
        "  # Muestro gráfica de accuracy y losses\n",
        "  plt.style.use(\"ggplot\")\n",
        "  plt.figure()\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"loss\"], label=\"train_loss\")\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "  plt.title(\"Training Loss and Accuracy\")\n",
        "  plt.xlabel(\"Epoch #\")\n",
        "  plt.ylabel(\"Loss/Accuracy\")\n",
        "  plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jw55ghdTl5p"
      },
      "source": [
        "Los valores típicos de learning rate suelen ser: \n",
        "\n",
        "* 0.1\n",
        "* 0.01\n",
        "* 0.001\n",
        "\n",
        "A partir de ahí, nos toca a nosotros *tunear* el learning rate según lo que veamos que ocurre."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZIML54DSR5C"
      },
      "source": [
        "# vamos a probar con un learning rate ENORME\n",
        "learning_rate = ## Code ##\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "## Code ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBUt9cbKUJ8r"
      },
      "source": [
        "En este caso, incluso escogiendo un learning rate que debería hacerlo explotar todo, la red puede llegar a converger. Esto se debe a que es un problema muy sencillo, pero no pasaría igual si estuvieramos trabajando con otro problema más real, como comprobaréis en la próxima sesión.\n",
        "\n",
        "Pero como os digo, está al limite: si lo reejecutáis, os dará valores distintos, siendo lo más normal que no logre converger (aparecería `nan` como salida). Esta variabilidad se debe a que el cargador de datos aleatoriza las imágenes en cada ejecución, y el orden en que la red ve las imágenes le hace converger o no.\n",
        "\n",
        "Veamos qué ocurre cuando disminuímos el learning rate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBvWZAZuUIeX"
      },
      "source": [
        "# vamos a probar con 0.1\n",
        "learning_rate =## Code ##\n",
        "n_epochs = 10\n",
        "batch_size = 128\n",
        "train_network(learning_rate, batch_size, n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpvEdeDxVZ9f"
      },
      "source": [
        "# y ahora con uno muy pequeño\n",
        "learning_rate = ## Code ##\n",
        "n_epochs = 10\n",
        "batch_size = 128\n",
        "train_network(learning_rate, batch_size, n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmzelwmxdnfH"
      },
      "source": [
        "Como podéis comprobar, en este caso las pérdidas van disminuyendo paulatinamente, pero tan despacio, que podría llevarnos horas conseguir la solución que hemos alcanzado con un learning rate adecuado en solo 10 épocas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUZYyV6rV6yh"
      },
      "source": [
        "Bueno, pues la mejor ejecución la hemos conseguido con learning rate = 0.1. Pero... ¿se puede mejorar?\n",
        "\n",
        "Como podréis imaginaros, el learning rate es un parámetro muy importante. Ya hemos visto antes que si ponemos un learning rate muy alto, podemos saltarnos el mínimo. En cambio, si ponemos un learning rate muy bajo, igual nos morimos de viejos antes de ver el resultado. ¿Cómo podemos arreglar esto? Pues una forma sería dar pasos más grandes al principio, y conforme nos aproximamos a la meta, empezar a disminuir su longitud para no pasárnosla, ¿no os parece?\n",
        "\n",
        "Pues esto mismo se llama learning rate *decay*. A continuación vamos a implementar el standard \"decay\" de keras. De esa forma, se esablece que nuestro decaimiento  sea la tasa de aprendizaje dividida por el número total de épocas para las que estamos entrenando la red (una regla general común).\n",
        "\n",
        "Internamente, Keras aplica el siguiente programa de tasa de aprendizaje para ajustar la tasa de aprendizaje después de cada actualización por lotes.\n",
        "\n",
        "La actualizació sigue la siguiente fórmula:\n",
        "\n",
        "lr = init_lr * 1 / (1 + decay * iteraciones)\n",
        "\n",
        "¿Qué os parece si lo implementamos en nuestro ejemplo?\n",
        "\n",
        "Vamos allá!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je-NzPCRWdso"
      },
      "source": [
        "# definimos la función para entrenar nuestra red con los parámetros deseados\n",
        "def train_network_decay(learning_rate, lr_decay, batch_size, num_epochs):\n",
        "  \n",
        "  # Implementamos la red empleando Keras\n",
        "  model = Sequential() # Instancia de modelo API secuencial #(X)\n",
        "  model.add(Flatten()) # Estiramos los datos en forma de vector como entrada a nuestro Perceptrón Simple #(X)\n",
        "  model.add(Dense(10, input_shape=(784,), activation=\"softmax\")) # Construimos nuestro Perceptrón simple con una única capa Dense #(X)\n",
        "  # Compilamos y entrenamos el modelo SGD\n",
        "  print(\"[INFO]: Entrenando red neuronal...\")\n",
        "  ## Code ##\n",
        "\n",
        "  # Entrenando la solución\n",
        "  H = model.fit(x_tr, y_tr, validation_data=(x_val, y_val), epochs=num_epochs, batch_size=batch_size) \n",
        "\n",
        "  # Evaluando el modelo de predicción con las imágenes de test\n",
        "  print(\"[INFO]: Evaluando red neuronal...\")\n",
        "  predictions = model.predict(x_te, batch_size=batch_size)  \n",
        "  print(classification_report(y_te.argmax(axis=1), predictions.argmax(axis=1)))\n",
        "\n",
        "  # Muestro gráfica de accuracy y losses\n",
        "  plt.style.use(\"ggplot\")\n",
        "  plt.figure()\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"loss\"], label=\"train_loss\")\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "  plt.title(\"Training Loss and Accuracy\")\n",
        "  plt.xlabel(\"Epoch #\")\n",
        "  plt.ylabel(\"Loss/Accuracy\")\n",
        "  plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1S_x06lZRHQ"
      },
      "source": [
        "# vamos a probar nuestra red con decay\n",
        "learning_rate = 0.2\n",
        "lr_decay = ## Code ##\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "## Code ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHrdVpJDWcxE"
      },
      "source": [
        "Fijaos que con esta simple mejora, hemos sido capaces de mejorar la precisión un poco con respecto al learning rate óptimo, que habíamos definido como 0.1. Y existen métodos más complejos de aplicar el *decay* que producen mejores resultados.\n",
        "\n",
        "**Así que ya sabéis, ¡¡mucha atención al learning rate!!**\n",
        "\n",
        "**IMPORTANTE**: Cabe decir que esta implementación de learning rate *decay* es muy básico. En realidad existen distintos tipos de \"calendarios\" de actualización de learning rate: de escalón, polinomial, etc. Al final, lo que hacen todos es modificar el learning rate de acuerdo a una ecuación o regla.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlXGxShTMytR"
      },
      "source": [
        "### 3.2 Batch size\n",
        "\n",
        "Vamos a ver ahora qué es el **batch size**. ¿Recordáis cuando hemos hablado antes del SGD y el Mini-batch SGD? \n",
        "\n",
        "Recordad que el SGD es un Mini-bacth SGD donde $k=1$.\n",
        "\n",
        "Y que en el Mini-bacth SGD, la $k$ indica el número de muestras que se utilizan para actualizar los pesos cada vez. Realmente, este no es un parámetro crítico y se suele establecer como el **número máximo de muestras potencia de 2 que caben en nuestra GPU**.\n",
        "\n",
        "Ejemplos:\n",
        "\n",
        "* Tenemos una GPU con 8GB de memoria, cuantas muestras nos caben si cada imagen ocupa 1MB?\n",
        "\n",
        "Bueno, ¡pues no es tan fácil! Resulta que depende de la arquitectura de la red. Las capas *Densas* o *Fully Connected*, que son las tradicionales en las que todas las neuronas se interconectan con todas las neuronas de la siguiente capa, son las que **más parametros tienen**, y por consiguiente, las que **más memoria ocupan**.\n",
        "\n",
        "Luego tambien tenemos capas convolucionales, de pooling, de dropout, y de muchos otros tipos. Así que en la práctica, es difícil calcular a mano cual es el número máximo de muestras que podemos usar.\n",
        "\n",
        "Lo que se hace es probar con tamaños de batch potencia de 2 e ir disminuyéndolo si tenemos un error de memoria. Por ejemplo, podríamos empezar con 512, y si nos da error ir bajando a 256, 128, 64, 32, 16, 8, 4, 2 e incluso 1. Dependiendo de la arquitectura de nuestra red, puede llegar a pasarnos que tengamos que usar $k=1$, y por tanto, SGD.\n",
        "\n",
        "Aunque muchas veces es preferible disminuir el tamaño de la imagen, por ejemplo, de 512x512 a 256x256 o 128x128 pixels, y usar un $k$ mayor.\n",
        "\n",
        "Yo por ejemplo he tenido que usar $k=1$ con imágenes de 512x512 y la arquitectura DenseNet. **Y no hay problema**, simplemente tarda **más tiempo** en llegar a una solución adecuada.\n",
        "\n",
        "Vamos a ver algunos casos de diferentes bath size siguiendo con el ejemplo anterior:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZLOQ3nTO_bj"
      },
      "source": [
        "# con batch_size = 2048\n",
        "learning_rate = 1.\n",
        "lr_decay = 1e-3\n",
        "n_epochs = 10\n",
        "batch_size = ## Code ##\n",
        "train_network_decay(learning_rate, lr_decay, batch_size, n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ6v_fDqPVSa"
      },
      "source": [
        "# con batch_size = 256\n",
        "learning_rate = 1.\n",
        "lr_decay = 1e-3\n",
        "n_epochs = 10\n",
        "batch_size = ## Code ##\n",
        "train_network_decay(learning_rate, lr_decay, batch_size, n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck_evhpWPc8u"
      },
      "source": [
        "# con batch_size = 32\n",
        "learning_rate = 1.\n",
        "lr_decay = 1e-3\n",
        "n_epochs = 10\n",
        "batch_size = ## Code ##\n",
        "train_network_decay(learning_rate, lr_decay, batch_size, n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5NefVp8fPTi"
      },
      "source": [
        "# recordad la montaña, estamos saltando de arriba a abajo y de abajo a arriba, en vez de ir siempre hacia abajo..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeCdwKLGPkAy"
      },
      "source": [
        "### Vaya!! Qué es lo que ha pasado?\n",
        "\n",
        "Es muy importante tener en cuenta que el **learning rate va relacionado con el batch size**.\n",
        "\n",
        "Si nos aproximamos a $k=1$, debemos bajar el learning rate para que las actualizaciones de los pesos tengan menos importancia, ya que cada vez se aproxima más al SGD, es decir, a cálculos del gradiente con muestras aleatorias. \n",
        "\n",
        "Veamos qué pasa si disminuimos el learning rate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm2a0cHOQFS0"
      },
      "source": [
        "# con batch_size = 32 y learning rate = 0.1\n",
        "learning_rate = 0.1\n",
        "lr_decay = 1e-3\n",
        "n_epochs = 10\n",
        "batch_size = 32\n",
        "train_network_decay(learning_rate, lr_decay, batch_size, n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6piKxddOQWvL"
      },
      "source": [
        "Y si os fijáis en la curva de pérdidas, podéis intuir que todavía es demasiado grande, puesto que la función no es monótona decreciente, es decir, que no disminuye en cada época. Así que sería mejor usar un learning rate aun menor. Veámoslo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vfLaLRjQm2m"
      },
      "source": [
        "# con batch_size = 32 y learning_rate=0.01\n",
        "learning_rate = 0.01\n",
        "lr_decay = 1e-3\n",
        "n_epochs = 10\n",
        "batch_size = 32\n",
        "train_network_decay(learning_rate, lr_decay, batch_size, n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_7BEzfsQ8Fw"
      },
      "source": [
        "Fijáos como el Accuracy es menor con el learning rate más bajo. ¿Esto por qué? Acordaos! Necesitamos más épocas, ya que los pesos se actualizan más lentamente :)\n",
        "\n",
        "### ¿Os dáis cuenta? Como deberes os dejo que hagáis pruebas variando estos parámetros ;-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geMndMZoD4PV"
      },
      "source": [
        "### 3.3 Funciones de pérdidas\n",
        "\n",
        "\n",
        "¿Qué es una función de pérdidas (o de coste)? ¿Quién sabe decírmelo?\n",
        "\n",
        "La función de pérdidas es la que nos indica en cuánto nos hemos equivocado con nuestras predicciones.\n",
        "\n",
        "Imaginad que tenemos que adivinar cuánto cuesta una casa simplemente viendo una foto. Nuestra red tendría como entrada los píxels de la foto, y como salida un número indicando el precio.\n",
        "\n",
        "Por ejemplo, digamos que queremos predecir el precio de esta casa:\n",
        "\n",
        "<img src=\"https://cdn.elgrupoinformatico.com/img/w720/Noticias/2018/05/memes-chalet-pablo-iglesias-irene-montero-720x362.jpg\" border=\"0\">\n",
        "\n",
        "Imaginaos que estamos entrenando la red y que esta casa está dentro de nuestro conjunto de training. Cuando la imagen pasa hacia delante, se calcula una predicción, que es que vale 323.567€. La verdad es que la casa cuesta 600.000€, así que parece obvio que una función de pérdidas adecuada podría ser:\n",
        "\n",
        "$f_{loss} = prediccion - valor\\_real$\n",
        "\n",
        "¿Lo entendéis verdad? Es exactamente lo mismo que con un SVM o la regresión lineal, por ejemplo.\n",
        "\n",
        "Las funciones de pérdidas más comunes son:\n",
        "\n",
        "* **Problemas de regresión**\n",
        " * Mean Squared Error\n",
        " * Mean Absolute Error\n",
        "* **Problemas de clasificación**\n",
        " * Binary Cross-Entropy\n",
        " * Categorical Cross-Entropy\n",
        "\n",
        "Veamos qué son cada una:\n",
        "\n",
        "* Mean Squared Error\n",
        "\n",
        "$$MSE = \\frac{1}{n} \\sum^{n}_{i=1} (y_i-x_i)^2$$\n",
        "\n",
        "* Mean Absolute Error\n",
        "\n",
        "$$MAE = \\frac{1}{n} \\sum^{n}_{i=1} |y_i-x_i|$$\n",
        "\n",
        "Hasta aquí todo bien verdad? Pero.. ¿qué es la entropía cruzada o cross-entropy?\n",
        "\n",
        "Vamos a verla en este ejemplo a parte:\n",
        "\n",
        "https://colab.research.google.com/drive/1FLM26U7Co5DwqCpyVyxFgQJfax94cEnE?authuser=2\n",
        "\n",
        "Bueno, pues ahora que está claro qué son las funciones de pérdidas, vamos a por las de activación!\n",
        "\n",
        "### 3.4 Funciones de activación\n",
        "\n",
        "Os he de confesar una cosa: la magia de las redes neuronales no es solo el back-propagation. Sin las funciones de activación, las redes neuronales no funcionarían. ¿Alguien sabe decirme por qué?\n",
        "\n",
        "\n",
        "\n",
        "Os doy una pista:\n",
        "\n",
        "### ¿Qué pasaría si no existiese la función de activación?\n",
        "\n",
        "<img src=\"https://image.ibb.co/ftYCVo/what_if_no_activation_function.png\" alt=\"what_if_no_activation_function\" border=\"0\">\n",
        "\n",
        "Tendríamos que $y(x)= Wx + b$. Esto es una combinación lineal que sería incapaz incluso de resolver un problema como el XOR.\n",
        "\n",
        "<img src=\"https://image.ibb.co/kg9GO8/xor.gif\" alt=\"xor\" border=\"0\">\n",
        "\n",
        "Por lo tanto, necesitamos una forma de introducir **no linealidades**, y de eso es de lo que se encarga la **función de activación**. En la siguiente imagen podéis ver algunas de las más típicas, y donde interviene en la red:\n",
        "\n",
        "<img src=\"https://image.ibb.co/bVS6qo/perceptron_activation.png\" alt=\"perceptron_activation\" border=\"0\" width=\"600\">\n",
        "\n",
        "Aquí podéis ver las más usadas:\n",
        "\n",
        "<img src=\"https://image.ibb.co/gMG5kd/activation_functions.png\" alt=\"activation_functions\" border=\"0\" width=\"600\">\n",
        "\n",
        "Es difícil saber con cuál de ellas nuestra red se va a comportar mejor, pero existe una que suele dar buenos resultados casi siempre: la **ReLU**. \n",
        "\n",
        "Por lo tanto, siempre que empecemos, emplearemos la ReLU, y una vez consigamos unos resultados que consideremos buenos, podemos probar con la **Leaky ReLU**, o cualquier otra que os apetezca. Cada día salen nuevas, y una simple búsqueda en google os puede llevar a alguna interesante: como la SELU, por ejemplo (https://towardsdatascience.com/selu-make-fnns-great-again-snn-8d61526802a9).\n",
        "\n",
        "Muchas de estas funciones de activación necesitan métodos específicos de **inicialización de pesos**, para que esten dentro de unos valores y que el descenso del gradiente funcione adecuadamente.\n",
        "\n",
        "A continuación, vamos a darle profundiad a la red y veamos qué es lo que pasa si empleamos diferentes funciones de activación con nuestra ya conocida red:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LUQxK5nVrKo"
      },
      "source": [
        "# Importamos el dataset MNIST desde Keras datasets y cargamos los datos #(X)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_te, y_te) = mnist.load_data()\n",
        "# Normalizamos los datos en el rango de 0-1 para que computacionalmente sea más eficiente el proceso #(X)\n",
        "x_train, x_te = x_train / 255.0, x_te / 255.0\n",
        "# Pasamos a etiquetas one-hot encoded #(X)\n",
        "y_train = to_categorical(y_train)\n",
        "y_te = to_categorical(y_te)\n",
        "# Dividimos el conjunto de training en training y validation #(X)\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definimos la función para entrenar nuestra red con los parámetros deseados\n",
        "def train_network_decay_fnact(activation_function, learning_rate, lr_decay, batch_size, num_epochs):\n",
        "  \n",
        "  # Implementamos la red empleando Keras\n",
        "  model = Sequential() # Instancia de modelo API secuencial #(X)\n",
        "  model.add(Flatten()) # Estiramos los datos en forma de vector como entrada a nuestro Perceptrón Simple #(X)\n",
        "  ## Code ### Añadimos una capa con 32 neuronas y añadimos una función de activacion\n",
        "  model.add(Dense(10, input_shape=(784,), activation=\"softmax\")) # Construimos nuestro Perceptrón simple con una única capa Dense #(X)\n",
        "  # Compilamos y entrenamos el modelo SGD\n",
        "  print(\"[INFO]: Entrenando red neuronal...\")\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(learning_rate, decay=lr_decay/num_epochs), metrics=[\"accuracy\"])  #(X)\n",
        "\n",
        "  # Entrenando la solución\n",
        "  H = model.fit(x_tr, y_tr, validation_data=(x_val, y_val), epochs=num_epochs, batch_size=batch_size)  #(X)\n",
        "\n",
        "  # Evaluando el modelo de predicción con las imágenes de test\n",
        "  print(\"[INFO]: Evaluando red neuronal...\")\n",
        "  predictions = model.predict(x_te, batch_size=batch_size)  #(X)\n",
        "  print(classification_report(y_te.argmax(axis=1), predictions.argmax(axis=1)))\n",
        "\n",
        "  # Muestro gráfica de accuracy y losses\n",
        "  plt.style.use(\"ggplot\")\n",
        "  plt.figure()\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"loss\"], label=\"train_loss\")\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "  plt.title(\"Training Loss and Accuracy\")\n",
        "  plt.xlabel(\"Epoch #\")\n",
        "  plt.ylabel(\"Loss/Accuracy\")\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "lLS99Oa4SNPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Veamos con la ReLU\n",
        "\n",
        "<img src=\"https://image.ibb.co/mSsKBT/act_fn_relu.png\" alt=\"act_fn_relu\" border=\"0\" height=\"250\">\n",
        "\n",
        "<img src=\"https://image.ibb.co/iUdsWT/act_fn_relu2.png\" alt=\"act_fn_relu2\" border=\"0\" height=\"250\">\n",
        "\n",
        "<img src=\"https://image.ibb.co/fzXako/act_fn_relu3.png\" alt=\"act_fn_relu3\" border=\"0\" height=\"250\">"
      ],
      "metadata": {
        "id": "UGn_eIHEhYEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "activation_function = ## Code ##\n",
        "learning_rate = 0.1\n",
        "lr_decay = 1e-3\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "## Code ##"
      ],
      "metadata": {
        "id": "pCYtPMWPUmAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Veamos con la Leaky RELU\n",
        "\n",
        "<img src=\"https://image.ibb.co/j5pAJ8/act_fn_lrelu.png\" alt=\"act_fn_lrelu\" border=\"0\" height=\"250\">"
      ],
      "metadata": {
        "id": "EgzGHv6oiVai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "activation_function = ## Code ##\n",
        "learning_rate = 0.1\n",
        "lr_decay = 1e-3\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "train_network_decay_fnact(activation_function, learning_rate, lr_decay, batch_size, num_epochs)"
      ],
      "metadata": {
        "id": "RaQeDqvIiWjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Veamos con la ELU\n",
        "\n",
        "<img src=\"https://image.ibb.co/gEJgQo/act_fn_elu.png\" alt=\"act_fn_elu\" border=\"0\" height=\"250\">"
      ],
      "metadata": {
        "id": "wUvPfRW8iuuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "activation_function = ## Code ##\n",
        "learning_rate = 0.1\n",
        "lr_decay = 1e-3\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "train_network_decay_fnact(activation_function, learning_rate, lr_decay, batch_size, num_epochs)"
      ],
      "metadata": {
        "id": "8mmnJgcYiwhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc8JoxsdHhrO"
      },
      "source": [
        "# Vamos a probar con la Sigmoide\n",
        "\n",
        "<img src=\"https://image.ibb.co/cMMqJ8/act_fn_sigmoid.png\" alt=\"act_fn_sigmoid\" border=\"0\" height=\"250\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AI72-5wV6Rt"
      },
      "source": [
        "# probamos la sigmoid\n",
        "activation_function = ## Code ##\n",
        "learning_rate = 0.1\n",
        "lr_decay = 1e-3\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "train_network_decay_fnact(activation_function, learning_rate, lr_decay, batch_size, num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHiIKghWHz3f"
      },
      "source": [
        "# Veamos con la tanh\n",
        "\n",
        "<img src=\"https://image.ibb.co/haCKBT/act_fn_tanh.png\" alt=\"act_fn_tanh\" border=\"0\" height=\"250\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_wY_6hiXIyD"
      },
      "source": [
        "# probamos la tanh\n",
        "activation_function = ## Code ##\n",
        "learning_rate = 0.1\n",
        "lr_decay = 1e-3\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "train_network_decay_fnact(activation_function, learning_rate, lr_decay, batch_size, n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3tSe_xXKKJh"
      },
      "source": [
        "\n",
        "Probemos a cambiar la inicialización de la bias, en vez de a 0s, a 1s para ver si tenemos algún cambio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqgIhAZkKZIn"
      },
      "source": [
        "\n",
        "# definimos la función para entrenar nuestra red con los parámetros deseados\n",
        "def train_network_decay_fnact_b1(activation_function, learning_rate, lr_decay, batch_size, num_epochs):\n",
        "  \n",
        "  # Implementamos la red empleando Keras\n",
        "  model = Sequential() # Instancia de modelo API secuencial #(X)\n",
        "  model.add(Flatten()) # Estiramos los datos en forma de vector como entrada a nuestro Perceptrón Simple #(X)\n",
        "  ## Code ## # Añadimos una capa con 32 neuronas y añadimos una función de activacion\n",
        "  model.add(Dense(10, input_shape=(784,), activation=\"softmax\")) # Construimos nuestro Perceptrón simple con una única capa Dense #(X)\n",
        "  # Compilamos y entrenamos el modelo SGD\n",
        "  print(\"[INFO]: Entrenando red neuronal...\")\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(learning_rate, decay=lr_decay/num_epochs), metrics=[\"accuracy\"])  #(X)\n",
        "\n",
        "  # Entrenando la solución\n",
        "  H = model.fit(x_tr, y_tr, validation_data=(x_val, y_val), epochs=num_epochs, batch_size=batch_size)  #(X)\n",
        "\n",
        "  # Evaluando el modelo de predicción con las imágenes de test\n",
        "  print(\"[INFO]: Evaluando red neuronal...\")\n",
        "  predictions = model.predict(x_te, batch_size=batch_size)  #(X)\n",
        "  print(classification_report(y_te.argmax(axis=1), predictions.argmax(axis=1)))\n",
        "\n",
        "  # Muestro gráfica de accuracy y losses\n",
        "  plt.style.use(\"ggplot\")\n",
        "  plt.figure()\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"loss\"], label=\"train_loss\")\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "  plt.title(\"Training Loss and Accuracy\")\n",
        "  plt.xlabel(\"Epoch #\")\n",
        "  plt.ylabel(\"Loss/Accuracy\")\n",
        "  plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGYKMiT1KdLL"
      },
      "source": [
        "# probamos la tanh y bias 1 en vez de 0\n",
        "activation_function = tf.nn.tanh\n",
        "learning_rate = 0.1\n",
        "lr_decay = 1e-3\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "train_network_decay_fnact_b1(activation_function, learning_rate, lr_decay, batch_size, num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAJF2Jb6K1He"
      },
      "source": [
        "También podemos a cambiar la función de pérdidas, de la cross-entropy al error cuadrático medio:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gk3iIApK929"
      },
      "source": [
        "# definimos la función para entrenar nuestra red con los parámetros deseados\n",
        "def train_network_decay_fnact_b1_mse(activation_function, learning_rate, lr_decay, batch_size, num_epochs):\n",
        "  \n",
        "  # Implementamos la red empleando Keras\n",
        "  model = Sequential() # Instancia de modelo API secuencial #(X)\n",
        "  model.add(Flatten()) # Estiramos los datos en forma de vector como entrada a nuestro Perceptrón Simple #(X)\n",
        "  model.add(Dense(32, activation=activation_function,  kernel_initializer='random_uniform', bias_initializer='ones')) # Añadimos una capa con 32 neuronas y añadimos una función de activacion\n",
        "  model.add(Dense(10, input_shape=(784,), activation=\"softmax\")) # Construimos nuestro Perceptrón simple con una única capa Dense #(X)\n",
        "  # Compilamos y entrenamos el modelo SGD\n",
        "  print(\"[INFO]: Entrenando red neuronal...\")\n",
        "  ## Code ##\n",
        "\n",
        "  # Entrenando la solución\n",
        "  H = model.fit(x_tr, y_tr, validation_data=(x_val, y_val), epochs=num_epochs, batch_size=batch_size)  #(X)\n",
        "\n",
        "  # Evaluando el modelo de predicción con las imágenes de test\n",
        "  print(\"[INFO]: Evaluando red neuronal...\")\n",
        "  predictions = model.predict(x_te, batch_size=batch_size)  #(X)\n",
        "  print(classification_report(y_te.argmax(axis=1), predictions.argmax(axis=1)))\n",
        "\n",
        "  # Muestro gráfica de accuracy y losses\n",
        "  plt.style.use(\"ggplot\")\n",
        "  plt.figure()\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"loss\"], label=\"train_loss\")\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "  plt.plot(np.arange(0, num_epochs), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "  plt.title(\"Training Loss and Accuracy\")\n",
        "  plt.xlabel(\"Epoch #\")\n",
        "  plt.ylabel(\"Loss/Accuracy\")\n",
        "  plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0TBurcgK9DB"
      },
      "source": [
        "# probamos la tanh, bias = 1 y loss_fn = mse\n",
        "activation_function = ## Code ##\n",
        "learning_rate = 0.1\n",
        "lr_decay = 1e-3\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "train_network_decay_fnact_b1_mse(activation_function, learning_rate, lr_decay, batch_size, num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlKmAv_wMFwj"
      },
      "source": [
        "¿Os dáis cuenta? Hay 3 cosas que van íntimamente ligadas y de las que debemos ocuparnos para encontrar una buena configuración:\n",
        "\n",
        "* **La función de activación**\n",
        "* **La función de pérdidas**\n",
        "* **La inicialización de los pesos y bias**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWgDJYQxM1s5"
      },
      "source": [
        "### Lo que pretendo con estos ejemplos es que os deis cuenta de la importancia de estos 3 parámetros. Recordad, merece la pena *perder* un poco de tiempo hasta encontrar una configuración adecuada de:\n",
        "\n",
        "* **La función de activación**\n",
        "* **La función de pérdidas**\n",
        "* **La inicialización de los pesos y bias**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL9rwNH1I5I1"
      },
      "source": [
        "# Atención:\n",
        "\n",
        "### Como he comentado antes, en el caso de las capas de salida, practicamente siempre se utiliza la función de activación de tipo softmax, ya que es capaz de dar una probabilidad a cada clase, haciendo que todas ellas sumen 1. Esto en el caso de clasificación, porque en regresión, la última capa tiene tantas neuronas como valores queramos predecir y función de activación LINEAL, es decir, NINGUNA.\n",
        "\n",
        "Como esto puede parecer un poco complicado, os voy a escribir aquí la receta que sigo yo y que hasta ahora me ha dado buenos resultados:\n",
        "\n",
        "# Receta\n",
        "\n",
        "* Empezar usando la ReLU con un learning rate de 0.01 o 0.001, y observar qué pasa.\n",
        "\n",
        "* Si la red entrena (va convergiendo) pero es lenta, podéis probar a aumentar un poco el learning rate\n",
        "\n",
        "* Si la red no converge y se compora de forma caótica, disminuid el learning rate\n",
        "\n",
        "* Una vez tengáis la red funcionando, probad con la Leaky ReLU o la ELU\n",
        "\n",
        "* En clasificación, usad la softmax. No uséis la sigmoide a menos que sepáis lo que estáis haciendo, en la práctica no suele dar buenos resultados. En regresión, recordad que la última capa NO TIENE functión de activación o si habéis normalizado las etiquetas entre 0 y 1 podéis utilizar la función sigmoid.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pxfMOpR2WEz"
      },
      "source": [
        "## 3.5 Inicialización de pesos\n",
        "\n",
        "Como habéis visto antes, la inicialización de los pesos y la bias es muy importante para conseguir la convergencia de nuestra red a un mínimo adecuado. Así que vamos a ver algunas formas de inicializar los pesos.\n",
        "\n",
        "Siguiendo con nuestro ejemplo del MNIST, nuestra matriz de pesos va a ser de 768 (entradas) x 10 (salidas).\n",
        "\n",
        "\n",
        "*   **Inicialización constante**\n",
        "\n",
        "Podemos inicializar nuestros pesos a cero:\n",
        "\n",
        "`W = np.zeros((768, 10))`\n",
        "\n",
        "A uno:\n",
        "\n",
        "`W = np.ones((768, 10))`\n",
        "\n",
        "O a una constante $C$:\n",
        "\n",
        "`W = np.ones((768, 10)) * C`\n",
        "\n",
        "*   **Distribución normal y uniforme**\n",
        "\n",
        "También podemos inicializar los pesos usando una distribución **uniforme**, en la que se definen un $[upper\\_bound, lower\\_bound]$ y todos los números dentro del rango tienen la misma probabilidad de ser escogidos. Por ejemplo, para una distribución entre $[-0.2, 0.2]$:\n",
        "\n",
        "`W = np.random.uniform(low=-0.2, high=0.2, size=(768, 10))`\n",
        "\n",
        "Con esta instrucción, inicializaremos la matriz de pesos $W$ con valores extraídos del rango entre $[-0.2, 0.2]$ donde todos ellos tienen la misma probabilidad de ser extraídos.\n",
        "\n",
        "También podemos hacerlo con una distribución **normal** o Gaussiana, la cual viene definida como:\n",
        "\n",
        "$$p(x)=\\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$$\n",
        "\n",
        "Donde como ya sabéis:\n",
        "\n",
        "* $\\mu$ es la media\n",
        "* $\\sigma$ es la desviación estándar, y $\\sigma^2$ la varianza\n",
        "\n",
        "Así que podríamos inicializar nuestros pesos con una distribución normal con $\\mu = 0$ y $\\sigma = 0.2$, por ejemplo, de la siguiente forma:\n",
        "\n",
        "`W = np.random.normal(0.0, 0.2, size=(768, 10))`\n",
        "\n",
        "*   **Inicialización: LeCun normal y uniforme**\n",
        "\n",
        "Otra forma más avanzada es el método de LeCun, también conocido como *\"Efficient backprop\"*.\n",
        "\n",
        "Este método define 3 parámetros:\n",
        "\n",
        "* $f_{in}$: número de entradas a la capa (en nuestro ejemplo, 768)\n",
        "* $f_{out}$: número de salidas de la capa (en nuestro ejemplo, 10)\n",
        "* $limit$: queda definido según $f_{in}$ y $f{out}$ como $limit = \\sqrt{\\frac{3}{f_{in}}}$\n",
        "\n",
        "El código para inicializar $W$ mediante este método usando una distribución uniforme sería:\n",
        "\n",
        "`W = np.random.uniform(low=-limit, high=limit, size=(F_in, F_out))`\n",
        "\n",
        "Y para una normal:\n",
        "\n",
        "`W = np.random.normal(low=-limit, high=limit, size=(F_in, F_out))`\n",
        "\n",
        "*   **Inicialización: Glorot/Xavier normal y uniforme**\n",
        "\n",
        "Esta es quizás el método más empleado a la hora de inicializar los pesos y la bias. De hecho, es el empleado por defecto cuando se utiliza Keras, un framework que veréis en la próxima sesión.\n",
        "\n",
        "En este caso también se definen los mismos parámetros que con LeCun, pero varía el cálculo del $limit$:\n",
        "\n",
        " $limit = \\sqrt{\\frac{2}{f_{in}+f_{out}}}$\n",
        " \n",
        " El código para inicializar $W$ mediante este método sería el mismo que con LeCun. \n",
        " \n",
        " Para una distribución uniforme sería:\n",
        "\n",
        "`W = np.random.uniform(low=-limit, high=limit, size=(F_in, F_out))`\n",
        "\n",
        "Y para una normal:\n",
        "\n",
        "`W = np.random.normal(low=-limit, high=limit, size=(F_in, F_out))`\n",
        "\n",
        "* **Inicialización: He et al./Kaiming/MSRA normal y uniforme**\n",
        "\n",
        "Este método debe su nombre a Kaiming He, el primer autor de *Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification*.\n",
        "\n",
        "Normalmente, este método se usa cuando estamos entrenando redes neuronales *muy profundas* que usan un tipo particular de ReLU como activación: la Parametric ReLU).\n",
        "\n",
        "El código en el caso de la uniforme es este:\n",
        "\n",
        "`limit = np.sqrt(6 / float(F_ini))`\n",
        "\n",
        "`W = np.random.uniform(low=-limit, high=limit, size=(F_in, F_out))`\n",
        "\n",
        "\n",
        "Y en el caso de la normal, este:\n",
        "\n",
        "\n",
        "`limit = np.sqrt(2 / float(F_ini))`\n",
        "\n",
        "`W = np.random.uniform(low=-limit, high=limit, size=(F_in, F_out))`\n",
        "\n",
        "\n",
        "## Consejo:\n",
        "\n",
        "La inicialización de los pesos no suele ser determinante en el entrenamiento de una red, pero a veces puede hacer que la red no empiece a entrenar porque no consigue converger. Por lo tanto, mi consejo es que uséis random, y si ese día estáis aventureros y queréis ver si conseguís hacer que mejore la precisión, probéis con otras ;-)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU6XrKlABlDE"
      },
      "source": [
        "# **FUENTES:**\n",
        "\n",
        "---\n",
        "https://www.analyticsvidhya.com/blog/2016/04/deep-learning-computer-vision-introduction-convolution-neural-networks/\n",
        "\n",
        "http://cs231n.github.io/neural-networks-2/"
      ]
    }
  ]
}