{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"id":"tA_xJZ9claIv"},"source":["# Módulo 2. Redes neuronales\n","\n","¡Bienvenidos al segundo módulo! Tras haber visto una pequeña introducción al Deep Learning y haber jugado un poco con TensorFlow implementado una pequeña red neuronal, en este módulo vamos a hacer un pequeñísimo repaso de qué es y cómo funciona una red neuronal. Posteriormente, vamos a estudiar detenidamente cómo aprenden y, por último, resolveréis vuestro primer problema real haciendo uso de redes neuronales con TensorFlow.\n","\n","El temario que cubrirá este módulo es el siguiente:\n","\n"," 1. **Introducción a las redes neuronales**\n"," <ul>\n","   1.1 Descripción de las redes neuronales\n","\n","   1.2 La unidad básica y su relación con la biología\n","\n","   1.3 Principales funcionalidades\n","   </ul>\n"," 2. **Entrenamiento de una red neuronal**\n"," <ul>\n","  2.1 Forward y back propagation\n","  </ul>\n"," 3. **Implementación de una red neuronal en Tensorflow**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wyahOFLqnP9k"},"source":["# 1. Introducción a las redes neuronales\n","\n","## 1.1 Descripción de las redes neuronales\n","Como todos sabéis, las redes neuronales son el corazón de los algoritmos basados en deep learning. De forma sencilla, una red neuronal no es más que un método de aproximación de funciones. De hecho, según el teorma de aproximación universal:\n","\n","**Una red neuronal con una sola capa oculta es suficiente para representar cualquier función en un determinado rango de valores**, aunque es posible que dicha capa oculta sea tan grande que haga su implementación imposible o que no sea posible encontrar los pesos adecuados.\n","\n","Si tenemos en cuenta que normalmente cualquier problema que se os ocurra puede ser descompuesto y modelado en forma de funciones matemáticas, de acuerdo con este teorema, las redes neuronales deberían ser capaces de resolver cualquier problema, ¿no?\n","\n","Bueno, hay dos limitaciones importantes de las redes neuronales: \n","* Son capaces de aproximar funciones **continuas** \n","* En un determinado **rango** de valores\n","\n","Una red neuronal está formada por nodos de procesamiento densamente conectados (veremos posteriormente su similitud con las neuronas cerebrales). Cada nodo puede estar conectado a diferentes nodos en múltiples capas por encima y por debajo de él. Una red neuronal simple tiene una **capa de entrada**, una **capa de salida** y una **capa oculta** entre ellas. Una red con más de tres capas, incluyendo la de entrada y la de salida, se conoce como red de aprendizaje profundo. Cuantas más capas, mayor es la capacidad de reconocer información más compleja. En este tipo de arquitecturas, cada neurona de la capa $i$ se conecta con todas las neuronas de la capa $i+1$. Es decir, a las neuronas de una capa determinada solo se les permite conectarse a las neuronas de la siguiente capa. Este tipo de capas se conocen como capas **densas** o **fully connected**. Cuando las conexiones hacia detrás estan permitidas, se llaman **redes recurrentes** (esto lo veremos con más detalle en una sesión posterior).\n","\n","<center> <img src=\"https://i.ibb.co/j32GMwJ/redes-neuronales.png\" border=\"0\" height=\"250\"  height=\"300\" align= \"middle\"> </center>\n","\n","## 1.2 La unidad básica y su relación con la biología\n","\n","Comopodéis comprobar, la unidad básica de las redes neuronales es la **neurona**. De hecho, las redes neuronales están inspiradas en el cerebro humano, donde disponemos de más o menos 10 billones de neuronas, cada una conectada con otras 10.000 neuronas.\n","\n","<img src=\"https://image.ibb.co/cZtMad/net_4_bio.png\" alt=\"net_4_bio\" border=\"0\">\n","\n","<img src=\"https://image.ibb.co/jegAfo/math_model_neuron.jpg\" alt=\"math_model_neuron\" border=\"0\" height=\"200\">\n","\n","La forma de funcionar es que cada neurona recibe un impulso electroquímico de otras neuronas a través de sus dendritas (entradas). Si estos impulsos son lo **suficientemente intensos** para activar la neurona, entonces esta neurona **pasa el impulso a sus conexiones**. Al hacer esto, cada una de las neuronas conectadas vuelve a comprobar si el impulso que le llega al soma a partir de las dendritas es lo suficientemente fuerte como para activar la neurona y espandirse por más neuronas. Teniendo en cuenta este modo de funcionamiento, nos damos cuenta de que realmente las neuronas son como un **interruptor**: o pasan el mensaje o no. Es muy importante que entendáis que las redes neuronales no se *basan* en sus compañeras biológicas, si no que se **inspiran** en ellas.\n","\n","##   1.3 Principales funcionalidades\n","En cuanto a su funcionalidad, a grandes rasgos, con una red neuronal podemos **detectar patrones** y utilizarlos para resolver problemas. Además, con las **redes neuronales profundas** conseguimos transformar el espacio de los datos hasta que encontramos una representación que facilita la consecución de la tarea perseguida. Mirad:\n","\n","<center> <img src=\"https://i.ibb.co/rsMgTXV/redes-neuronales-1.png\" border=\"0\" height=\"450\"  height=\"300\" align= \"middle\"> </center>\n","\n","¿Os dáis cuenta de cómo transforman los datos de entrada para coneguir diferenciarlos más fácilmente?\n","\n","Fijaos en este ejemplo:\n","\n","<center><img src=\"http://cs231n.github.io/assets/eg/spiral_raw.png\" border=\"0\" height=\"300\"></center>\n","\n","Si tratásemos de solucionarlo con un clasificador lineal, por ejemplo, sería muy complicado, ya que los datos no son linealmente separables. Una posible solución sería esta:\n","\n","<center><img src=\"http://cs231n.github.io/assets/eg/spiral_linear.png\" border=\"0\" height=\"300\"></center>\n","\n","Pero como podéis ver, no es demasiado buena... ¿Queréis ver lo que sería capaz de hacer una red neuronal?\n","\n","<center><img src=\"http://cs231n.github.io/assets/eg/spiral_net.png\" border=\"0\" height=\"300\"></center>\n","\n","(Fuente: http://cs231n.github.io/neural-networks-case-study/)\n","\n","Como podéis ver, ¡Mejoran considerablemente los resultados!\n","\n","Entonces, **¿qué es lo que no se puede hacer con redes neuronales?**\n","\n","En general, dar soluciones **exactas** a un problema. Por ejemplo, una red neuronal lo pasaría realmente mal para conseguir implementar la multiplicación. Primero, porque le exigiríamos valores exactos, y segundo, porque como hemos dicho antes, son capaces de aproximar funciones en un rango determinado. La multiplicación exigiría un rango de [-inf, +inf].\n","\n","Además, **tampoco pueden \"pensar\"**. No son más que detectores muy potentes de patrones que dan la sensación de **inteligencia**, pero **no la tienen**. La inteligencia la tenemos que poner **nosotros**.\n","\n","También hay que tener en cuenta que aunque son muy útiles porque resuelven problemas hasta ahora muy complejos para un ordenador, como por ejemplo, detectar distintos tipos de razas de perro o señales de tráfico, es muy difícil extraer ese conocimiento de ellas. Es decir, son capaces de hacer lo que les pidamos, pero es complicado averiguar cómo exáctamente lo están haciendo.\n","\n","Podemos lograr una precisión de +99%, sin embargo, saber en qué se fija la red para tomar sus decisiones es complicado. Aún así, se están haciendo esfuerzos para visualizar los filtros aprendidos y las salidas de cada capa de la red, de forma que podemos intuir cómo funcionan fijándonos en dónde prestan más atención.\n"]},{"cell_type":"markdown","metadata":{"id":"7Cix9wfWDP5U"},"source":["# 2. Entrenamiento de una red neuronal\n","\n","Se puede decir que el aprendizaje de una red neuronal se asemeja al de los seres humanos, aprendizaje basado en ejemplos. Al igual que los seres humanos, las redes neuronales analizan objetos, predicen lo que representan y son corregidas en el caso de que se equivoquen. Tras está corrección, varían su conocimiento para no producir el mismo error. \n","\n","<img src=\"https://i.ibb.co/zPk2t9Y/como-aprende-red.png\" alt=\"como_aprende_red\" border=\"0\" height=\"400\">\n","\n","Por tanto, el entrenamiento de una red neuronal se basa en cuatro pasos básicos: **forward pass**, **comparación con el Ground truth** (GT), **cálculo del error total** y **backward pass o backpropagation**. \n","\n","¿Y cómo varián las redes neuronales su conocimiento para asemejarse lo máximo posible a la verdad absoluta o Ground truth? Pues ... sencillo, minimizando el error obtenido. ¿Os acordáis del método más utilizado para la minimización de una función? **¡El descenso de gradiente!**\n","\n","Imaginaros que la ruta para bajar de la montaña es la función que queremos minimizar para llegar al error mínimo (la zona baja de la montaña) ¿Cómo podríamos calcular la pendiente en cada punto para elegir el camino óptimo? \n","\n","<center><img src=\"https://image.ibb.co/cXGCqd/mountain_gd.png\" alt=\"mountain_gd\" border=\"0\" height=\"200\"> <img src=\"https://image.ibb.co/ganZLd/gradient_descent_2.png\" alt=\"gradient_descent_2\" border=\"0\" height=\"200\"> </center>\n","\n","Cálculando la derivada, ¿os acordáis de como se expresaba? \n","\n","$f'(x) = \\frac{f(x+h)-f(x-h)}{2}$, cuando $h\\to 0$.\n","\n","La primera derivada de una función mide la rapidez con que cambia una función, es decir cuanto crece o decrece. Así que lo que podemos hacer es **calcular la pendiente para cada punto al que llegamos para seguir bajando esa pendiente hasta un punto mínimo**.\n","\n","Pues si amigos, esto va a ir de derivadas.... El descenso del gradiente, algoritmo de optimización que permite **minimizar cualquier función** (siempre que sea **diferenciable**, es decir, que podamos calcular sus derivadas), va a ser el corazoón de las redes neuronales y aquel que nos va a permitir su optimización.\n","\n","## 2.1 Forward y back propagation\n","\n","Vamos a diseñar una red neuronal sencilla que nos permita ejemplificar su entrenamiento. En esta imagen, podemos ver una red con una primera capa de 2 neuronas, una capa oculta de 2 neuronas y una capa de salida de otras 2 neuronas. Además, la capa interna y la de salida tienen también bias.\n","\n","<center><img src=\"https://image.ibb.co/mmk68y/net_1.png\" alt=\"net_1\" border=\"0\"></center>\n","\n","Por simplicidad, vamos a suponer que nuestro training set se compone solo de 1 elemento: 0.05, 0.1, que es de clase 1 (podría ser de clase 0, si la probabilidad de la neurona o1 es mayor que la de la neurona o2, o de clase 1 si ocurre lo contrario). En la siguiente imagen podéis ver la red con los pesos inicializados aleatoriamente, el elemento del training set a la entrada, y la salida deseada:\n","\n","<center><img src=\"https://image.ibb.co/g7C8MJ/net_2.png\" alt=\"net_2\" border=\"0\"></center>\n","\n","Vale, pues ya tenemos nuestra red definida y lista para entrenar. Pero... ¿cómo aprende una red?\n","\n","Mediante el **forward pass** y el backward pass o **backpropagation**.\n","\n","### Forward pass\n","\n","El feed-forward o pasada hacia delante consiste en calcular la salida de nuestra red con los valores actuales de los pesos. Para ello, siguiendo con nuestro ejemplo, lo que hacemos es alimentar (feed forward) la red con nuestro elemento de entrenamiento.\n","\n","Pero antes de nada, vamos a ver cómo es realmente **una neurona**:\n","\n","<center><img src=\"https://image.ibb.co/dq0sFd/net_3_neuron.png\" alt=\"net_3_neuron\" border=\"0\"></center>\n","\n","$$in_{h1} = i1\\cdot w1 + i2\\cdot w2 + 1 \\cdot b1$$\n","\n","$$out_{h1} = \\texttt{fn_activacion}(in_{h1}) = \\texttt{fn_activation}(i1\\cdot w1 + i2\\cdot w2 + 1 \\cdot b1)$$\n","\n","Donde $\\texttt{fn_activacion}$ es la función de activación elegida. Aquí podéis visualizar algunas de estas funciones, que luego veremos con más detalle:\n","\n","<center><img src=\"https://image.ibb.co/gMG5kd/activation_functions.png\" alt=\"activation_functions\" border=\"0\" width=\"600\"> </center>\n","\n","\n","\n","\n","\n","Perfecto! Ya sabéis cómo funciona una neurona, ¿quién sería capaz ahora de decirme cuál es el resultado de $out_{h1}$ de nuestra red?\n","\n","¡Venga! ¡Dadle a esas cabezas! Es simplemente sustituir ;-)\n","\n","¡Vamos allá!\n","\n","Lo primero, vamos a ver qué necesitamos calcular, por orden, que siempre está bien ser ordenado. Veamos primero nuestra red y la estructura de la neurona otra vez:\n","\n","<center><img src=\"https://image.ibb.co/g7C8MJ/net_2.png\" alt=\"net_2\" border=\"0\" height=\"200\"> <img src=\"https://image.ibb.co/dq0sFd/net_3_neuron.png\" alt=\"net_3_neuron\" border=\"0\" height=\"200\"> </center>\n","\n","De acuerdo con esto, para calcular o1 y o2 necesitamos:\n","\n","Para la primera capa, la oculta:\n","\n","* $in_{h1}$ y $out_{h1}$\n","* $in_{h2}$ y $out_{h2}$\n","\n","Para la última capa, la de salida:\n","\n","* $in_{o1}$ y $out_{o1}$\n","* $in_{o2}$ y $out_{o2}$\n","\n","Donde o1 = $out_{o1}$ y o2 = $out_{o2}$. ¿Estamos de acuerdo hasta ahora?\n","\n","Con lo cual, tenemos que calcular:\n","\n","$$in_{h1} = w_1 \\cdot i_1 + w_2 \\cdot i_2 + b_1 \\cdot 1$$\n","\n","$$in_{h1} = 0.15 \\cdot 0.05 + 0.2 \\cdot 0.1 + 0.35 \\cdot 1 = 0.3775$$\n","\n","$$in_{h2} = w_3 \\cdot i_1 + w_4 \\cdot i_2 + b_1 \\cdot 1$$\n","\n","$$in_{h2} = 0.25 \\cdot 0.05 + 0.3 \\cdot 0.1 + 0.35 \\cdot 1 = 0.3925$$\n","\n"]},{"cell_type":"code","metadata":{"id":"xlGv13dIXSCJ"},"source":["in_h1 = 0.15*0.05+0.2*0.1+0.35*1\n","print(in_h1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XyHxh5KyXx5W"},"source":["in_h2 = 0.25*0.05+0.3*0.1+0.35*1\n","print(in_h2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PSr0M-u-X6VJ"},"source":["So far so good!\n","\n","Ahora, para obtener $out_{h1}$ y $out_{h2}$, necesitamos aplicar la $\\texttt{fn_activacion}$. En este caso hemos escogido la función de activación logística:\n","\n","$$\\texttt{fn_activacion}(x) = \\frac{1}{1+e^{-x}}$$\n","\n","Por lo tanto:\n","\n","$$out_{h1} = \\texttt{fn_activacion}(in_{h1}) = \\frac{1}{1+e^{-in_{h1}}}=\\frac{1}{1+e^{-0.3775}} = 0.5933$$\n","\n","$$out_{h2} = \\texttt{fn_activacion}(in_{h2}) = \\frac{1}{1+e^{-in_{h2}}}=\\frac{1}{1+e^{-0.3925}} = 0.5969$$"]},{"cell_type":"code","metadata":{"id":"oGYFIBpTZLjb"},"source":["import numpy as np\n","out_h1 =  ## Code ##\n","print(out_h1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E-gxfhJPZWLk"},"source":["out_h2 = ## Code ##\n","print(out_h2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w2OhtmFQZlLf"},"source":["<img src=\"https://image.ibb.co/gPFbrJ/meme_excelente.jpg\" alt=\"meme_excelente\" border=\"0\" width=\"200\">"]},{"cell_type":"markdown","metadata":{"id":"CzY7z_2HZqoj"},"source":["Vamos a ver cómo llevamos el cálculo de nuestra salida:\n","\n","<center><img src=\"https://image.ibb.co/c21o5d/net_hidden_out.png\" alt=\"net_hidden_out\" border=\"0\" width=\"350\"> </center>\n","\n","¡Solo nos queda calcular o1 y o2! Vamos allá:\n","\n","$$in_{o1} = w_5 \\cdot out_{h1} + w_6 \\cdot out_{h2} + b_2 \\cdot 1$$\n","\n","$$in_{o1} = 0.40 \\cdot 0.5933 + 0.45 \\cdot 0.5969 + 0.60 \\cdot 1 = 1.1059$$\n","\n","$$in_{o2} = w_7 \\cdot out_{h1} + w_8 \\cdot out_{h2} + b_2 \\cdot 1$$\n","\n","$$in_{o2} = 0.50 \\cdot 0.5933 + 0.55 \\cdot 0.5969 + 0.60 \\cdot 1 = 1.2250$$\n","\n","Por lo tanto, aplicando la función de activación:\n","\n","$$out_{o1} = \\texttt{fn_activacion}(in_{o1}) = \\frac{1}{1+e^{-in_{o1}}}=\\frac{1}{1+e^{-1.1059}} = 0.7514$$\n","\n","$$out_{o2} = \\texttt{fn_activacion}(in_{o2}) = \\frac{1}{1+e^{-in_{o2}}}=\\frac{1}{1+e^{-1.2250}} = 0.7729$$"]},{"cell_type":"code","metadata":{"id":"To8q7wyycM_m"},"source":["in_o1 = 0.40*0.5933+0.45*0.5969+0.60*1\n","print(in_o1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TeWUzK0YcVYP"},"source":["in_o2 = 0.50*0.5933+0.55*0.5969+0.60*1\n","print(in_o2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bIymHtuvceZb"},"source":["out_o1 = 1 / (1+np.exp(-in_o1))\n","print(out_o1)  # target_o1 = 0.01"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tELjSE14cnKI"},"source":["out_o2 = 1 / (1+np.exp(-in_o2))\n","print(out_o2)  # target_o2 = 0.99"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gM4CzhedcNaH"},"source":["¡Por fin! ¡Ya tenemos las predicciones de nuestra red neuronal calculadas! ¿Qué pasa? ¿No os convencen?\n","\n","**¡Por supuesto que no, por ahora son pésimas!** ¡No se parecen en nada al 0.01 y 0.99 deseados! ¿Cómo arreglamos esto?\n","\n","## Comparación con el GT y cálculo del error\n","¿Qué os parece si **calculamos el error total** cometido y tratamos de **minimizarlo**? Parece lógico, ¿no? De hecho, es precisamente lo que hace el algoritmo de **backpropagation: actualizar los pesos en función de lo que influya cada peso en el error total para minimizarlo**?\n","\n","Vamos a calcular el error total:\n","\n","$$E_{total}=\\frac{1}{2}\\sum(target-output)^2 = E_{o1} + E_{o2}$$\n","\n","$$E_{o1}=\\frac{1}{2}\\sum(target_{o1}-out_{o1})^2 = \\frac{1}{2}\\sum(0.01-0.7514)^2 = 0.2748$$\n","\n","$$E_{o2}=\\frac{1}{2}\\sum(target_{o2}-out_{o2})^2 = \\frac{1}{2}\\sum(0.99-0.7729)^2 = 0.0236$$\n","\n","$$E_{total} = 0.2748 + 0.0236 = 0.2984$$\n","\n","Fijáos en cómo el error de $out_{o2}$ es mucho menor que el de $out_{o1}$. Esto se debe a que 0.7729 está mucho más cerca de 0.99 que 0.7514 de 0.01, con lo cual, el cambio debería ser mayor en las neuronas que intervienen en el cálculo de $out_{o1}$ que las de $out_{o2}$. Hasta aquí todo lógico, ¿verdad?\n","\n","## Backward pass\n","\n","¿Y cómo podemos actualizar los pesos, cada uno en función de lo que influya en el error total? Muy sencillo, calculando cuanto influye un cambio en un determinado peso con respecto al error total, y actualizándolo teniendo en cuenta esta relación.\n","\n","Por ejemplo, ¿se os ocurre alguna forma de cálcular cuanto influye el peso w5 en el error total? Mejor dicho, cuánto influye un cambio en el peso w5 en el error total? ¿No os suena de nada esto?\n","\n","¡Exacto! ¡Estamos hablando de derivadas! Fijaos, podemos entender cada neurona como una función, y aplicar la **regla de la cadena** para llegar desde el error total hasta el peso w5. Pero antes, ¿os acordáis de cómo funciona la regla de la cadena?\n","\n","Vamos a ver un ejemplo:\n","\n","Imagináos que tenemos que derivar la función $y=(x^2 +1)^3$ respecto de $x$, es decir, queremos encontrar cuanto un cambio en $x$ afecta a la función $y$. \n","\n","Podemos entender esta función como una composición de 2 funciones, donde:\n","\n","$u = x^2 + 1$\n","\n","$y = u^3$\n","\n","¿Lo véis, verdad? Vale, pues ahora necesitamos derivar $y$ con respecto de $x$. Para ello, primero necesitamos derivar $y$ con respecto a $u$, y luego $u$ con respecto a $x$:\n","\n","$\\frac{\\partial y}{\\partial x} = \\frac{\\partial y}{\\partial u} \\cdot \\frac{\\partial u}{\\partial x}$\n","\n","Vamos a verlo con nuestro ejemplo:\n","\n","$\\frac{\\partial y}{\\partial u} = 3 \\cdot u^{3-1} \\cdot u'=3 \\cdot u^{3-1} \\cdot 1 = 3u^2$\n","\n","$\\frac{\\partial u}{\\partial x} = 2x$\n","\n","$\\frac{\\partial y}{\\partial x} = \\frac{\\partial y}{\\partial u} \\cdot \\frac{\\partial u}{\\partial x} = 3u^2 \\cdot 2x = 3 \\cdot (x^2+1)^2 \\cdot 2x$\n","\n","Pues esto, para los que no os acordárais o no lo supierais, es la regla de la cadena. ¿Fácil verdad?\n","\n","Veamoslo ahora como si fuese un grafo:\n","\n","<center><img src=\"https://image.ibb.co/kCTsAo/graph_abcde.png\" alt=\"graph_abcde\" border=\"0\" height=\"50\"></center>\n","\n","Imaginad que cada círculo es una función y que cada flecha una multiplicación. Entonces, utilizando la regla de la cadena podríamos escribir:\n","\n","$$\\frac{\\partial e}{\\partial a} = \\frac{\\partial e}{\\partial d} \\cdot \\frac{\\partial d}{\\partial c} \\cdot \\frac{\\partial c}{\\partial b} \\cdot \\frac{\\partial b}{\\partial a}$$ \n","\n","Pues ahora sí, tras recordar la regla de la cadena, veamos cómo podemos escribir la fórmula que nos indique cúanto cambia el $E_{total}$ en función del peso $w_5$:\n","\n","<center><img src=\"https://image.ibb.co/dRbxgJ/net_out_out.png\" alt=\"net_out_out\" border=\"0\"></center>\n","<center><img src=\"https://image.freepik.com/free-icon/arrow-bold-down-ios-7-interface-symbol_318-34310.jpg\" alt=\"arrow\" border=\"0\" height=\"100\"></center>\n","<center><img src=\"https://image.ibb.co/h6m06J/net_Etotal_Eo1_Eo2.png\" alt=\"net_Etotal_Eo1_Eo2\" border=\"0\" height=\"300\"></center>\n","\n","Vayamos por partes. \n","\n","El error total se define como:\n","\n","$$E_{total} = E_{o1} + E_{o2} = \\frac{1}{2}\\sum(target_{o1}-out_{o1})^2 + \\frac{1}{2}\\sum(target_{o2}-out_{o2})^2$$\n","\n","En este caso, queremos llegar al peso $w_5$, verdad? Pues si os fijáis bien, el peso $w_5$ solo influye realmente en la neurona o1, así que solo nos importa el $E_{o1}$, lo que hace que nuestro $E_{total} = E_{o1}$. \n","\n","<center><img src=\"https://image.ibb.co/eihF6J/net_Etotal_Eo1_Eo2_after.png\" alt=\"net_Etotal_Eo1_Eo2_after\" border=\"0\" height=\"300\"></center>\n","\n","Con lo cual, podemos definir la variación del peso $w_5$ con respecto al $E_{total}$ como:\n","\n","$$\\frac{\\partial E_{total}}{\\partial w_5} = \\frac{\\partial E_{total}}{\\partial out_{o1}} \\cdot \\frac{\\partial out_{o1}}{\\partial in_{o1}} \\cdot \\frac{\\partial in_{o1}}{\\partial w_5}$$\n","\n","Ahora necesitamos calcular su derivada con respecto a $out_{o1}$, que es lo que indica cuanto un cambio en $out_{o1}$ influye en el $E_{total}$:\n","\n","$$\\frac{\\partial E_{total}}{\\partial out_{o1}} = 2 \\cdot \\frac{1}{2}(target_{o1}-out_{o1}) \\cdot -1 + 0$$\n","\n","$$\\frac{\\partial E_{total}}{\\partial out_{o1}} = -(target_{o1}-out_{o1})=-(0.7514-0.01)=0.7414$$\n","\n","¡Genial! Ya tenemos lo que un cambio en $out_{o1}$ afecta al $E_{total}$. Vamos con el siguiente término:\n","\n","$$out_{o1}=\\frac{1}{1+e^{-in_{o1}}}$$\n","\n","Que se puede expresar como:\n","\n","$$out_{o1}=\\frac{e^{in_{o1}}}{1+e^{in_{o1}}}$$\n","\n","Y su derivada:\n","\n","$$\\frac{\\partial}{\\partial in_{o1}}out_{o1}(in_{o1}) = \\frac{\\partial out_{o1}}{\\partial in_{o1}} = \\frac{(e^{in_{o1}})' \\cdot (1+e^{in_{o1}})-e^{in_{o1}} \\cdot (1+e^{in_{o1}})'}{(1+e^{in_{o1}})^2}=\\frac{e^{in_{o1}}\\cdot (1 + e^{in_{o1}}) - e^{in_{o1}}\\cdot (e^{in_{o1}})}{(1+e^{in_{o1}})^2}=\\frac{e^{in_{o1}}+e^{2\\cdot in_{o1}}-e^{2\\cdot in_{o1}}}{(1+e^{in_{o1}})^2} = \\frac{e^{in_{o1}}}{(1+e^{in_{o1}})^2} = \\frac{e^{-in_{o1}}}{(1+e^{-in_{o1}})^2}=out_{o1}\\cdot(1-out_{o1})$$\n","\n","Los dos últimos pasos son posibles debido a que la derivada de la función logística es una función par, es decir, que $f(x)=f(-x)$. Os animo a todos a que probéis a demostrar lo que os acabo de contar. Son 5 o 10 minutos de reloj y ¡merece la pena! ;-)\n","\n","De acuerdo, volvamos a lo nuestro. Ya tenemos la derivada así que ahora hay que calcular su valor:\n","\n","$$\\frac{\\partial out_{o1}}{\\partial in_{o1}} =out_{o1}\\cdot(1-out_{o1})=0.7514 \\cdot(1-0.7514)=0.1868$$\n","\n","Recapitulando!! Ya tenemos el primer y el segundo término calculado de nuestra fórmula para llegar a $w_5$:\n","\n","$$\\frac{\\partial E_{total}}{\\partial w_5} = \\frac{\\partial E_{total}}{\\partial out_{o1}} \\cdot \\frac{\\partial out_{o1}}{\\partial in_{o1}} \\cdot \\frac{\\partial in_{o1}}{\\partial w_5}=0.7414 \\cdot 0.1868 \\cdot \\frac{\\partial in_{o1}}{\\partial w_5}$$\n","\n","Así que ya sólo nos queda calcular $\\frac{\\partial in_{o1}}{\\partial w_5}$.\n","\n","Venga, necesito algún valiente que se atreva con esto. ¿Quién puede decirme la fórmula de $in_{o1}$?\n","\n","Si lo pensáis un poco lo sacáis seguro. Acordaos de qué es $in_{o1}$:\n","\n","<center>\n","<img src=\"https://image.ibb.co/g7C8MJ/net_2.png\" alt=\"net_2\" border=\"0\" height=\"250\">\n","<img src=\"https://image.ibb.co/imZBVd/net_4_w5.png\" alt=\"net_4_w5\" border=\"0\" height=\"200\">\n","</center>\n","\n","Si nos fijamos en las entradas que tiene la neurona o1 podemos sacar inmediatamente la fórmula de $in_{o1}$:\n","\n","$$in_{o1}=out_{h1}\\cdot w_5+ out_{h2} \\cdot w_6 + 1\\cdot b_2$$\n","\n","Y con esto, ya podemos calcular $\\frac{\\partial in_{o1}}{\\partial w_5}$.\n","\n","$$\\frac{\\partial in_{o1}}{\\partial w_5} = out_{h1}+0+0=out_{h1}=0.5933$$\n","\n","Por fin!! Ya tenemos todos los términos necesarios para saber cuanto influye $w_5$ en el $E_{total}$ calculados:\n","\n","$$\\frac{\\partial E_{total}}{\\partial w_5} = \\frac{\\partial E_{total}}{\\partial out_{o1}} \\cdot \\frac{\\partial out_{o1}}{\\partial in_{o1}} \\cdot \\frac{\\partial in_{o1}}{\\partial w_5}=0.7414 \\cdot 0.1868 \\cdot 0.5933 = 0.0822$$\n","\n","Genial, ¿no? Ya sabemos cómo calcular cuanto influyen los pesos que hay entre la segunda capa y la terera (la oculta y la de salida). Pero... ¿cómo averiguamos lo que influyen los pesos que hay entre la primera capa y la segunda (la de entrada y la oculta)?\n","\n","**¡¡Muy sencillo, de la misma forma!!**"]},{"cell_type":"markdown","metadata":{"id":"Ythn8Jqgsne3"},"source":["**¡¡Vamos a verlo!!** Ahora ya sabéis cómo se hace, asi que venga, ¿qué es lo primero que necesitamos definir?\n","\n","La derivada del $E_{total}$ con respecto al peso $w_1$. ¿Y eso cómo se define? Aquí tenéis la red, ¿quién sabe decírmelo?\n","\n","<center><img src=\"https://image.ibb.co/g7C8MJ/net_2.png\" alt=\"net_2\" border=\"0\" height=\"300\"></center>\n","\n","...\n","\n","\n","...\n","\n","\n","...\n","\n","\n","Vamos a verlo desmenuzando nuestra red en neuronas:\n","\n","<center><img src=\"https://image.ibb.co/dEkBmT/net_Etotal_Eo1_Eo2_w1.png\" alt=\"net_Etotal_Eo1_Eo2_w1\" border=\"0\" height=\"350\"></center>\n","\n","En esta ocasión, si os fijáis, existen dos posibles caminos que tenemos que tener en cuenta:\n","\n","* $E_{o1}$ -> $out_{o1}$ -> $in_{o1}$ -> $out_{h1}$ -> $in_{h1}$ -> $w_1$\n","* $E_{o2}$ -> $out_{o2}$ -> $in_{o2}$ -> $out_{h1}$ -> $in_{h1}$ -> $w_1$\n","\n","Por lo tanto, tenemos que calcular los errores correspondientes a la neurona 1 y a la 2:\n","\n","$$\\frac{\\partial E_{total}}{\\partial w_{1}} = \\frac{\\partial E_{o1}}{\\partial w_{1}} + \\frac{\\partial E_{o2}}{\\partial w_{1}}$$\n","\n","Esto significa que ahora tenemos dos fuentes de error que afectan al peso $w_1$, que son $E_{o1}$ y $E_{o2}$. ¿Cómo se define cada uno? Muy fácil, ¿cuál es el primer elemento que nos encontraríamos si fuesemos andando desde el $E_{o1}$ hasta el peso $w_1$ en el diagrama de la red? $out_{o1}$, verdad? \n","\n","Con lo cual, ya tenemos que:\n","\n","$$\\frac{\\partial E_{o1}}{\\partial w_{1}} = \\frac{\\partial E_{o1}}{\\partial out_{o1}} \\cdot \\ldots$$\n","\n","Y después de $out_{o1}$ ¿qué viene?\n","\n","$in_{o2}$\n","\n","Así que:\n","\n","$$\\frac{\\partial E_{o1}}{\\partial w_{1}} = \\frac{\\partial E_{o1}}{\\partial out_{o1}} \\cdot \\frac{\\partial out_{o1}}{\\partial in_{o1}} \\cdot \\ldots$$\n","\n","¿Y después?\n","\n","$out_{h1}$\n","\n","Así que:\n","\n","$$\\frac{\\partial E_{o1}}{\\partial w_{1}} = \\frac{\\partial E_{o1}}{\\partial out_{o1}} \\cdot \\frac{\\partial out_{o1}}{\\partial in_{o1}} \\cdot \\frac{\\partial in_{o1}}{\\partial out_{h1}} \\ldots$$\n","\n","Y si seguimos el camino, luego vienen por orden: $out_{h1}$, $in_{h1}$ y $w_1$, y se acabó, ya hemos llegado a $w_1$!! Con lo cual, la ecuación completa para llegar desde $E_{o1}$ hasta $w_1$ es:\n","\n","$$\\frac{\\partial E_{o1}}{\\partial w_{1}} = \\frac{\\partial E_{o1}}{\\partial out_{o1}} \\cdot \\frac{\\partial out_{o1}}{\\partial in_{o1}} \\cdot \\frac{\\partial in_{o1}}{\\partial out_{h1}} \\cdot \\frac{out_{h1}}{\\partial in_{h1}} \\cdot \\frac{\\partial in_{h1}}{\\partial w_1}$$\n","\n","<center><img src=\"https://image.ibb.co/g7C8MJ/net_2.png\" alt=\"net_2\" border=\"0\" height=\"250\"></center>\n","\n","\n","¿Y cuál sería la fórmula para llegar desde el error de la segunda neurona, $E_{o2}$, al peso $w_1$?\n","\n","Eso os lo dejo de **deberes, mañana lo corregimos.** \n","\n","Venga, pues vamos a resolver para el $E_{o1}$:\n","\n","$$\\frac{\\partial E_{o1}}{\\partial w_{1}} = \\frac{\\partial E_{o1}}{\\partial out_{o1}} \\cdot \\frac{\\partial out_{o1}}{\\partial in_{o1}} \\cdot \\frac{\\partial in_{o1}}{\\partial out_{h1}} \\cdot \\frac{out_{h1}}{\\partial in_{h1}} \\cdot \\frac{\\partial in_{h1}}{\\partial w_1}$$\n","\n","Tenemos un buen chorizo, así que vamos a ir término por término. Despacito pero con buena letra, que decía mi abuela:\n","\n","$$\\frac{\\partial E_{o1}}{\\partial out_{o1}} = \\frac{\\partial}{\\partial out_{o1}} \\left ( \\frac{1}{2} (target_{o1}-out_{o1})^2 \\right )=out_{o1}-target_{o1}$$\n","\n","$$\\frac{\\partial out_{o1}}{\\partial in_{o1}} = \\frac{\\partial}{\\partial in_{o1}} \\left ( \\frac{1}{1+e^{-in_{o1}}} \\right )=out_{o1}(1-out_{o1})$$\n","\n","$$\\frac{\\partial in_{o1}}{\\partial out_{h1}} = \\frac{\\partial}{\\partial out_{h1}} \\left ( w_5 \\cdot out_{h1} + w_6 \\cdot out_{h2} + b_2 \\cdot 1\\right )=w_5$$\n","\n","$$\\frac{out_{h1}}{\\partial in_{h1}} = \\frac{\\partial}{\\partial in_{h1}} \\left ( \\frac{1}{1+e^{-in_{h1}}} \\right ) = out_{h1}(1-out_{h1})$$\n","\n","$$\\frac{\\partial in_{h1}}{\\partial w_1} = \\frac{\\partial}{\\partial w_{1}} \\left ( w_1 \\cdot i_1 + w_2 \\cdot i_2 + b_1 \\cdot 1\\right ) = i_1  $$\n","\n","**Y con esto calcularíamos cuánto varía el $E_{o1}$ con respecto al peso $w_1$.** Pero nos falta algo, ¿no creéis? Recordad la imagen de las neuronas:\n","\n","<center><img src=\"https://image.ibb.co/dEkBmT/net_Etotal_Eo1_Eo2_w1.png\" alt=\"net_Etotal_Eo1_Eo2_w1\" border=\"0\" height=\"350\"></center>\n","\n","**¡Extacto! Necesitamos también el error correspondiente a la segunda neurona, $E_{o2}$!**. Con ese error, podríamos calcular cuanto influye el peso $w_1$ en el $E_{total}$, que es lo que nos interesa:\n","\n","$$\\frac{\\partial E_{total}}{\\partial w_{1}} = \\frac{\\partial E_{o1}}{\\partial w_{1}} + \\frac{\\partial E_{o2}}{\\partial w_{1}}$$\n","\n","Y repitiendo esto para cada peso, tendríamos todo lo necesario para aplicar el descenso del gradiente sobre nuestros pesos, y así actualizarlos, fijaos:\n","\n","<center><img src=\"https://image.ibb.co/jMmHRT/net_weights_update.png\" alt=\"net_weights_update\" border=\"0\" height=\"250\"></center>\n","\n","Donde $\\eta$ es el *learning rate* o tasa de aprendizaje, que indica lo grande que queremos dar el paso en la dirección contraria al gradiente.\n","\n","En este enlace podéis ver este ejemplo completado: https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/"]},{"cell_type":"markdown","metadata":{"id":"-gZUbPqx_0Xn"},"source":["### Bueno, pues esto es el gradient descent. ¿Lo habéis entendido todos? Merece la pena, de verdad, que invirtáis un fin de semana en implementarlo vosotros y hacerlo de cero, así no se os olvidará nunca.\n","\n","Aunque como mejor se aprende es implementándolo, vamos a ver cómo se implementa con TensorFlow. **¡¡Lo que no quita que no tengáis que pelearos vosotros con él como ya os he dicho!!!**"]},{"cell_type":"code","metadata":{"id":"w3y6kqDQB8Qg"},"source":["# implementación de gradient descent en una red neuronal\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn.datasets import make_blobs\n","import matplotlib.pyplot as plt\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"goXh3zBuRNR6"},"source":["# Implementamos nuestra función de activación: la función logística\n","def sigmoid_activation(x):\n","  return ## Code ##"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FaNkjZB7RaCk"},"source":["# Implementamos la función que nos calcula las predicciones (Forward pass)\n","def predict(X,W):\n","  # preds = fn_activacion( i1*w1 + i2*w2 + ... + 1* b1 )\n","  preds = ## Code ##\n","  # preds devuelve una probabilidad para cada posible clase, cuya suma da 1\n","  # necesitamos pasar este vector de probabilidades a un vector de clases:\n","  # umbralizamos\n","  preds[## Code ##] = 0\n","  preds[## Code ##] = 1\n","  \n","  #Devolvemos las predicciones\n","  return preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MTS-un_xSg1m"},"source":["# Generamos un dataset de juguete\n","(X, y) = make_blobs(n_samples=500, n_features=2, centers=2, cluster_std=2.5, random_state=1)\n","y = y.reshape((y.shape[0], 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YxQ0kaA-UNLC"},"source":["# Lo visualizamos\n","plt.scatter(X[:, 0], X[:, 1], c=y[:, 0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"643iATpiV8kp"},"source":["# Incluímos la columna de bias para poder realizar los cálculos de forma \n","# eficiente (bias trick)\n","X = ##Code##"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3jfbuTenWC7T"},"source":["# Veamos las dimensiones de X\n","X.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VGUu2VD3UPdU"},"source":["# Partimos en training y testing\n","(train_X, test_X, train_Y, test_Y) = ## Code ##"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yb2Y3rSUVxNr"},"source":["# Veamos los tamaños\n","train_X.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J-44n_29WZmA"},"source":["train_Y.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"04lK2RvnWbfW"},"source":["test_X.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7GrEXTCyWd24"},"source":["test_Y.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4TQQ2clrWgd2"},"source":["# Inicializamos nuestra matriz de pesos de forma aleatoria y el vector de \n","# históricos de pérdidas\n","W = np.random.randn(X.shape[1], 1)\n","losses = []\n","print(W)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T14zs8WjW5fI"},"source":["# Empezamos con el FORWARD PROPAGATION\n","\n","# Como ya sabéis, es un proceso iterativo, en el que poco a poco se van \n","# actualizando los pesos usando el gradient descent para llegar a una mejor\n","# solución => épocas\n","\n","n_epochs = 100\n","for epoch in np.arange(0, n_epochs):\n","\n","  # calculamos las predicciones que da nuestra red con sus pesos actuales\n","  preds = ## Code ##\n","\n","  # calculamos el error con respecto a las etiquetas\n","  error = ## Code ##\n","\n","  # definimos la función de pérdidas: en este caso, el error cuadrático\n","  # hay una gran variedad de funciones de pérdidas distintas que iremos viendo\n","  loss =## Code ##\n","\n","  # añadimos nuestra pérdida al vector histórico de pérdidas\n","  ## Code ##\n","\n","  # y comencamos con el BACK PROPAGATION\n","  gradient = ## Code ##\n","\n","  # ahora actualizamos nuestros pesos\n","  # pero primero, definimos nuestro learning rate\n","  learning_rate = 0.01\n","  W += ## Code ##\n","  \n","  # escribimos por pantalla cómo va el asunto\n","  ##Code##\n","  \n","# en cuanto acaba de entrenar, vemos lo que ha estudiado nuestra red\n","preds =## Code ##\n","print(## Code ##)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"85yAss0jZUzG"},"source":["# y ahora algo que os recomiendo que hagáis siempre que podáis, comprobar \n","# vuestras entradas, las predicciones y la curva de pérdidas\n","##Code##"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pRLGLOvpc3-E"},"source":["# veámoslo ahora con las predicciones\n","p##Code##"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uTpK4eYXcqVR"},"source":["# veamos nuestra curva de pérdidas\n","## Code ##"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FNHK1IW-dkHP"},"source":["## ¿Qué os parece? \n","\n","### ¡¡¡Acabáis de implementar el gradient descent en una red neuronal!!!\n","\n","<center><img src=\"https://image.ibb.co/gHQ30o/baby_party.gif\" alt=\"baby_party\" border=\"0\"> \n","</center>"]},{"cell_type":"markdown","metadata":{"id":"wrWp3SfsmmfB"},"source":["## 2.3 Implementación del Gradient Descent en una Red Neuronal con TensorFlow\n","\n","¿Os acordáis del MNIST? Es el dataset de imágenes monocromas de 28x28 píxels de dígitos del 0 al 9:\n","\n","<img src=\"https://image.ibb.co/gkZAD8/mnist.jpg\" alt=\"mnist\" border=\"0\" height=\"200\">\n","\n","Vamos a repetir la implementación que hicimos en el módulo anterior calculando nosotros mismos el gradiente. Además, vamos a introducir la diferencia con tenfoflow 2.x, donde no hace falta ejecutar sesiones, ni alimentar placeholders (lo hace internamente)."]},{"cell_type":"code","metadata":{"id":"1dH4fqJZrCzI"},"source":["# imports necesarios\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","# importamos el dataset MNIST y cargamos los datos\n","from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Importamos el dataset que vamos a utilizar: el MNIST\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()\n","from sklearn.model_selection import train_test_split\n","\n","# Cargamos el dataset \n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15)\n","\n","# Normalizamos el dataset\n","x_train = x_train / 255.\n","x_test = x_test / 255.\n","x_val= x_val / 255.\n","\n","# El dataset ya está dividido en train, validation y test. Dentro de cada uno\n","# de estos subsets ver el número de ejemplos y las dimensiones: \n","print(\"El conjunto de entrenamiento tiene dimensiones: \", x_train.shape)\n","print(\"El conjunto de validación tiene dimensiones: \",x_val.shape)\n","print(\"El conjunto de test tiene dimensiones: \",x_test.shape)\n","\n","#Hacemos lo mismo para las etiquetas.\n","print(\"El conjunto de entrenamiento (etiquetas) tiene dimensiones: \", y_train.shape)\n","print(\"El conjunto de validación (etiquetas) tiene dimensiones: \",y_val.shape)\n","print(\"El conjunto de test (etiquetas) tiene dimensiones: \",y_test.shape)\n","\n","# Cada etiqueta debería ser guardada en un vector de longitud = N_CLASES, con todo 0s excepto para \n","# el índice que indica la clase a la que pertenece la imágen, que contiene un 1)\n","# Por ejemplo, si tenemos 10 clases (números del 0 al 9), y la etiqueta \n","# pertenece al número 5:\n","# label = [0 0 0 0 0 1 0 0 0 0]\n","#Esto se llama one-hot encodding, cambiamos el formato de la etiquetas\n","y_train = tf.one_hot(y_train, depth=10)\n","y_val = tf.one_hot(y_val, depth=10)\n","y_test = tf.one_hot(y_test, depth=10)\n","\n","print(\"El conjunto de entrenamiento (etiquetas) en one-hot encoding tiene dimensiones: \", y_train.shape)\n","print(\"El conjunto de validación (etiquetas) en one-hot encoding tiene dimensiones: \",y_val.shape)\n","print(\"El conjunto de test (etiquetas) en one-hot encoding tiene dimensiones: \",y_test.shape)\n","\n","# Veamos algunas de las imágenes del dataset...\n","# Para ello, solo necesitamos acceder a un vector de nuestra matrix y \n","# redimensionarlo a 28x28\n","plt.subplot(131)\n","plt.imshow(np.reshape(x_train[0, :], (28, 28)), cmap='gray')\n","plt.subplot(132)\n","plt.imshow(np.reshape(x_train[27500, :], (28, 28)), cmap='gray')\n","plt.subplot(133)\n","plt.imshow(np.reshape(x_train[41000, :], (28, 28)), cmap='gray')"],"metadata":{"id":"gRLCig7Wn07q"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YKcXV1vus7oh"},"source":["# Ya hemos visto un poco en qué consiste el dataset del MNIST. \n","# Reducimos tamaño de entrenamiento para que vaya más rápido\n","size_train=1000\n","x_train=x_train[0:size_train]\n","y_train= y_train[0:size_train]\n","# Convertimos las imágenes a vectores, dado que aún no hemos visto cómo podemos implementar un modelo que trabaje con imágenes\n","x_train = tf.reshape(x_train, shape=(size_train, -1)) # Nuestros datos ya están en formato [N_instancias, variables] (nº instancias, 784 (28+28) pixels).\n","x_val = tf.reshape(x_val, shape=(9000, -1)) # Nuestros datos ya están en formato [N_instancias, variables] ((nº instancias, 784 (28+28) pixels).\n","x_test = tf.reshape(x_test, shape=(10000, -1)) # Nuestros datos ya están en formato [N_instancias, variables] ((nº instancias, 784 (28+28) pixels)."],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# parámetros\n","learning_rate = 0.01\n","n_epochs = 10\n","batch_size = 100"],"metadata":{"id":"ETvfUFw-n8t8"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ziow1_Wcs-RH"},"source":["# Cuando ejecutamos en grafo, lo primero es que creemos el placeholder \n","# para nuestros datos de entrada y salida. En este caso, la entrada va a ser \n","# un conjunto de vectores de tamaño 768 (vamos a pasarle varias imágenes \n","# a la vez a nuestro regresor, de esta forma, cuando calcule el gradiente \n","# se basará en varias imágenes, con lo que la  estimación será más precisa\n","# que si utilizase solo una). La salida tendrá dimensión 10, que son las 10 \n","# clases en las que podemos clasificar\n","\n","n_input = 784  # Número de características de los datos: nº píxels de la imagen\n","n_output = 10  # Número de clases: del 0 al 9\n","\n","# Creamos el placeholder de entrada a nuestro algoritmo\n","net_input = tf.placeholder(tf.float32, [None, n_input]) \n","# Necesitamos también un placeholder para la etiqueta de la imagen, con la que \n","# compararemos nuestra predicción\n","y_true = tf.placeholder(tf.float32, [None, n_output])\n","\n","# Creamos las variables W y b para el entrenamiento. Recordad y = W*x + b\n","W = tf.Variable(tf.zeros([n_input, n_output]))\n","b = tf.Variable(tf.zeros([n_output]))\n","\n","# Como la salida es multiclase, necesitamos una función que nos devuelva las \n","# probabilidades de una imagen de pertenecer a cada de las posibles clases. Lo\n","# ideal, además, es que estas probabilidades sumasen 1.\n","# Por ejemplo, si metemos una imagen con un 5, una posible salida sería:\n","# [0.05 0.05 0.05 0.05 0.05 0.55 0.05 0.05 0.05 0.05]\n","# cuya suma de probabilidades es 1, y la clase con la mayor probabilidad es 5.\n","# Aplicamos la función softmax para normalizar las probabilidades de salida\n","net_output = tf.nn.softmax(tf.matmul(net_input, W) + b)\n","print(\"Tamaño del input es: {}\".format(net_input)) # Dimensiones  axb\n","print(\"Tamaño los pesos es: {}\".format(net_output)) # El prodcuto tendrá dimensiones  axc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3euBU66OnyMD"},"source":["# Ahora, definimos nuestra función de pérdidas: esta vez, la cros-entropía\n","# no os preocupéis, la veremos en detalle en la próxima sesión\n","# a veces la llaman loss, a veces cost => es lo mismo\n","cost = tf.reduce_mean(-tf.reduce_sum(y_true*tf.log(net_output), axis=1))\n","\n","#### calculamos los gradientes (gradient descent) ####\n","## Code ##\n","# definimos las operaciones para actualizar los pesos con los gradientes calculados\n","# y el learning rate\n","new_W = ## Code ##\n","new_b = ## Code ##\n","\n","#### Esto lo calculaba la siguietne función implementada en la práctica anterior ####\n","#optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n","\n","#Definimos el número de batches totales\n","total_batch = size_train / batch_size\n","\n","# inicializamos las variables\n","init = tf.global_variables_initializer()\n","\n","# para almacenar el histórico de costes\n","costs = []\n","# empezamos la sesión\n","with tf.Session() as sess:\n","    sess.run(init)\n","\n","    # entrenamiento de nuestra red\n","    for epoch in range(n_epochs):\n","        avg_cost = 0.     \n","        # y si en vez de actualizar los pesos para cada imagen, lo hacemos\n","        # de X en X imágenes?\n","        for sample_i in range(0,x_train.shape[0],batch_size):\n","            sample_x = x_train[sample_i:sample_i+batch_size]\n","            sample_y = y_train[sample_i:sample_i+batch_size]    \n","            # ejecutamos la optimización\n","            _, _, c = ##code ##\n","            # calculamos el coste teniendo en cuenta los batches que hay\n","            avg_cost += ##code ##\n","            \n","        # guardamos nuestro coste en el histórico\n","        ##code ##\n","        \n","        # imprimimos las iteraciones\n","        print(\"[{}] cost: {}\".format(epoch, avg_cost))\n","\n","    print(\"Entrenamiento finalizado!!\")\n","\n","    # comprobamos lo que ha aprendido nuestra red\n","    correct_prediction = tf.equal(tf.argmax(net_output, 1), tf.argmax(y_true, 1))\n","    \n","    # calculamos el accuracy (precisión)\n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","    print(\"Accuracy:\", accuracy.eval({net_input: x_test.eval(), y_true: y_test.eval()}))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x-gt4KhtOoZ2"},"source":["# veamos nuestra función de pérdidas con respecto a las épocas ejecutadas\n","  ## Code##"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o9prkSKnyV0i"},"source":["#¿Y cómo haríamos esto con TF 2.0? ¡Veámoslo!"]},{"cell_type":"code","metadata":{"id":"tmI9WU-Ezy9C"},"source":["# Importamos el dataset que vamos a utilizar: el MNIST\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","# Cargamos el dataset \n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15)\n","\n","# Normalizamos el dataset\n","x_train = x_train / 255.\n","x_test = x_test / 255.\n","x_val= x_val / 255.\n","\n","# El dataset ya está dividido en train, validation y test. Dentro de cada uno\n","# de estos subsets ver el número de ejemplos y las dimensiones: \n","print(\"El conjunto de entrenamiento tiene dimensiones: \", x_train.shape)\n","print(\"El conjunto de validación tiene dimensiones: \",x_val.shape)\n","print(\"El conjunto de test tiene dimensiones: \",x_test.shape)\n","\n","#Hacemos lo mismo para las etiquetas.\n","print(\"El conjunto de entrenamiento (etiquetas) tiene dimensiones: \", y_train.shape)\n","print(\"El conjunto de validación (etiquetas) tiene dimensiones: \",y_val.shape)\n","print(\"El conjunto de test (etiquetas) tiene dimensiones: \",y_test.shape)\n","\n","# Cada etiqueta debería ser guardada en un vector de longitud = N_CLASES, con todo 0s excepto para \n","# el índice que indica la clase a la que pertenece la imágen, que contiene un 1)\n","# Por ejemplo, si tenemos 10 clases (números del 0 al 9), y la etiqueta \n","# pertenece al número 5:\n","# label = [0 0 0 0 0 1 0 0 0 0]\n","#Esto se llama one-hot encodding, cambiamos el formato de la etiquetas\n","y_train = tf.one_hot(y_train, depth=10)\n","y_val = tf.one_hot(y_val, depth=10)\n","y_test = tf.one_hot(y_test, depth=10)\n","\n","print(\"El conjunto de entrenamiento (etiquetas) en one-hot encoding tiene dimensiones: \", y_train.shape)\n","print(\"El conjunto de validación (etiquetas) en one-hot encoding tiene dimensiones: \",y_val.shape)\n","print(\"El conjunto de test (etiquetas) en one-hot encoding tiene dimensiones: \",y_test.shape)\n","\n","# Veamos algunas de las imágenes del dataset...\n","# Para ello, solo necesitamos acceder a un vector de nuestra matrix y \n","# redimensionarlo a 28x28\n","plt.subplot(131)\n","plt.imshow(np.reshape(x_train[0, :], (28, 28)), cmap='gray')\n","plt.subplot(132)\n","plt.imshow(np.reshape(x_train[27500, :], (28, 28)), cmap='gray')\n","plt.subplot(133)\n","plt.imshow(np.reshape(x_train[41000, :], (28, 28)), cmap='gray')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CTToL1y_zy9K"},"source":["# Ya hemos visto un poco en qué consiste el dataset del MNIST. \n","# Reducimos tamaño de entrenamiento para que vaya más rápido\n","size_train=1000\n","x_train=x_train[0:size_train]\n","y_train= y_train[0:size_train]\n","# Convertimos las imágenes a vectores, dado que aún no hemos visto cómo podemos implementar un modelo que trabaje con imágenes\n","x_train = tf.reshape(x_train, shape=(size_train, -1)) # Nuestros datos ya están en formato [N_instancias, variables] (nº instancias, 784 (28+28) pixels).\n","x_val = tf.reshape(x_val, shape=(9000, -1)) # Nuestros datos ya están en formato [N_instancias, variables] ((nº instancias, 784 (28+28) pixels).\n","x_test = tf.reshape(x_test, shape=(10000, -1)) # Nuestros datos ya están en formato [N_instancias, variables] ((nº instancias, 784 (28+28) pixels)."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vroOcO-g7O1G"},"source":["Por último, debemos fijarnos en los tipos de datos con los que estamos trabajando. TF exige que los tipos coincidan, si no, se queja :("]},{"cell_type":"code","metadata":{"id":"OFm6Kyj37UaX"},"source":["print(x_train.dtype)\n","print(x_test.dtype)\n","print(y_train.dtype)\n","print(y_test.dtype)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mkCMSdQj7biE"},"source":["# convertimos las etiquetas a float64\n","y_train =   ## Code##\n","y_test =   ## Code##"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_XCxu6vL7mo5"},"source":["print(x_train.dtype)\n","print(x_test.dtype)\n","print(y_train.dtype)\n","print(y_test.dtype)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fh5KNq937oNS"},"source":["¡Perfecto! Ahora sí que estamos preparados. Si no hubieramos hecho esta conversión, hubieramos obtenido un error como este:\n","\n","\n","\n","```\n","---------------------------------------------------------------------------\n","InvalidArgumentError                      Traceback (most recent call last)\n","<ipython-input-38-4d4399931cbf> in <module>()\n","     20         # no os preocupéis, la veremos en detalle en la próxima sesión\n","     21         # a veces la llaman loss, a veces cost => es lo mismo\n","---> 22         cost = tf.reduce_mean(-tf.reduce_sum(batch_ys*tf.math.log(pred), axis=1))\n","     23 \n","     24         # calculamos los gradientes (gradient descent)\n","\n","4 frames\n","/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\n","\n","InvalidArgumentError: cannot compute Mul as input #1(zero-based) was expected to be a uint8 tensor but is a double tensor [Op:Mul]\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"7YpcaTRA701S"},"source":["Nos creamos ahora el iterador para que recorra nuestro dataset. Podéis leer más sobre `tf.data` aquí: https://www.tensorflow.org/guide/data"]},{"cell_type":"code","metadata":{"id":"NTmSpz0T35Qt"},"source":["train_ds =   ## Code##\n","train_ds =   ## Code##\n","\n","# para el conjunto de test no vamos a necesitar el dataloader porque\n","# no vamos a procesar los datos por batches, sino todos a la vez, así \n","# que utilizaremos x_test y y_test. \n","# Si fuesemos a procesarlo por batches, se haría así:\n","# test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n","# test_ds = test_ds.batch(batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ED0WNPxU_BU1"},"source":["# cuantas iteraciones habrá por época? \n","# en una época se tienen que ver todos los elementos del dataset, y estamos\n","# pasándole los elementos de 100 en 100, así que habrá 60000 / 100 = 600 épocas\n","total_batch =  ## Code##\n","print(total_batch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WOUtLtXg4ThZ"},"source":["# y creamos las variables W y b para el entrenamiento\n","W = tf.zeros([784, 10], tf.double)\n","b = tf.zeros([10], tf.double)\n","\n","# para almacenar el histórico de costes\n","costs = []\n","# entrenamiento de nuestra red\n","for epoch in range(n_epochs):\n","    avg_cost = 0.\n","    \n","    # y si en vez de actualizar los pesos para cada imagen, lo hacemos\n","    # de X en X imágenes?\n","    for batch_xs, batch_ys in train_ds:\n","        # empezamos con la optimización\n","  \n","        # haremos uso de tf.GradientTape, que lleva un control de las variables\n","        # para poder calcular sus gradientes\n","        with tf.GradientTape() as tape:\n","            # le indicamos que \"vigile\" las variables a optimizar\n","            tape.watch(W)\n","            tape.watch(b)\n","            \n","            # ejecutamos el modelo (a veces, lo llamamos net_output o pred, es lo mismo)\n","            pred = tf.nn.softmax(tf.matmul(batch_xs, W) + b)\n","\n","            # ahora, definimos nuestra función de pérdidas: esta vez, la cros-entropía\n","            # no os preocupéis, la veremos en detalle en la próxima sesión\n","            # a veces la llaman loss, a veces cost => es lo mismo\n","            cost = tf.reduce_mean(-tf.reduce_sum(batch_ys*tf.math.log(pred), axis=1))\n","\n","            # calculamos los gradientes (gradient descent)\n","            ## code ##\n","\n","            # definimos las operaciones para actualizar los pesos con los gradientes calculados\n","            # y el learning rate\n","            W = ## code ##\n","            b = ## code ##\n","\n","        # calculamos el coste teniendo en cuenta los batches que hay\n","        avg_cost += ## code ##\n","        \n","    # guardamos nuestro coste en el histórico\n","    ## code ##\n","    \n","    # imprimimos las iteraciones\n","    print(\"[{}] cost: {}\".format(epoch, avg_cost))\n","\n","print(\"Entrenamiento finalizado!!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ILLQeB2UATrf"},"source":["# comprobamos lo que ha aprendido nuestra red\n","pred = ## Code##\n","correct_prediction =   ## Code##\n","\n","# calculamos el accuracy (precisión)\n","accuracy =   ## Code##\n","print(\"Accuracy:\", accuracy.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wh3pvylMzy9T"},"source":["# veamos nuestra función de pérdidas con respecto a las épocas ejecutadas\n","  ## Code##"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9warNBx5_7XY"},"source":["¡Ahí lo tenéis! Hemos llegado al mismo sitio de una forma más \"sencilla e intuitiva\". Para esto surgió TF2, pero es importante que sepáis que hace por debajo! A partir de ahora trabajaremos con TF2 y así tensorflow ejecutará los grafos por nosotros"]},{"cell_type":"markdown","metadata":{"id":"Kz9rSGWouAgm"},"source":["## ¡Y esto es todo amigos!\n","\n","<img src=\"https://image.ibb.co/jZEXD8/thats_all_folks.gif\" alt=\"thats_all_folks\" border=\"0\">\n","\n","Mañana veremos todo lo relacionado con el proceso de aprendizaje de las redes neuronales: los diferentes tipos de gradient descent, las funciones de pérdidas y activacion, el learning rate, el batch size, y la normalización.\n","\n","## ¡Así que cargad las pilas! ;-)"]}]}