{"cells":[{"cell_type":"markdown","metadata":{"id":"bpSt_OQ47_4P"},"source":["# Módulo 6. Optimización de hiper-parámetros\n","\n","¡Bienvenidos al sexto módulo! Ahora que ya sabemos lo que son las redes neuronales, las redes convolucionales y todos sus parámetros y entresijos, vamos a ver cómo podemos optimizarlas al máximo.\n","\n","Para ello, en este módulo veremos:\n","\n","\n","1. **Grid search**\n","\n","2. **Hyperopt**\n","\n","3. **Algoritmos genéticos**\n"]},{"cell_type":"markdown","metadata":{"id":"yvLzmsFm8bv9"},"source":["## 1. Grid search\n","\n","El grid search es el método más sencillo que existe para encontrar los mejores parámetros dentro de un conjunto. Esencialmente se trata de fuerza bruta. Vamos a ver un ejemplo sencillo:\n","\n","Suponed que tenemos nuestra anterior red y queremos ver qué parámetros son los mejores. Tenemos:\n","\n","* dropout: puede variar de 0 a 0.5 en intervalos 0.1\n","* learning rate: puede variar de 0.1 a 0.001 en intervalos de x10\n","* número de filtros: puede variar de 64 a 256 en intervalos de 64\n","* tamaños del filtro: puede variar desde 3 hasta 7 de 2 en 2 (filtros cuadrados siempre)\n","\n","Pues bien, lo que el grid search haría es los iguiente:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1675339036681,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"vA05n2y9DGgj","outputId":"2197553a-74e0-4a71-9666-212bc3e4fbce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ejecutando la red con d=0, lr=0.1, nf=64, fs=3\n","[1] Resultado: 0.19661973512024022\n","Ejecutando la red con d=0, lr=0.1, nf=64, fs=5\n","[2] Resultado: 0.6897227213907497\n","Ejecutando la red con d=0, lr=0.1, nf=64, fs=7\n","[3] Resultado: 0.36066861917870696\n","Ejecutando la red con d=0, lr=0.1, nf=128, fs=3\n","[4] Resultado: 0.3298865524847676\n","Ejecutando la red con d=0, lr=0.1, nf=128, fs=5\n","[5] Resultado: 0.3003231116506575\n","Ejecutando la red con d=0, lr=0.1, nf=128, fs=7\n","[6] Resultado: 0.6613869166950703\n","Ejecutando la red con d=0, lr=0.1, nf=192, fs=3\n","[7] Resultado: 0.9602528704234449\n","Ejecutando la red con d=0, lr=0.1, nf=192, fs=5\n","[8] Resultado: 0.08822187388808844\n","Ejecutando la red con d=0, lr=0.1, nf=192, fs=7\n","[9] Resultado: 0.6487446510078899\n","Ejecutando la red con d=0, lr=0.1, nf=256, fs=3\n","[10] Resultado: 0.30750915662025313\n","Ejecutando la red con d=0, lr=0.1, nf=256, fs=5\n","[11] Resultado: 0.6998012181465161\n","Ejecutando la red con d=0, lr=0.1, nf=256, fs=7\n","[12] Resultado: 0.9056137371647177\n","Ejecutando la red con d=0, lr=0.01, nf=64, fs=3\n","[13] Resultado: 0.2083106433930101\n","Ejecutando la red con d=0, lr=0.01, nf=64, fs=5\n","[14] Resultado: 0.4823516652032921\n","Ejecutando la red con d=0, lr=0.01, nf=64, fs=7\n","[15] Resultado: 0.2282989810811904\n","Ejecutando la red con d=0, lr=0.01, nf=128, fs=3\n","[16] Resultado: 0.9845968129026704\n","Ejecutando la red con d=0, lr=0.01, nf=128, fs=5\n","[17] Resultado: 0.09372044524516976\n","Ejecutando la red con d=0, lr=0.01, nf=128, fs=7\n","[18] Resultado: 0.8072946377012239\n","Ejecutando la red con d=0, lr=0.01, nf=192, fs=3\n","[19] Resultado: 0.029466018035372188\n","Ejecutando la red con d=0, lr=0.01, nf=192, fs=5\n","[20] Resultado: 0.43941170866858514\n","Ejecutando la red con d=0, lr=0.01, nf=192, fs=7\n","[21] Resultado: 0.9325934775370164\n","Ejecutando la red con d=0, lr=0.01, nf=256, fs=3\n","[22] Resultado: 0.09194439470100235\n","Ejecutando la red con d=0, lr=0.01, nf=256, fs=5\n","[23] Resultado: 0.7860312673937528\n","Ejecutando la red con d=0, lr=0.01, nf=256, fs=7\n","[24] Resultado: 0.6254933308056213\n","Ejecutando la red con d=0, lr=0.001, nf=64, fs=3\n","[25] Resultado: 0.46663205666722174\n","Ejecutando la red con d=0, lr=0.001, nf=64, fs=5\n","[26] Resultado: 0.5465133714662145\n","Ejecutando la red con d=0, lr=0.001, nf=64, fs=7\n","[27] Resultado: 0.9524886952937789\n","Ejecutando la red con d=0, lr=0.001, nf=128, fs=3\n","[28] Resultado: 0.6636094631051115\n","Ejecutando la red con d=0, lr=0.001, nf=128, fs=5\n","[29] Resultado: 0.17410323702273278\n","Ejecutando la red con d=0, lr=0.001, nf=128, fs=7\n","[30] Resultado: 0.39271761080658585\n","Ejecutando la red con d=0, lr=0.001, nf=192, fs=3\n","[31] Resultado: 0.46135197580254206\n","Ejecutando la red con d=0, lr=0.001, nf=192, fs=5\n","[32] Resultado: 0.9460581308796017\n","Ejecutando la red con d=0, lr=0.001, nf=192, fs=7\n","[33] Resultado: 0.5666372460370928\n","Ejecutando la red con d=0, lr=0.001, nf=256, fs=3\n","[34] Resultado: 0.5766930809036661\n","Ejecutando la red con d=0, lr=0.001, nf=256, fs=5\n","[35] Resultado: 0.9581551654234194\n","Ejecutando la red con d=0, lr=0.001, nf=256, fs=7\n","[36] Resultado: 0.9461341591035176\n","Ejecutando la red con d=0, lr=0.0001, nf=64, fs=3\n","[37] Resultado: 0.8863648324463717\n","Ejecutando la red con d=0, lr=0.0001, nf=64, fs=5\n","[38] Resultado: 0.21643257473371025\n","Ejecutando la red con d=0, lr=0.0001, nf=64, fs=7\n","[39] Resultado: 0.2865422902511502\n","Ejecutando la red con d=0, lr=0.0001, nf=128, fs=3\n","[40] Resultado: 0.11370414868248047\n","Ejecutando la red con d=0, lr=0.0001, nf=128, fs=5\n","[41] Resultado: 0.571037276691598\n","Ejecutando la red con d=0, lr=0.0001, nf=128, fs=7\n","[42] Resultado: 0.9588830523640667\n","Ejecutando la red con d=0, lr=0.0001, nf=192, fs=3\n","[43] Resultado: 0.6228732384000866\n","Ejecutando la red con d=0, lr=0.0001, nf=192, fs=5\n","[44] Resultado: 0.1315337700787622\n","Ejecutando la red con d=0, lr=0.0001, nf=192, fs=7\n","[45] Resultado: 0.39459548617127027\n","Ejecutando la red con d=0, lr=0.0001, nf=256, fs=3\n","[46] Resultado: 0.3391685499288619\n","Ejecutando la red con d=0, lr=0.0001, nf=256, fs=5\n","[47] Resultado: 0.7956308024597137\n","Ejecutando la red con d=0, lr=0.0001, nf=256, fs=7\n","[48] Resultado: 0.5497718206146063\n","Ejecutando la red con d=0.1, lr=0.1, nf=64, fs=3\n","[49] Resultado: 0.8845081528762484\n","Ejecutando la red con d=0.1, lr=0.1, nf=64, fs=5\n","[50] Resultado: 0.1460611987528333\n","Ejecutando la red con d=0.1, lr=0.1, nf=64, fs=7\n","[51] Resultado: 0.8650079584217296\n","Ejecutando la red con d=0.1, lr=0.1, nf=128, fs=3\n","[52] Resultado: 0.5709962054053886\n","Ejecutando la red con d=0.1, lr=0.1, nf=128, fs=5\n","[53] Resultado: 0.27433598651294\n","Ejecutando la red con d=0.1, lr=0.1, nf=128, fs=7\n","[54] Resultado: 0.3594651724588698\n","Ejecutando la red con d=0.1, lr=0.1, nf=192, fs=3\n","[55] Resultado: 0.8226664356781908\n","Ejecutando la red con d=0.1, lr=0.1, nf=192, fs=5\n","[56] Resultado: 0.18471590386150993\n","Ejecutando la red con d=0.1, lr=0.1, nf=192, fs=7\n","[57] Resultado: 0.3543850827331061\n","Ejecutando la red con d=0.1, lr=0.1, nf=256, fs=3\n","[58] Resultado: 0.5002897826420232\n","Ejecutando la red con d=0.1, lr=0.1, nf=256, fs=5\n","[59] Resultado: 0.9435389454582339\n","Ejecutando la red con d=0.1, lr=0.1, nf=256, fs=7\n","[60] Resultado: 0.9495697553555682\n","Ejecutando la red con d=0.1, lr=0.01, nf=64, fs=3\n","[61] Resultado: 0.07891268155393139\n","Ejecutando la red con d=0.1, lr=0.01, nf=64, fs=5\n","[62] Resultado: 0.607473504094541\n","Ejecutando la red con d=0.1, lr=0.01, nf=64, fs=7\n","[63] Resultado: 0.7572938259917414\n","Ejecutando la red con d=0.1, lr=0.01, nf=128, fs=3\n","[64] Resultado: 0.7572543512180535\n","Ejecutando la red con d=0.1, lr=0.01, nf=128, fs=5\n","[65] Resultado: 0.824314545145255\n","Ejecutando la red con d=0.1, lr=0.01, nf=128, fs=7\n","[66] Resultado: 0.9618363096268461\n","Ejecutando la red con d=0.1, lr=0.01, nf=192, fs=3\n","[67] Resultado: 0.1906945328499784\n","Ejecutando la red con d=0.1, lr=0.01, nf=192, fs=5\n","[68] Resultado: 0.24554883731623645\n","Ejecutando la red con d=0.1, lr=0.01, nf=192, fs=7\n","[69] Resultado: 0.8233191896095369\n","Ejecutando la red con d=0.1, lr=0.01, nf=256, fs=3\n","[70] Resultado: 0.10724653325163658\n","Ejecutando la red con d=0.1, lr=0.01, nf=256, fs=5\n","[71] Resultado: 0.5024084619618432\n","Ejecutando la red con d=0.1, lr=0.01, nf=256, fs=7\n","[72] Resultado: 0.27567744653579096\n","Ejecutando la red con d=0.1, lr=0.001, nf=64, fs=3\n","[73] Resultado: 0.6579005826975473\n","Ejecutando la red con d=0.1, lr=0.001, nf=64, fs=5\n","[74] Resultado: 0.8408130655655773\n","Ejecutando la red con d=0.1, lr=0.001, nf=64, fs=7\n","[75] Resultado: 0.7651535350976724\n","Ejecutando la red con d=0.1, lr=0.001, nf=128, fs=3\n","[76] Resultado: 0.2029601589276231\n","Ejecutando la red con d=0.1, lr=0.001, nf=128, fs=5\n","[77] Resultado: 0.7574215371875953\n","Ejecutando la red con d=0.1, lr=0.001, nf=128, fs=7\n","[78] Resultado: 0.6823221188846625\n","Ejecutando la red con d=0.1, lr=0.001, nf=192, fs=3\n","[79] Resultado: 0.07669922329887102\n","Ejecutando la red con d=0.1, lr=0.001, nf=192, fs=5\n","[80] Resultado: 0.6085936578512015\n","Ejecutando la red con d=0.1, lr=0.001, nf=192, fs=7\n","[81] Resultado: 0.2352943003787259\n","Ejecutando la red con d=0.1, lr=0.001, nf=256, fs=3\n","[82] Resultado: 0.5665486815082158\n","Ejecutando la red con d=0.1, lr=0.001, nf=256, fs=5\n","[83] Resultado: 0.030700015856148677\n","Ejecutando la red con d=0.1, lr=0.001, nf=256, fs=7\n","[84] Resultado: 0.03605501847782355\n","Ejecutando la red con d=0.1, lr=0.0001, nf=64, fs=3\n","[85] Resultado: 0.4256665538727564\n","Ejecutando la red con d=0.1, lr=0.0001, nf=64, fs=5\n","[86] Resultado: 0.9242262251292861\n","Ejecutando la red con d=0.1, lr=0.0001, nf=64, fs=7\n","[87] Resultado: 0.6212688681365317\n","Ejecutando la red con d=0.1, lr=0.0001, nf=128, fs=3\n","[88] Resultado: 0.462944473409304\n","Ejecutando la red con d=0.1, lr=0.0001, nf=128, fs=5\n","[89] Resultado: 0.22957960271330924\n","Ejecutando la red con d=0.1, lr=0.0001, nf=128, fs=7\n","[90] Resultado: 0.821251407644033\n","Ejecutando la red con d=0.1, lr=0.0001, nf=192, fs=3\n","[91] Resultado: 0.03748745980244672\n","Ejecutando la red con d=0.1, lr=0.0001, nf=192, fs=5\n","[92] Resultado: 0.3325130322328267\n","Ejecutando la red con d=0.1, lr=0.0001, nf=192, fs=7\n","[93] Resultado: 0.900229189142111\n","Ejecutando la red con d=0.1, lr=0.0001, nf=256, fs=3\n","[94] Resultado: 0.347661096782535\n","Ejecutando la red con d=0.1, lr=0.0001, nf=256, fs=5\n","[95] Resultado: 0.34590992769681395\n","Ejecutando la red con d=0.1, lr=0.0001, nf=256, fs=7\n","[96] Resultado: 0.7638640327314655\n","Ejecutando la red con d=0.2, lr=0.1, nf=64, fs=3\n","[97] Resultado: 0.7535674129919044\n","Ejecutando la red con d=0.2, lr=0.1, nf=64, fs=5\n","[98] Resultado: 0.2903587920342261\n","Ejecutando la red con d=0.2, lr=0.1, nf=64, fs=7\n","[99] Resultado: 0.8142932894226071\n","Ejecutando la red con d=0.2, lr=0.1, nf=128, fs=3\n","[100] Resultado: 0.23934830404365393\n","Ejecutando la red con d=0.2, lr=0.1, nf=128, fs=5\n","[101] Resultado: 0.8019561458521709\n","Ejecutando la red con d=0.2, lr=0.1, nf=128, fs=7\n","[102] Resultado: 0.8278214282689789\n","Ejecutando la red con d=0.2, lr=0.1, nf=192, fs=3\n","[103] Resultado: 0.40820277370734903\n","Ejecutando la red con d=0.2, lr=0.1, nf=192, fs=5\n","[104] Resultado: 0.05499174841023513\n","Ejecutando la red con d=0.2, lr=0.1, nf=192, fs=7\n","[105] Resultado: 0.5521025615995203\n","Ejecutando la red con d=0.2, lr=0.1, nf=256, fs=3\n","[106] Resultado: 0.691000662798895\n","Ejecutando la red con d=0.2, lr=0.1, nf=256, fs=5\n","[107] Resultado: 0.42394200049806763\n","Ejecutando la red con d=0.2, lr=0.1, nf=256, fs=7\n","[108] Resultado: 0.9195068111195578\n","Ejecutando la red con d=0.2, lr=0.01, nf=64, fs=3\n","[109] Resultado: 0.4486242493899525\n","Ejecutando la red con d=0.2, lr=0.01, nf=64, fs=5\n","[110] Resultado: 0.8538571527418435\n","Ejecutando la red con d=0.2, lr=0.01, nf=64, fs=7\n","[111] Resultado: 0.35533092607273353\n","Ejecutando la red con d=0.2, lr=0.01, nf=128, fs=3\n","[112] Resultado: 0.2780158720230069\n","Ejecutando la red con d=0.2, lr=0.01, nf=128, fs=5\n","[113] Resultado: 0.23051865248294123\n","Ejecutando la red con d=0.2, lr=0.01, nf=128, fs=7\n","[114] Resultado: 0.69339568665674\n","Ejecutando la red con d=0.2, lr=0.01, nf=192, fs=3\n","[115] Resultado: 0.6250177686732388\n","Ejecutando la red con d=0.2, lr=0.01, nf=192, fs=5\n","[116] Resultado: 0.560239079102095\n","Ejecutando la red con d=0.2, lr=0.01, nf=192, fs=7\n","[117] Resultado: 0.8291316902514214\n","Ejecutando la red con d=0.2, lr=0.01, nf=256, fs=3\n","[118] Resultado: 0.4885503927156172\n","Ejecutando la red con d=0.2, lr=0.01, nf=256, fs=5\n","[119] Resultado: 0.33342792953421163\n","Ejecutando la red con d=0.2, lr=0.01, nf=256, fs=7\n","[120] Resultado: 0.07812034559084158\n","Ejecutando la red con d=0.2, lr=0.001, nf=64, fs=3\n","[121] Resultado: 0.24863389771764655\n","Ejecutando la red con d=0.2, lr=0.001, nf=64, fs=5\n","[122] Resultado: 0.35339798207939477\n","Ejecutando la red con d=0.2, lr=0.001, nf=64, fs=7\n","[123] Resultado: 0.9781717434926016\n","Ejecutando la red con d=0.2, lr=0.001, nf=128, fs=3\n","[124] Resultado: 0.7673213315279827\n","Ejecutando la red con d=0.2, lr=0.001, nf=128, fs=5\n","[125] Resultado: 0.48981026785664317\n","Ejecutando la red con d=0.2, lr=0.001, nf=128, fs=7\n","[126] Resultado: 0.7393010160360812\n","Ejecutando la red con d=0.2, lr=0.001, nf=192, fs=3\n","[127] Resultado: 0.5332458155678819\n","Ejecutando la red con d=0.2, lr=0.001, nf=192, fs=5\n","[128] Resultado: 0.8408868028559622\n","Ejecutando la red con d=0.2, lr=0.001, nf=192, fs=7\n","[129] Resultado: 0.3382193436951404\n","Ejecutando la red con d=0.2, lr=0.001, nf=256, fs=3\n","[130] Resultado: 0.8056919249557793\n","Ejecutando la red con d=0.2, lr=0.001, nf=256, fs=5\n","[131] Resultado: 0.07703068186177797\n","Ejecutando la red con d=0.2, lr=0.001, nf=256, fs=7\n","[132] Resultado: 0.8358764940320006\n","Ejecutando la red con d=0.2, lr=0.0001, nf=64, fs=3\n","[133] Resultado: 0.9527428296056784\n","Ejecutando la red con d=0.2, lr=0.0001, nf=64, fs=5\n","[134] Resultado: 0.7718680240775005\n","Ejecutando la red con d=0.2, lr=0.0001, nf=64, fs=7\n","[135] Resultado: 0.10564318710472742\n","Ejecutando la red con d=0.2, lr=0.0001, nf=128, fs=3\n","[136] Resultado: 0.3989711999261544\n","Ejecutando la red con d=0.2, lr=0.0001, nf=128, fs=5\n","[137] Resultado: 0.19607123996765696\n","Ejecutando la red con d=0.2, lr=0.0001, nf=128, fs=7\n","[138] Resultado: 0.21551115430451628\n","Ejecutando la red con d=0.2, lr=0.0001, nf=192, fs=3\n","[139] Resultado: 0.05375140254563937\n","Ejecutando la red con d=0.2, lr=0.0001, nf=192, fs=5\n","[140] Resultado: 0.5201273875846214\n","Ejecutando la red con d=0.2, lr=0.0001, nf=192, fs=7\n","[141] Resultado: 0.6145398805276967\n","Ejecutando la red con d=0.2, lr=0.0001, nf=256, fs=3\n","[142] Resultado: 0.6461650481441787\n","Ejecutando la red con d=0.2, lr=0.0001, nf=256, fs=5\n","[143] Resultado: 0.5804783433081868\n","Ejecutando la red con d=0.2, lr=0.0001, nf=256, fs=7\n","[144] Resultado: 0.7885364502488486\n","Ejecutando la red con d=0.3, lr=0.1, nf=64, fs=3\n","[145] Resultado: 0.5778324464696073\n","Ejecutando la red con d=0.3, lr=0.1, nf=64, fs=5\n","[146] Resultado: 0.2225113297744159\n","Ejecutando la red con d=0.3, lr=0.1, nf=64, fs=7\n","[147] Resultado: 0.8076288163303359\n","Ejecutando la red con d=0.3, lr=0.1, nf=128, fs=3\n","[148] Resultado: 0.23325159420058705\n","Ejecutando la red con d=0.3, lr=0.1, nf=128, fs=5\n","[149] Resultado: 0.8881553162180341\n","Ejecutando la red con d=0.3, lr=0.1, nf=128, fs=7\n","[150] Resultado: 0.5260160914836385\n","Ejecutando la red con d=0.3, lr=0.1, nf=192, fs=3\n","[151] Resultado: 0.12584799139813097\n","Ejecutando la red con d=0.3, lr=0.1, nf=192, fs=5\n","[152] Resultado: 0.10381706873820418\n","Ejecutando la red con d=0.3, lr=0.1, nf=192, fs=7\n","[153] Resultado: 0.18387013033673172\n","Ejecutando la red con d=0.3, lr=0.1, nf=256, fs=3\n","[154] Resultado: 0.5216311239718626\n","Ejecutando la red con d=0.3, lr=0.1, nf=256, fs=5\n","[155] Resultado: 0.6250674964208016\n","Ejecutando la red con d=0.3, lr=0.1, nf=256, fs=7\n","[156] Resultado: 0.39663743545936925\n","Ejecutando la red con d=0.3, lr=0.01, nf=64, fs=3\n","[157] Resultado: 0.058974725295504404\n","Ejecutando la red con d=0.3, lr=0.01, nf=64, fs=5\n","[158] Resultado: 0.5564407863040554\n","Ejecutando la red con d=0.3, lr=0.01, nf=64, fs=7\n","[159] Resultado: 0.5782905015805365\n","Ejecutando la red con d=0.3, lr=0.01, nf=128, fs=3\n","[160] Resultado: 0.7560960187892645\n","Ejecutando la red con d=0.3, lr=0.01, nf=128, fs=5\n","[161] Resultado: 0.20285236555547181\n","Ejecutando la red con d=0.3, lr=0.01, nf=128, fs=7\n","[162] Resultado: 0.19158891853658133\n","Ejecutando la red con d=0.3, lr=0.01, nf=192, fs=3\n","[163] Resultado: 0.4582489751476041\n","Ejecutando la red con d=0.3, lr=0.01, nf=192, fs=5\n","[164] Resultado: 0.4561020354795121\n","Ejecutando la red con d=0.3, lr=0.01, nf=192, fs=7\n","[165] Resultado: 0.8263281928850041\n","Ejecutando la red con d=0.3, lr=0.01, nf=256, fs=3\n","[166] Resultado: 0.08793917156408193\n","Ejecutando la red con d=0.3, lr=0.01, nf=256, fs=5\n","[167] Resultado: 0.3430347319710061\n","Ejecutando la red con d=0.3, lr=0.01, nf=256, fs=7\n","[168] Resultado: 0.13849359328131505\n","Ejecutando la red con d=0.3, lr=0.001, nf=64, fs=3\n","[169] Resultado: 0.22733356636429858\n","Ejecutando la red con d=0.3, lr=0.001, nf=64, fs=5\n","[170] Resultado: 0.7463995476548368\n","Ejecutando la red con d=0.3, lr=0.001, nf=64, fs=7\n","[171] Resultado: 0.22116808261906307\n","Ejecutando la red con d=0.3, lr=0.001, nf=128, fs=3\n","[172] Resultado: 0.7610956983389838\n","Ejecutando la red con d=0.3, lr=0.001, nf=128, fs=5\n","[173] Resultado: 0.35940588387895145\n","Ejecutando la red con d=0.3, lr=0.001, nf=128, fs=7\n","[174] Resultado: 0.3830896817038044\n","Ejecutando la red con d=0.3, lr=0.001, nf=192, fs=3\n","[175] Resultado: 0.4347891192921165\n","Ejecutando la red con d=0.3, lr=0.001, nf=192, fs=5\n","[176] Resultado: 0.05236343579785985\n","Ejecutando la red con d=0.3, lr=0.001, nf=192, fs=7\n","[177] Resultado: 0.45784836219348446\n","Ejecutando la red con d=0.3, lr=0.001, nf=256, fs=3\n","[178] Resultado: 0.19843255262730453\n","Ejecutando la red con d=0.3, lr=0.001, nf=256, fs=5\n","[179] Resultado: 0.7796974837825174\n","Ejecutando la red con d=0.3, lr=0.001, nf=256, fs=7\n","[180] Resultado: 0.046546316968899215\n","Ejecutando la red con d=0.3, lr=0.0001, nf=64, fs=3\n","[181] Resultado: 0.25606223968834296\n","Ejecutando la red con d=0.3, lr=0.0001, nf=64, fs=5\n","[182] Resultado: 0.5563863542389115\n","Ejecutando la red con d=0.3, lr=0.0001, nf=64, fs=7\n","[183] Resultado: 0.7594639626299768\n","Ejecutando la red con d=0.3, lr=0.0001, nf=128, fs=3\n","[184] Resultado: 0.3585035243994058\n","Ejecutando la red con d=0.3, lr=0.0001, nf=128, fs=5\n","[185] Resultado: 0.8388470168820787\n","Ejecutando la red con d=0.3, lr=0.0001, nf=128, fs=7\n","[186] Resultado: 0.5617765845609716\n","Ejecutando la red con d=0.3, lr=0.0001, nf=192, fs=3\n","[187] Resultado: 0.4179905350672062\n","Ejecutando la red con d=0.3, lr=0.0001, nf=192, fs=5\n","[188] Resultado: 0.07064401759269967\n","Ejecutando la red con d=0.3, lr=0.0001, nf=192, fs=7\n","[189] Resultado: 0.3440411933484129\n","Ejecutando la red con d=0.3, lr=0.0001, nf=256, fs=3\n","[190] Resultado: 0.1314338638952527\n","Ejecutando la red con d=0.3, lr=0.0001, nf=256, fs=5\n","[191] Resultado: 0.7257538209720218\n","Ejecutando la red con d=0.3, lr=0.0001, nf=256, fs=7\n","[192] Resultado: 0.6802744602453036\n","Ejecutando la red con d=0.4, lr=0.1, nf=64, fs=3\n","[193] Resultado: 0.9573081338452689\n","Ejecutando la red con d=0.4, lr=0.1, nf=64, fs=5\n","[194] Resultado: 0.5142722455178792\n","Ejecutando la red con d=0.4, lr=0.1, nf=64, fs=7\n","[195] Resultado: 0.32397826166131327\n","Ejecutando la red con d=0.4, lr=0.1, nf=128, fs=3\n","[196] Resultado: 0.24425438902088925\n","Ejecutando la red con d=0.4, lr=0.1, nf=128, fs=5\n","[197] Resultado: 0.3504498329736284\n","Ejecutando la red con d=0.4, lr=0.1, nf=128, fs=7\n","[198] Resultado: 0.1642235658860055\n","Ejecutando la red con d=0.4, lr=0.1, nf=192, fs=3\n","[199] Resultado: 0.5589249430540074\n","Ejecutando la red con d=0.4, lr=0.1, nf=192, fs=5\n","[200] Resultado: 0.8348062175981721\n","Ejecutando la red con d=0.4, lr=0.1, nf=192, fs=7\n","[201] Resultado: 0.9748202127450761\n","Ejecutando la red con d=0.4, lr=0.1, nf=256, fs=3\n","[202] Resultado: 0.22298106430122877\n","Ejecutando la red con d=0.4, lr=0.1, nf=256, fs=5\n","[203] Resultado: 0.4596662893205018\n","Ejecutando la red con d=0.4, lr=0.1, nf=256, fs=7\n","[204] Resultado: 0.7781347889543954\n","Ejecutando la red con d=0.4, lr=0.01, nf=64, fs=3\n","[205] Resultado: 0.5795725897472953\n","Ejecutando la red con d=0.4, lr=0.01, nf=64, fs=5\n","[206] Resultado: 0.24105610748033957\n","Ejecutando la red con d=0.4, lr=0.01, nf=64, fs=7\n","[207] Resultado: 0.8629304335792688\n","Ejecutando la red con d=0.4, lr=0.01, nf=128, fs=3\n","[208] Resultado: 0.3004737805957254\n","Ejecutando la red con d=0.4, lr=0.01, nf=128, fs=5\n","[209] Resultado: 0.2978924229856831\n","Ejecutando la red con d=0.4, lr=0.01, nf=128, fs=7\n","[210] Resultado: 0.5187515265697279\n","Ejecutando la red con d=0.4, lr=0.01, nf=192, fs=3\n","[211] Resultado: 0.668316002550162\n","Ejecutando la red con d=0.4, lr=0.01, nf=192, fs=5\n","[212] Resultado: 0.5779466292887128\n","Ejecutando la red con d=0.4, lr=0.01, nf=192, fs=7\n","[213] Resultado: 0.5293866632715507\n","Ejecutando la red con d=0.4, lr=0.01, nf=256, fs=3\n","[214] Resultado: 0.27269763680133774\n","Ejecutando la red con d=0.4, lr=0.01, nf=256, fs=5\n","[215] Resultado: 0.08319582205729914\n","Ejecutando la red con d=0.4, lr=0.01, nf=256, fs=7\n","[216] Resultado: 0.8345379057885857\n","Ejecutando la red con d=0.4, lr=0.001, nf=64, fs=3\n","[217] Resultado: 0.09473484426739631\n","Ejecutando la red con d=0.4, lr=0.001, nf=64, fs=5\n","[218] Resultado: 0.6372092408332921\n","Ejecutando la red con d=0.4, lr=0.001, nf=64, fs=7\n","[219] Resultado: 0.738336520154112\n","Ejecutando la red con d=0.4, lr=0.001, nf=128, fs=3\n","[220] Resultado: 0.8351768708959287\n","Ejecutando la red con d=0.4, lr=0.001, nf=128, fs=5\n","[221] Resultado: 0.9769070955836406\n","Ejecutando la red con d=0.4, lr=0.001, nf=128, fs=7\n","[222] Resultado: 0.5320745985933133\n","Ejecutando la red con d=0.4, lr=0.001, nf=192, fs=3\n","[223] Resultado: 0.6223713636452205\n","Ejecutando la red con d=0.4, lr=0.001, nf=192, fs=5\n","[224] Resultado: 0.5423751699492868\n","Ejecutando la red con d=0.4, lr=0.001, nf=192, fs=7\n","[225] Resultado: 0.9424756146094978\n","Ejecutando la red con d=0.4, lr=0.001, nf=256, fs=3\n","[226] Resultado: 0.7872252307986641\n","Ejecutando la red con d=0.4, lr=0.001, nf=256, fs=5\n","[227] Resultado: 0.5087602296712805\n","Ejecutando la red con d=0.4, lr=0.001, nf=256, fs=7\n","[228] Resultado: 0.2819959488285274\n","Ejecutando la red con d=0.4, lr=0.0001, nf=64, fs=3\n","[229] Resultado: 0.9605683923614396\n","Ejecutando la red con d=0.4, lr=0.0001, nf=64, fs=5\n","[230] Resultado: 0.7023384652557727\n","Ejecutando la red con d=0.4, lr=0.0001, nf=64, fs=7\n","[231] Resultado: 0.6606836691319941\n","Ejecutando la red con d=0.4, lr=0.0001, nf=128, fs=3\n","[232] Resultado: 0.3411020194534856\n","Ejecutando la red con d=0.4, lr=0.0001, nf=128, fs=5\n","[233] Resultado: 0.09980614325817283\n","Ejecutando la red con d=0.4, lr=0.0001, nf=128, fs=7\n","[234] Resultado: 0.3166342274612537\n","Ejecutando la red con d=0.4, lr=0.0001, nf=192, fs=3\n","[235] Resultado: 0.5551425598054243\n","Ejecutando la red con d=0.4, lr=0.0001, nf=192, fs=5\n","[236] Resultado: 0.5707943938962053\n","Ejecutando la red con d=0.4, lr=0.0001, nf=192, fs=7\n","[237] Resultado: 0.33397337052793086\n","Ejecutando la red con d=0.4, lr=0.0001, nf=256, fs=3\n","[238] Resultado: 0.7327397911183207\n","Ejecutando la red con d=0.4, lr=0.0001, nf=256, fs=5\n","[239] Resultado: 0.4703995098645025\n","Ejecutando la red con d=0.4, lr=0.0001, nf=256, fs=7\n","[240] Resultado: 0.9778699573802674\n","Ejecutando la red con d=0.5, lr=0.1, nf=64, fs=3\n","[241] Resultado: 0.6043546424550751\n","Ejecutando la red con d=0.5, lr=0.1, nf=64, fs=5\n","[242] Resultado: 0.9505630238853753\n","Ejecutando la red con d=0.5, lr=0.1, nf=64, fs=7\n","[243] Resultado: 0.3347879661309001\n","Ejecutando la red con d=0.5, lr=0.1, nf=128, fs=3\n","[244] Resultado: 0.9829741143807227\n","Ejecutando la red con d=0.5, lr=0.1, nf=128, fs=5\n","[245] Resultado: 0.6360001238770701\n","Ejecutando la red con d=0.5, lr=0.1, nf=128, fs=7\n","[246] Resultado: 0.39730545596009725\n","Ejecutando la red con d=0.5, lr=0.1, nf=192, fs=3\n","[247] Resultado: 0.948827524019146\n","Ejecutando la red con d=0.5, lr=0.1, nf=192, fs=5\n","[248] Resultado: 0.4718255253944573\n","Ejecutando la red con d=0.5, lr=0.1, nf=192, fs=7\n","[249] Resultado: 0.15111803552590986\n","Ejecutando la red con d=0.5, lr=0.1, nf=256, fs=3\n","[250] Resultado: 0.20099778812802505\n","Ejecutando la red con d=0.5, lr=0.1, nf=256, fs=5\n","[251] Resultado: 0.4941821061227897\n","Ejecutando la red con d=0.5, lr=0.1, nf=256, fs=7\n","[252] Resultado: 0.4251521701873112\n","Ejecutando la red con d=0.5, lr=0.01, nf=64, fs=3\n","[253] Resultado: 0.3105458647912591\n","Ejecutando la red con d=0.5, lr=0.01, nf=64, fs=5\n","[254] Resultado: 0.8069940991664475\n","Ejecutando la red con d=0.5, lr=0.01, nf=64, fs=7\n","[255] Resultado: 0.14205773949046774\n","Ejecutando la red con d=0.5, lr=0.01, nf=128, fs=3\n","[256] Resultado: 0.8289965313427943\n","Ejecutando la red con d=0.5, lr=0.01, nf=128, fs=5\n","[257] Resultado: 0.2243092618545348\n","Ejecutando la red con d=0.5, lr=0.01, nf=128, fs=7\n","[258] Resultado: 0.9216771208222021\n","Ejecutando la red con d=0.5, lr=0.01, nf=192, fs=3\n","[259] Resultado: 0.05201864281597168\n","Ejecutando la red con d=0.5, lr=0.01, nf=192, fs=5\n","[260] Resultado: 0.27862962549574555\n","Ejecutando la red con d=0.5, lr=0.01, nf=192, fs=7\n","[261] Resultado: 0.96314357667735\n","Ejecutando la red con d=0.5, lr=0.01, nf=256, fs=3\n","[262] Resultado: 0.63768956543626\n","Ejecutando la red con d=0.5, lr=0.01, nf=256, fs=5\n","[263] Resultado: 0.9564777928903699\n","Ejecutando la red con d=0.5, lr=0.01, nf=256, fs=7\n","[264] Resultado: 0.29270611097641563\n","Ejecutando la red con d=0.5, lr=0.001, nf=64, fs=3\n","[265] Resultado: 0.802467046789628\n","Ejecutando la red con d=0.5, lr=0.001, nf=64, fs=5\n","[266] Resultado: 0.7853227407883865\n","Ejecutando la red con d=0.5, lr=0.001, nf=64, fs=7\n","[267] Resultado: 0.19838466274159794\n","Ejecutando la red con d=0.5, lr=0.001, nf=128, fs=3\n","[268] Resultado: 0.5209217854492398\n","Ejecutando la red con d=0.5, lr=0.001, nf=128, fs=5\n","[269] Resultado: 0.786647407331698\n","Ejecutando la red con d=0.5, lr=0.001, nf=128, fs=7\n","[270] Resultado: 0.6767153131545055\n","Ejecutando la red con d=0.5, lr=0.001, nf=192, fs=3\n","[271] Resultado: 0.610548082473328\n","Ejecutando la red con d=0.5, lr=0.001, nf=192, fs=5\n","[272] Resultado: 0.10953521069374517\n","Ejecutando la red con d=0.5, lr=0.001, nf=192, fs=7\n","[273] Resultado: 0.9148532825113818\n","Ejecutando la red con d=0.5, lr=0.001, nf=256, fs=3\n","[274] Resultado: 0.9615992539068153\n","Ejecutando la red con d=0.5, lr=0.001, nf=256, fs=5\n","[275] Resultado: 0.4958847280159212\n","Ejecutando la red con d=0.5, lr=0.001, nf=256, fs=7\n","[276] Resultado: 0.10499117773264188\n","Ejecutando la red con d=0.5, lr=0.0001, nf=64, fs=3\n","[277] Resultado: 0.2909006602864146\n","Ejecutando la red con d=0.5, lr=0.0001, nf=64, fs=5\n","[278] Resultado: 0.1295562283230458\n","Ejecutando la red con d=0.5, lr=0.0001, nf=64, fs=7\n","[279] Resultado: 0.9796610031362347\n","Ejecutando la red con d=0.5, lr=0.0001, nf=128, fs=3\n","[280] Resultado: 0.19424551173143467\n","Ejecutando la red con d=0.5, lr=0.0001, nf=128, fs=5\n","[281] Resultado: 0.7622283781982708\n","Ejecutando la red con d=0.5, lr=0.0001, nf=128, fs=7\n","[282] Resultado: 0.38628763555161383\n","Ejecutando la red con d=0.5, lr=0.0001, nf=192, fs=3\n","[283] Resultado: 0.6345063650595152\n","Ejecutando la red con d=0.5, lr=0.0001, nf=192, fs=5\n","[284] Resultado: 0.1233484921689596\n","Ejecutando la red con d=0.5, lr=0.0001, nf=192, fs=7\n","[285] Resultado: 0.17088737490872985\n","Ejecutando la red con d=0.5, lr=0.0001, nf=256, fs=3\n","[286] Resultado: 0.7962761056668771\n","Ejecutando la red con d=0.5, lr=0.0001, nf=256, fs=5\n","[287] Resultado: 0.8115009625972966\n","Ejecutando la red con d=0.5, lr=0.0001, nf=256, fs=7\n","[288] Resultado: 0.02894707047745204\n"]}],"source":["# definimos nuestra grid\n","dropouts = [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n","learning_rates = [0.1, 0.01, 0.001, 0.0001]\n","n_filters = [64, 128, 192, 256]\n","filter_sizes = [3, 5, 7]\n","\n","# creamos una variable para guardar nuestras accuracies\n","log_accuracies = []\n","\n","# para hacer esta prueba definimos una función que sustituye a nuestra red y \n","# asigna un valor aleatorio cada vez\n","# si lo hiciésemos con nuestra red de verdad, tardaría demasiado como para verlo\n","# en clase\n","from random import uniform\n","def dummy_net(d, lr, nf, fs):\n","  print('Ejecutando la red con d={}, lr={}, nf={}, fs={}'.format(d, lr, nf, fs))\n","  return uniform(0,1)\n","\n","# contador\n","i = 1\n","\n","# empezamos el grid search\n","for d in dropouts:\n","  for lr in learning_rates:\n","    for nf in n_filters:\n","      for fs in filter_sizes:\n","        result_net = dummy_net(d, lr, nf, fs)\n","        print('[{}] Resultado: {}'.format(i, result_net))\n","        log_accuracies.append(result_net)\n","        i += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1675339042215,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"_3H4yePeLZTV","outputId":"337a0d74-8fba-40ae-8e9a-c4c657a37b68"},"outputs":[{"name":"stdout","output_type":"stream","text":["(array([15]),)\n","Best execution: 15. Accuracy: 0.9845968129026704\n"]}],"source":["# y el mejor resultado sería\n","import numpy as np\n","idx_max = np.nonzero(log_accuracies==np.max(log_accuracies))\n","print(idx_max)\n","\n","print('Best execution: {}. Accuracy: {}'.format(idx_max[0][0], log_accuracies[idx_max[0][0]]))"]},{"cell_type":"markdown","metadata":{"id":"ty5EDQgLJkkf"},"source":["Y con esto sabríamos cuál es la mejor configuración de nuestra red. Mucho mejor que andar cambiando parámetros a mano, ¿verdad?\n","\n","¿Cuál es el problema de este método? Pues que tenemos 6 x 4 x 4 x 3 ejecuciones de nuestra red, lo que hacen un total de 288 ejecuciones, a un mínimo de 10 minutos por ejecución, son 48 horas, ¡¡¡2 días!!!\n","\n","Si queréis comprobarlo no tenéis más que meter dentro de dummy_net la arquitectura de la red y ejecutarlo ;-)\n","\n","Vamos a hacer una prueba con una red muy sencillita para que veáis qué tal funciona:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3836,"status":"ok","timestamp":1675339078305,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"CAsIhauG3Fl8","outputId":"1a4a7e58-f752-457e-ed25-d590c8f66d1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n"]}],"source":["# importamos los paquetes necesarios\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D,MaxPooling2D, Dense, Dropout, Flatten\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.optimizers import Adam\n","\n","# cargamos los datos y pasamos de vector a imagen\n","img_rows, img_cols = 28, 28\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","input_shape = (img_rows, img_cols, 1)\n","\n","# normalizamos\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","# convert class vectors to binary class matrices\n","num_classes = 10\n","y_train = to_categorical(y_train, num_classes)\n","y_test = to_categorical(y_test, num_classes)\n","\n","def net(do, lr, nf, fs):\n","\n","  model = Sequential()\n","  model.add(Conv2D(nf, kernel_size=fs, activation='relu', input_shape=input_shape))\n","  model.add(Conv2D(nf, fs, activation='relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","  model.add(Dropout(do))\n","  model.add(Flatten())\n","  model.add(Dense(128, activation='relu'))\n","  model.add(Dropout(do))\n","  model.add(Dense(10, activation='softmax'))\n","\n","  model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr), metrics=['accuracy'])\n","\n","  model.fit(x_train, y_train,\n","            batch_size=1024,\n","            epochs=1,\n","            verbose=0,\n","            validation_data=(x_test, y_test))\n","\n","  score = model.evaluate(x_test, y_test, verbose=0)\n","  \n","  print('Red con d={}, lr={}, nf={}, fs={}. Loss: {}. Acc: {}.'.format(d, lr, nf, fs, score[0], score[1]))      \n","  return score[1] # accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":102216,"status":"ok","timestamp":1675339316208,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"RWl0Fm0j2exL","outputId":"0bfef289-5ce1-4224-aed0-408f4a928e62"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Red con d=0, lr=0.1, nf=32, fs=3. Loss: 2.3025612831115723. Acc: 0.11349999904632568.\n","[1] Resultado: 0.11349999904632568\n","Red con d=0, lr=0.1, nf=32, fs=5. Loss: 2.302077531814575. Acc: 0.11349999904632568.\n","[2] Resultado: 0.11349999904632568\n","Red con d=0, lr=0.1, nf=64, fs=3. Loss: 2.301684617996216. Acc: 0.11349999904632568.\n","[3] Resultado: 0.11349999904632568\n","Red con d=0, lr=0.1, nf=64, fs=5. Loss: 2.3017165660858154. Acc: 0.11349999904632568.\n","[4] Resultado: 0.11349999904632568\n","Red con d=0, lr=0.01, nf=32, fs=3. Loss: 0.05965760350227356. Acc: 0.9807999730110168.\n","[5] Resultado: 0.9807999730110168\n","Red con d=0, lr=0.01, nf=32, fs=5. Loss: 0.06504429131746292. Acc: 0.9789999723434448.\n","[6] Resultado: 0.9789999723434448\n","Red con d=0, lr=0.01, nf=64, fs=3. Loss: 0.07252343744039536. Acc: 0.9769999980926514.\n","[7] Resultado: 0.9769999980926514\n","Red con d=0, lr=0.01, nf=64, fs=5. Loss: 0.06412394344806671. Acc: 0.9790999889373779.\n","[8] Resultado: 0.9790999889373779\n","Red con d=0.3, lr=0.1, nf=32, fs=3. Loss: 2.301408290863037. Acc: 0.11349999904632568.\n","[9] Resultado: 0.11349999904632568\n","Red con d=0.3, lr=0.1, nf=32, fs=5. Loss: 2.3018977642059326. Acc: 0.11349999904632568.\n","[10] Resultado: 0.11349999904632568\n","Red con d=0.3, lr=0.1, nf=64, fs=3. Loss: 2.3019378185272217. Acc: 0.11349999904632568.\n","[11] Resultado: 0.11349999904632568\n","Red con d=0.3, lr=0.1, nf=64, fs=5. Loss: 2.301274299621582. Acc: 0.11349999904632568.\n","[12] Resultado: 0.11349999904632568\n","Red con d=0.3, lr=0.01, nf=32, fs=3. Loss: 0.072371706366539. Acc: 0.9761000275611877.\n","[13] Resultado: 0.9761000275611877\n","Red con d=0.3, lr=0.01, nf=32, fs=5. Loss: 0.050683531910181046. Acc: 0.9837999939918518.\n","[14] Resultado: 0.9837999939918518\n","Red con d=0.3, lr=0.01, nf=64, fs=3. Loss: 0.05276474729180336. Acc: 0.9825999736785889.\n","[15] Resultado: 0.9825999736785889\n","Red con d=0.3, lr=0.01, nf=64, fs=5. Loss: 0.07277051359415054. Acc: 0.9761000275611877.\n","[16] Resultado: 0.9761000275611877\n","(array([13]),)\n","Best execution: 13. Accuracy: 0.9837999939918518\n"]}],"source":["# definimos nuestra grid\n","dropouts = [0, 0.3]\n","learning_rates = [0.1, 0.01]\n","n_filters = [32, 64]\n","filter_sizes = [3, 5]\n","\n","# creamos una variable para guardar nuestras accuracies\n","log_accuracies = []\n","\n","# contador\n","i = 1\n","\n","# empezamos el grid search\n","for d in dropouts:\n","  for lr in learning_rates:\n","    for nf in n_filters:\n","      for fs in filter_sizes:\n","        result_net = net(d, lr, nf, fs)\n","        print('[{}] Resultado: {}'.format(i, result_net))\n","        log_accuracies.append(result_net)\n","        i += 1\n","        \n","# y el mejor resultado sería\n","import numpy as np\n","idx_max = np.nonzero(log_accuracies==np.max(log_accuracies))\n","print(idx_max)\n","\n","print('Best execution: {}. Accuracy: {}'.format(idx_max[0][0], log_accuracies[idx_max[0][0]]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52392,"status":"ok","timestamp":1653549873955,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-120},"id":"lleM0ooV7xGQ","outputId":"5ca52483-3a7f-4c2e-deec-81548bfa4ebd"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Red con d=0, lr=0.01, nf=32, fs=5. Loss: 0.05877402424812317. Acc: 0.9818000197410583.\n","[1] Resultado: 0.9818000197410583\n","Red con d=0, lr=0.01, nf=32, fs=7. Loss: 0.0606892891228199. Acc: 0.9814000129699707.\n","[2] Resultado: 0.9814000129699707\n","Red con d=0, lr=0.01, nf=64, fs=5. Loss: 0.06242161989212036. Acc: 0.9807000160217285.\n","[3] Resultado: 0.9807000160217285\n","Red con d=0, lr=0.01, nf=64, fs=7. Loss: 0.06790235638618469. Acc: 0.9789000153541565.\n","[4] Resultado: 0.9789000153541565\n","Red con d=0, lr=0.01, nf=128, fs=5. Loss: 0.06226867064833641. Acc: 0.9799000024795532.\n","[5] Resultado: 0.9799000024795532\n","Red con d=0, lr=0.01, nf=128, fs=7. Loss: 0.07306826114654541. Acc: 0.9768000245094299.\n","[6] Resultado: 0.9768000245094299\n","Red con d=0.3, lr=0.01, nf=32, fs=5. Loss: 0.0549386590719223. Acc: 0.9811999797821045.\n","[7] Resultado: 0.9811999797821045\n","Red con d=0.3, lr=0.01, nf=32, fs=7. Loss: 0.05194045975804329. Acc: 0.9842000007629395.\n","[8] Resultado: 0.9842000007629395\n","Red con d=0.3, lr=0.01, nf=64, fs=5. Loss: 0.05857934057712555. Acc: 0.9807999730110168.\n","[9] Resultado: 0.9807999730110168\n","Red con d=0.3, lr=0.01, nf=64, fs=7. Loss: 0.06684824824333191. Acc: 0.9785000085830688.\n","[10] Resultado: 0.9785000085830688\n","Red con d=0.3, lr=0.01, nf=128, fs=5. Loss: 0.07882623374462128. Acc: 0.9739000201225281.\n","[11] Resultado: 0.9739000201225281\n","Red con d=0.3, lr=0.01, nf=128, fs=7. Loss: 0.06372769176959991. Acc: 0.98089998960495.\n","[12] Resultado: 0.98089998960495\n","(array([7]),)\n","Best execution: 7. Accuracy: 0.9842000007629395\n"]}],"source":["# definimos nuestra grid con mejores valores\n","dropouts = [0, 0.3]\n","learning_rates = [0.01]\n","n_filters = [32, 64, 128]\n","filter_sizes = [5, 7]\n","\n","# creamos una variable para guardar nuestras accuracies\n","log_accuracies = []\n","\n","# contador\n","i = 1\n","\n","# empezamos el grid search\n","for d in dropouts:\n","  for lr in learning_rates:\n","    for nf in n_filters:\n","      for fs in filter_sizes:\n","        result_net = net(d, lr, nf, fs)\n","        print('[{}] Resultado: {}'.format(i, result_net))\n","        log_accuracies.append(result_net)\n","        i += 1\n","        \n","# y el mejor resultado sería\n","import numpy as np\n","idx_max = np.nonzero(log_accuracies==np.max(log_accuracies))\n","print(idx_max)\n","\n","print('Best execution: {}. Accuracy: {}'.format(idx_max[0][0], log_accuracies[idx_max[0][0]]))"]},{"cell_type":"markdown","metadata":{"id":"WUZHM4_J2Zf5"},"source":["Bueno, no está mal, ¿verdad?\n","\n","Aunque estaría genial que hubiesen métodos más rápidos o usando algo de heurística, ¿no? En vez de fuerza bruta...\n","\n","Pues estáis de suerte! Existen varios métodos de este tipo:\n","\n","* Spearmint (Python)\n","* BayesOpt (C++ with Python and Matlab/Octave interfaces)\n","* hyperopt (Python)\n","* SMAC (Java)\n","* REMBO (Matlab)\n","* MOE (C++/Python)\n","\n","+INFO: http://fastml.com/optimizing-hyperparams-with-hyperopt/\n","\n","Y hoy vamos a ver **hyperopt**"]},{"cell_type":"markdown","metadata":{"id":"ywTCluaY8cLo"},"source":["## 1.2 Hyper-opt\n","\n","Otra opción es utilizar hyperopt (Hyperopt: Distributed Asynchronous Hyper-parameter Optimization, https://github.com/hyperopt/hyperopt).\n","\n","Hyperopt es una librería escrita en Python que permite optimizar funciones de una forma rápida fijándose más en los valores que más probablemente van a dar una buena solución.\n","\n","Actualmente tiene dos algoritmos implementados para hacer esto:\n","\n","* Random Search\n","* Tree of Parzen Estimators (TPE)\n","\n","Además, se pueden ejecutar en serie o en paralelo, haciendo uso de MongoDB.\n","\n","Vamos a ver un ejemplo de cómo utilizarlo.\n","\n","Vamos a encontrar el mínimo de $x^2$:\n","(\u003ca href=\"https://www.google.es/search?source=hp\u0026ei=2ds5XO_jG6y_lwTvxp2QBQ\u0026q=x**2\u0026btnK=Google+Search\u0026oq=x**2\u0026gs_l=psy-ab.3...716.1584..1916...0.0..0.301.1084.1j0j3j1......0....1..gws-wiz.....0..0i131j0.cgRgMW95cQk\"\u003eclick aqui para ver la funcion\u003c/a\u003e)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":704,"status":"ok","timestamp":1675339530494,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"yDMGyMu2_t4n","outputId":"47aea067-7820-4a15-b86c-164e1a05dce3"},"outputs":[{"name":"stdout","output_type":"stream","text":["100%|██████████| 10/10 [00:00\u003c00:00, 805.62it/s, best loss: 0.10837309557142201]\n","{'x': 0.32920069193642654}\n"]}],"source":["from hyperopt import fmin, tpe, hp, rand\n","# con 10 iteraciones\n","\n","best = fmin(fn=lambda x: x ** 2,\n","            space=hp.uniform('x', -10, 10),\n","            algo=tpe.suggest,\n","            max_evals=10)\n","\n","print(best)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":737,"status":"ok","timestamp":1675339538382,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"wlBOKvSEAyOw","outputId":"dd293054-439a-4563-d794-e0396aa59a29"},"outputs":[{"name":"stdout","output_type":"stream","text":["100%|██████████| 100/100 [00:00\u003c00:00, 342.88it/s, best loss: 0.012187942256892093]\n","{'x': 0.1103990138402155}\n"]}],"source":["# con 100 iteraciones\n","best = fmin(fn=lambda x: x ** 2,\n","            space=hp.uniform('x', -10, 10),\n","            algo=tpe.suggest,\n","            max_evals=100)\n","\n","print(best)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4881,"status":"ok","timestamp":1675339545664,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"ZLdjuCSTBNnK","outputId":"f3b82c22-adf1-431f-d14c-dc82b76a6de1"},"outputs":[{"name":"stdout","output_type":"stream","text":["100%|██████████| 1000/1000 [00:04\u003c00:00, 216.14it/s, best loss: 5.050605884296296e-06]\n","{'x': -0.0022473553088678024}\n"]}],"source":["# con 1000 iteraciones\n","best = fmin(fn=lambda x: x ** 2,\n","            space=hp.uniform('x', -10, 10),\n","            algo=tpe.suggest,\n","            max_evals=1000)\n","\n","print(best)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1096,"status":"ok","timestamp":1675339547974,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"OWC1H--a_6Cr","outputId":"3eca815c-2c83-442a-b1f6-dcc051f58e5f"},"outputs":[{"name":"stdout","output_type":"stream","text":["100%|██████████| 1000/1000 [00:01\u003c00:00, 953.81it/s, best loss: 0.00031978551452010323]\n","{'x': 0.017882547763674594}\n"]}],"source":["best = fmin(fn=lambda x: x ** 2,\n","            space=hp.uniform('x', -10, 10),\n","            algo=rand.suggest,\n","            max_evals=1000)\n","\n","print(best)"]},{"cell_type":"markdown","metadata":{"id":"XADBBMkk_-1g"},"source":["Y ahora uno más complejo con redes neuronales:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9196,"status":"ok","timestamp":1675339566159,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"BHyu3hB95H-x","outputId":"81b9dc20-73f7-49b5-bb06-8adc5ac61c02"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting networkx==1.11\n","  Downloading networkx-1.11-py2.py3-none-any.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator\u003e=3.4.0 in /usr/local/lib/python3.8/dist-packages (from networkx==1.11) (4.4.2)\n","Installing collected packages: networkx\n","  Attempting uninstall: networkx\n","    Found existing installation: networkx 3.0\n","    Uninstalling networkx-3.0:\n","      Successfully uninstalled networkx-3.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","scikit-image 0.18.3 requires networkx\u003e=2.0, but you have networkx 1.11 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed networkx-1.11\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: hyperopt in /usr/local/lib/python3.8/dist-packages (0.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from hyperopt) (4.64.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from hyperopt) (1.21.6)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from hyperopt) (1.11)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from hyperopt) (1.7.3)\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.8/dist-packages (from hyperopt) (4.3.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from hyperopt) (1.15.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from hyperopt) (0.16.0)\n","Requirement already satisfied: decorator\u003e=3.4.0 in /usr/local/lib/python3.8/dist-packages (from networkx-\u003ehyperopt) (4.4.2)\n","Requirement already satisfied: dnspython\u003c3.0.0,\u003e=1.16.0 in /usr/local/lib/python3.8/dist-packages (from pymongo-\u003ehyperopt) (2.2.1)\n"]}],"source":["# instalamos los paquetes necesarios\n","!pip install networkx==1.11 # para instala hyperopt correctamente, si no, da errores\n","!pip install hyperopt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":265422,"status":"ok","timestamp":1675339841078,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"A-19aAqN713Q","outputId":"423b88e4-8db8-47fd-b462-6496ee8ed3f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 6s 0us/step\n","Parameters: \n","{'dropout': 0.010610649468516031, 'n_filters_conv': 128, 'neurons_dense': 512}\n","  0%|          | 0/10 [00:00\u003c?, ?it/s, best loss: ?]"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n","\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 - val acc: 0.5468000173568726 - val loss: 1.2620946168899536\n","Parameters: \n","{'dropout': 0.29046378866084166, 'n_filters_conv': 64, 'neurons_dense': 512}\n","Epoch 4 - val acc: 0.4611999988555908 - val loss: 1.5046957731246948\n","Parameters: \n","{'dropout': 0.3660237507048865, 'n_filters_conv': 128, 'neurons_dense': 1024}\n","Epoch 4 - val acc: 0.49900001287460327 - val loss: 1.394073486328125\n","Parameters: \n","{'dropout': 0.02452211198368659, 'n_filters_conv': 128, 'neurons_dense': 256}\n","Epoch 4 - val acc: 0.5393999814987183 - val loss: 1.2991169691085815\n","Parameters: \n","{'dropout': 0.43214942829953845, 'n_filters_conv': 64, 'neurons_dense': 1024}\n","Epoch 4 - val acc: 0.4052000045776367 - val loss: 1.6386640071868896\n","Parameters: \n","{'dropout': 0.05195220110445009, 'n_filters_conv': 64, 'neurons_dense': 512}\n","Epoch 4 - val acc: 0.5009999871253967 - val loss: 1.3934370279312134\n","Parameters: \n","{'dropout': 0.05704612661381975, 'n_filters_conv': 32, 'neurons_dense': 1024}\n","Epoch 4 - val acc: 0.45840001106262207 - val loss: 1.491466760635376\n","Parameters: \n","{'dropout': 0.12580440341938648, 'n_filters_conv': 128, 'neurons_dense': 1024}\n","Epoch 4 - val acc: 0.5479999780654907 - val loss: 1.2655431032180786\n","Parameters: \n","{'dropout': 0.119384622586652, 'n_filters_conv': 128, 'neurons_dense': 256}\n","Epoch 4 - val acc: 0.5353999733924866 - val loss: 1.3094160556793213\n","Parameters: \n","{'dropout': 0.38853696215309785, 'n_filters_conv': 32, 'neurons_dense': 256}\n","Epoch 4 - val acc: 0.3124000132083893 - val loss: 1.8625402450561523\n","100%|██████████| 10/10 [04:15\u003c00:00, 25.51s/it, best loss: 1.2620946168899536]\n","{'dropout': 0.010610649468516031, 'n_filters_conv': 2, 'neurons_dense': 1}\n"]}],"source":["# imports necesarios\n","import sys\n","import time\n","import numpy as np\n","from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.constraints import max_norm\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.datasets import cifar10\n","\n","SEED = 42\n","\n","(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n","validation_split = 0.1\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_split, random_state=SEED)\n","\n","# como os dije, en la práctica no se normaliza con media y std, simplemente se\n","# divide entre 255. Esto se debe a las características de una imagen, que sabemos\n","# que solo puede tener valores entre 0 y 255\n","# Primero convertimos a float y luego dividimos (si no convirtiesemos a float\n","# perderiamos toda la info de decimales!!! )\n","X_train = X_train.astype('float32') / 255.\n","X_val = X_val.astype('float32') / 255.\n","X_test = X_test.astype('float32') / 255.\n","\n","# convertimos las etiquetas a one-hot encoding\n","n_classes = 10\n","y_train = to_categorical(y_train, n_classes)\n","y_val = to_categorical(y_val, n_classes)\n","y_test = to_categorical(y_test, n_classes)\n","\n","# definimos nuestro espacio de búsqueda\n","# vamos a variar:\n","# - el número de filtros en nuestras capas conv\n","# - el porcentaje de dropout\n","# - el número de neuronas en la capa dense\n","space = {\n","    'n_filters_conv': hp.choice('n_filters_conv', [32, 64, 128]),\n","    'dropout': hp.uniform('dropout', 0.0, 0.5),\n","    'neurons_dense': hp.choice('neurons_dense', [256, 512, 1024]), \n","}\n","\n","def\tget_callbacks(pars):\n","  callbacks\t= [EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, verbose=0, mode='auto')]\n","  return callbacks\n","\n","def mi_cnn(pars):\n","  print ('Parameters: ', pars)\n","  model = Sequential()\n","  # ¡¡¡ Dibujar arquitectura y que ellos me digan cómo se implementa!!!\n","\n","  # Primer bloque convolucional\n","  model.add(Conv2D(pars['n_filters_conv'], kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","  model.add(Dropout(pars['dropout']))\n","\n","  # Segundo bloque convolucional\n","  model.add(Conv2D(pars['n_filters_conv'], kernel_size=(3, 3), activation='relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","  model.add(Dropout(pars['dropout']))\n","\n","  # Tercer bloque convolucional\n","  model.add(Conv2D(pars['n_filters_conv'], kernel_size=(3, 3), activation='relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","  model.add(Dropout(pars['dropout']))\n","\n","  # Bloque clasificador\n","  model.add(Flatten())\n","  model.add(Dense(pars['neurons_dense'], activation='relu', kernel_constraint=max_norm(3.)))\n","  model.add(Dropout(pars['dropout']))\n","  model.add(Dense(10, activation='softmax'))\n","\n","  # Compilamos el modelo\n","  model.compile(loss='categorical_crossentropy',\n","                optimizer=Adam(lr=0.0001, decay=1e-6),\n","                metrics=['accuracy'])\n","\n","  # Entrenamos el modelo\n","  history = model.fit(X_train, \n","                      y_train,\n","                      batch_size=128,\n","                      shuffle=True,\n","                      epochs=5,\n","                      validation_data=(X_val, y_val),\n","                      verbose = 0,\n","                      callbacks = get_callbacks(pars))\n","\n","  best_epoch_loss = np.argmin(history.history['val_loss'])\n","  best_val_loss = np.min(history.history['val_loss'])\n","  best_val_acc = np.max(history.history['val_accuracy'])\n","  \n","  print('Epoch {} - val acc: {} - val loss: {}'.format(best_epoch_loss, best_val_acc, best_val_loss))\n","  sys.stdout.flush()\n","  \n","  return {'loss': best_val_loss, 'best_epoch': best_epoch_loss, 'eval_time': time.time(), 'status': STATUS_OK, 'model': model, 'history': history}\n","\n","\n","trials = Trials()\n","best = fmin(mi_cnn, space, algo=tpe.suggest, max_evals=10, trials=trials)\n","print(best)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":313,"status":"ok","timestamp":1675339883937,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"HnWTApwx8tP0","outputId":"b3d3351d-6366-438a-f22b-cb24328cefd7"},"outputs":[{"data":{"text/plain":["[{'state': 2,\n","  'tid': 0,\n","  'spec': None,\n","  'result': {'loss': 1.2620946168899536,\n","   'best_epoch': 4,\n","   'eval_time': 1675339611.59243,\n","   'status': 'ok',\n","   'model': \u003ckeras.engine.sequential.Sequential at 0x7f47c8645eb0\u003e,\n","   'history': \u003ckeras.callbacks.History at 0x7f47f4248f70\u003e},\n","  'misc': {'tid': 0,\n","   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n","   'workdir': None,\n","   'idxs': {'dropout': [0], 'n_filters_conv': [0], 'neurons_dense': [0]},\n","   'vals': {'dropout': [0.010610649468516031],\n","    'n_filters_conv': [2],\n","    'neurons_dense': [1]}},\n","  'exp_key': None,\n","  'owner': None,\n","  'version': 0,\n","  'book_time': datetime.datetime(2023, 2, 2, 12, 6, 26, 165000),\n","  'refresh_time': datetime.datetime(2023, 2, 2, 12, 6, 51, 592000)},\n"," {'state': 2,\n","  'tid': 1,\n","  'spec': None,\n","  'result': {'loss': 1.5046957731246948,\n","   'best_epoch': 4,\n","   'eval_time': 1675339627.9056296,\n","   'status': 'ok',\n","   'model': \u003ckeras.engine.sequential.Sequential at 0x7f47de5d6c70\u003e,\n","   'history': \u003ckeras.callbacks.History at 0x7f47f40e8a90\u003e},\n","  'misc': {'tid': 1,\n","   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n","   'workdir': None,\n","   'idxs': {'dropout': [1], 'n_filters_conv': [1], 'neurons_dense': [1]},\n","   'vals': {'dropout': [0.29046378866084166],\n","    'n_filters_conv': [1],\n","    'neurons_dense': [1]}},\n","  'exp_key': None,\n","  'owner': None,\n","  'version': 0,\n","  'book_time': datetime.datetime(2023, 2, 2, 12, 6, 51, 597000),\n","  'refresh_time': datetime.datetime(2023, 2, 2, 12, 7, 7, 905000)},\n"," {'state': 2,\n","  'tid': 2,\n","  'spec': None,\n","  'result': {'loss': 1.394073486328125,\n","   'best_epoch': 4,\n","   'eval_time': 1675339670.0892994,\n","   'status': 'ok',\n","   'model': \u003ckeras.engine.sequential.Sequential at 0x7f47de59c760\u003e,\n","   'history': \u003ckeras.callbacks.History at 0x7f47f4092670\u003e},\n","  'misc': {'tid': 2,\n","   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n","   'workdir': None,\n","   'idxs': {'dropout': [2], 'n_filters_conv': [2], 'neurons_dense': [2]},\n","   'vals': {'dropout': [0.3660237507048865],\n","    'n_filters_conv': [2],\n","    'neurons_dense': [2]}},\n","  'exp_key': None,\n","  'owner': None,\n","  'version': 0,\n","  'book_time': datetime.datetime(2023, 2, 2, 12, 7, 7, 910000),\n","  'refresh_time': datetime.datetime(2023, 2, 2, 12, 7, 50, 89000)},\n"," {'state': 2,\n","  'tid': 3,\n","  'spec': None,\n","  'result': {'loss': 1.2991169691085815,\n","   'best_epoch': 4,\n","   'eval_time': 1675339712.5605116,\n","   'status': 'ok',\n","   'model': \u003ckeras.engine.sequential.Sequential at 0x7f47c863ff10\u003e,\n","   'history': \u003ckeras.callbacks.History at 0x7f47c83b84c0\u003e},\n","  'misc': {'tid': 3,\n","   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n","   'workdir': None,\n","   'idxs': {'dropout': [3], 'n_filters_conv': [3], 'neurons_dense': [3]},\n","   'vals': {'dropout': [0.02452211198368659],\n","    'n_filters_conv': [2],\n","    'neurons_dense': [0]}},\n","  'exp_key': None,\n","  'owner': None,\n","  'version': 0,\n","  'book_time': datetime.datetime(2023, 2, 2, 12, 7, 50, 95000),\n","  'refresh_time': datetime.datetime(2023, 2, 2, 12, 8, 32, 560000)},\n"," {'state': 2,\n","  'tid': 4,\n","  'spec': None,\n","  'result': {'loss': 1.6386640071868896,\n","   'best_epoch': 4,\n","   'eval_time': 1675339728.8467891,\n","   'status': 'ok',\n","   'model': \u003ckeras.engine.sequential.Sequential at 0x7f47c8413dc0\u003e,\n","   'history': \u003ckeras.callbacks.History at 0x7f485beb92e0\u003e},\n","  'misc': {'tid': 4,\n","   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n","   'workdir': None,\n","   'idxs': {'dropout': [4], 'n_filters_conv': [4], 'neurons_dense': [4]},\n","   'vals': {'dropout': [0.43214942829953845],\n","    'n_filters_conv': [1],\n","    'neurons_dense': [2]}},\n","  'exp_key': None,\n","  'owner': None,\n","  'version': 0,\n","  'book_time': datetime.datetime(2023, 2, 2, 12, 8, 32, 565000),\n","  'refresh_time': datetime.datetime(2023, 2, 2, 12, 8, 48, 846000)},\n"," {'state': 2,\n","  'tid': 5,\n","  'spec': None,\n","  'result': {'loss': 1.3934370279312134,\n","   'best_epoch': 4,\n","   'eval_time': 1675339750.8071938,\n","   'status': 'ok',\n","   'model': \u003ckeras.engine.sequential.Sequential at 0x7f485beb2160\u003e,\n","   'history': \u003ckeras.callbacks.History at 0x7f485bd0baf0\u003e},\n","  'misc': {'tid': 5,\n","   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n","   'workdir': None,\n","   'idxs': {'dropout': [5], 'n_filters_conv': [5], 'neurons_dense': [5]},\n","   'vals': {'dropout': [0.05195220110445009],\n","    'n_filters_conv': [1],\n","    'neurons_dense': [1]}},\n","  'exp_key': None,\n","  'owner': None,\n","  'version': 0,\n","  'book_time': datetime.datetime(2023, 2, 2, 12, 8, 48, 850000),\n","  'refresh_time': datetime.datetime(2023, 2, 2, 12, 9, 10, 807000)},\n"," {'state': 2,\n","  'tid': 6,\n","  'spec': None,\n","  'result': {'loss': 1.491466760635376,\n","   'best_epoch': 4,\n","   'eval_time': 1675339762.5241468,\n","   'status': 'ok',\n","   'model': \u003ckeras.engine.sequential.Sequential at 0x7f47c84337f0\u003e,\n","   'history': \u003ckeras.callbacks.History at 0x7f46f885d0a0\u003e},\n","  'misc': {'tid': 6,\n","   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n","   'workdir': None,\n","   'idxs': {'dropout': [6], 'n_filters_conv': [6], 'neurons_dense': [6]},\n","   'vals': {'dropout': [0.05704612661381975],\n","    'n_filters_conv': [0],\n","    'neurons_dense': [2]}},\n","  'exp_key': None,\n","  'owner': None,\n","  'version': 0,\n","  'book_time': datetime.datetime(2023, 2, 2, 12, 9, 10, 812000),\n","  'refresh_time': datetime.datetime(2023, 2, 2, 12, 9, 22, 524000)},\n"," {'state': 2,\n","  'tid': 7,\n","  'spec': None,\n","  'result': {'loss': 1.2655431032180786,\n","   'best_epoch': 4,\n","   'eval_time': 1675339787.7511113,\n","   'status': 'ok',\n","   'model': \u003ckeras.engine.sequential.Sequential at 0x7f46f8695fd0\u003e,\n","   'history': \u003ckeras.callbacks.History at 0x7f46f862a4c0\u003e},\n","  'misc': {'tid': 7,\n","   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n","   'workdir': None,\n","   'idxs': {'dropout': [7], 'n_filters_conv': [7], 'neurons_dense': [7]},\n","   'vals': {'dropout': [0.12580440341938648],\n","    'n_filters_conv': [2],\n","    'neurons_dense': [2]}},\n","  'exp_key': None,\n","  'owner': None,\n","  'version': 0,\n","  'book_time': datetime.datetime(2023, 2, 2, 12, 9, 22, 528000),\n","  'refresh_time': datetime.datetime(2023, 2, 2, 12, 9, 47, 751000)},\n"," {'state': 2,\n","  'tid': 8,\n","  'spec': None,\n","  'result': {'loss': 1.3094160556793213,\n","   'best_epoch': 4,\n","   'eval_time': 1675339830.3590438,\n","   'status': 'ok',\n","   'model': \u003ckeras.engine.sequential.Sequential at 0x7f46f89a8f40\u003e,\n","   'history': \u003ckeras.callbacks.History at 0x7f46f84b9250\u003e},\n","  'misc': {'tid': 8,\n","   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n","   'workdir': None,\n","   'idxs': {'dropout': [8], 'n_filters_conv': [8], 'neurons_dense': [8]},\n","   'vals': {'dropout': [0.119384622586652],\n","    'n_filters_conv': [2],\n","    'neurons_dense': [0]}},\n","  'exp_key': None,\n","  'owner': None,\n","  'version': 0,\n","  'book_time': datetime.datetime(2023, 2, 2, 12, 9, 47, 755000),\n","  'refresh_time': datetime.datetime(2023, 2, 2, 12, 10, 30, 359000)},\n"," {'state': 2,\n","  'tid': 9,\n","  'spec': None,\n","  'result': {'loss': 1.8625402450561523,\n","   'best_epoch': 4,\n","   'eval_time': 1675339841.258986,\n","   'status': 'ok',\n","   'model': \u003ckeras.engine.sequential.Sequential at 0x7f47c8382580\u003e,\n","   'history': \u003ckeras.callbacks.History at 0x7f47de17f2e0\u003e},\n","  'misc': {'tid': 9,\n","   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n","   'workdir': None,\n","   'idxs': {'dropout': [9], 'n_filters_conv': [9], 'neurons_dense': [9]},\n","   'vals': {'dropout': [0.38853696215309785],\n","    'n_filters_conv': [0],\n","    'neurons_dense': [0]}},\n","  'exp_key': None,\n","  'owner': None,\n","  'version': 0,\n","  'book_time': datetime.datetime(2023, 2, 2, 12, 10, 30, 362000),\n","  'refresh_time': datetime.datetime(2023, 2, 2, 12, 10, 41, 259000)}]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["trials.trials"]},{"cell_type":"markdown","metadata":{"id":"_Vi6qOtcBYqs"},"source":["¿Por qué dice que best_epoch=4? Porque history está indexado en 0."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":289,"status":"ok","timestamp":1675339891996,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"e_omggaGAqx6","outputId":"d2773b45-c03e-4dc3-99fe-aaaa9816272f"},"outputs":[{"data":{"text/plain":["{'state': 2,\n"," 'tid': 6,\n"," 'spec': None,\n"," 'result': {'loss': 1.491466760635376,\n","  'best_epoch': 4,\n","  'eval_time': 1675339762.5241468,\n","  'status': 'ok',\n","  'model': \u003ckeras.engine.sequential.Sequential at 0x7f47c84337f0\u003e,\n","  'history': \u003ckeras.callbacks.History at 0x7f46f885d0a0\u003e},\n"," 'misc': {'tid': 6,\n","  'cmd': ('domain_attachment', 'FMinIter_Domain'),\n","  'workdir': None,\n","  'idxs': {'dropout': [6], 'n_filters_conv': [6], 'neurons_dense': [6]},\n","  'vals': {'dropout': [0.05704612661381975],\n","   'n_filters_conv': [0],\n","   'neurons_dense': [2]}},\n"," 'exp_key': None,\n"," 'owner': None,\n"," 'version': 0,\n"," 'book_time': datetime.datetime(2023, 2, 2, 12, 9, 10, 812000),\n"," 'refresh_time': datetime.datetime(2023, 2, 2, 12, 9, 22, 524000)}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["trials.trials[6]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":298,"status":"ok","timestamp":1675339894752,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"GKUsa3IJ9O8j","outputId":"6481b173-5ffe-45f7-c85c-9b08a383abc8"},"outputs":[{"data":{"text/plain":["[{'loss': 1.2620946168899536,\n","  'best_epoch': 4,\n","  'eval_time': 1675339611.59243,\n","  'status': 'ok',\n","  'model': \u003ckeras.engine.sequential.Sequential at 0x7f47c8645eb0\u003e,\n","  'history': \u003ckeras.callbacks.History at 0x7f47f4248f70\u003e},\n"," {'loss': 1.5046957731246948,\n","  'best_epoch': 4,\n","  'eval_time': 1675339627.9056296,\n","  'status': 'ok',\n","  'model': \u003ckeras.engine.sequential.Sequential at 0x7f47de5d6c70\u003e,\n","  'history': \u003ckeras.callbacks.History at 0x7f47f40e8a90\u003e},\n"," {'loss': 1.394073486328125,\n","  'best_epoch': 4,\n","  'eval_time': 1675339670.0892994,\n","  'status': 'ok',\n","  'model': \u003ckeras.engine.sequential.Sequential at 0x7f47de59c760\u003e,\n","  'history': \u003ckeras.callbacks.History at 0x7f47f4092670\u003e},\n"," {'loss': 1.2991169691085815,\n","  'best_epoch': 4,\n","  'eval_time': 1675339712.5605116,\n","  'status': 'ok',\n","  'model': \u003ckeras.engine.sequential.Sequential at 0x7f47c863ff10\u003e,\n","  'history': \u003ckeras.callbacks.History at 0x7f47c83b84c0\u003e},\n"," {'loss': 1.6386640071868896,\n","  'best_epoch': 4,\n","  'eval_time': 1675339728.8467891,\n","  'status': 'ok',\n","  'model': \u003ckeras.engine.sequential.Sequential at 0x7f47c8413dc0\u003e,\n","  'history': \u003ckeras.callbacks.History at 0x7f485beb92e0\u003e},\n"," {'loss': 1.3934370279312134,\n","  'best_epoch': 4,\n","  'eval_time': 1675339750.8071938,\n","  'status': 'ok',\n","  'model': \u003ckeras.engine.sequential.Sequential at 0x7f485beb2160\u003e,\n","  'history': \u003ckeras.callbacks.History at 0x7f485bd0baf0\u003e},\n"," {'loss': 1.491466760635376,\n","  'best_epoch': 4,\n","  'eval_time': 1675339762.5241468,\n","  'status': 'ok',\n","  'model': \u003ckeras.engine.sequential.Sequential at 0x7f47c84337f0\u003e,\n","  'history': \u003ckeras.callbacks.History at 0x7f46f885d0a0\u003e},\n"," {'loss': 1.2655431032180786,\n","  'best_epoch': 4,\n","  'eval_time': 1675339787.7511113,\n","  'status': 'ok',\n","  'model': \u003ckeras.engine.sequential.Sequential at 0x7f46f8695fd0\u003e,\n","  'history': \u003ckeras.callbacks.History at 0x7f46f862a4c0\u003e},\n"," {'loss': 1.3094160556793213,\n","  'best_epoch': 4,\n","  'eval_time': 1675339830.3590438,\n","  'status': 'ok',\n","  'model': \u003ckeras.engine.sequential.Sequential at 0x7f46f89a8f40\u003e,\n","  'history': \u003ckeras.callbacks.History at 0x7f46f84b9250\u003e},\n"," {'loss': 1.8625402450561523,\n","  'best_epoch': 4,\n","  'eval_time': 1675339841.258986,\n","  'status': 'ok',\n","  'model': \u003ckeras.engine.sequential.Sequential at 0x7f47c8382580\u003e,\n","  'history': \u003ckeras.callbacks.History at 0x7f47de17f2e0\u003e}]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["trials.results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":456,"status":"ok","timestamp":1653551065911,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-120},"id":"edAvMjPX9Qxi","outputId":"e0581e7f-791e-4129-a7de-2747a0774dc1"},"outputs":[{"data":{"text/plain":["[1.5051878690719604,\n"," 1.5432941913604736,\n"," 1.4264308214187622,\n"," 1.7604674100875854,\n"," 1.374725580215454,\n"," 1.6723560094833374,\n"," 1.2444250583648682,\n"," 1.5358803272247314,\n"," 1.5488694906234741,\n"," 1.2682890892028809]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["trials.losses()"]},{"cell_type":"markdown","metadata":{"id":"JpK451ZLCF18"},"source":["¿Qué os parece?  Así, podéis dejar vuestra configuración e iros a hacer algo más útil que andar variando parámetros hasta que encontréis la configuración adecuada.\n","\n","**¡Mejor que lo hagan por nosotros y que nos la encontremos automáticamente seleccionada!**\n","\n","Pero no tenemos por qué quedarnos aquí, podemos también variar el número de capas o si queremos conexiones residuales, por ejemplo! Sí, esto significa que podemos variar la **arquitectura** también.\n","\n","Aquí tenéis un ejemplo muy completo: https://github.com/Vooban/Hyperopt-Keras-CNN-CIFAR-100\n","\n","Y aquí otro que quizá os parezca interesante: \n","\n","\u003cimg src=\"http://cdn.lizamayliza.com/storage/cache/images/003/636/Daffy-Duck-Money-eyes-feature,xlarge.1480369578.jpg\" border=\"0\" height=\"200\"\u003e\n","\n","https://medium.com/machine-learning-world/neural-networks-for-algorithmic-trading-hyperparameters-optimization-cb2b4a29b8ee"]},{"cell_type":"markdown","metadata":{"id":"XJBIyfkE8cl0"},"source":["## 1.3 Algoritmos genéticos\n","\n","Quizás estéis pensando en que tras haber visto esto no necesitáis saber nada más, ¡ya habéis encontrado algo que es la repera! Pues atentos porque lo que viene, pese a ser algo muy sencillo, es potentísimo, y os va encantar. Sí, estoy hablando de **los algoritmos genéticos**.\n","\n","En esencia, los algoritmos genéticos son un método de búsqueda meta-heurística inspirados en la evolución natural. Pertenecen a los algoritmos evolutivos, concretamente a los Algoritmos de búsqueda aleatoria guiada (Guided Random Search algorithms (Evolutionary Alg.)).\n","\n","Esto que os puede parecer chino, es muy sencillo. Vamos a entenderlos con un ejemplo:\n","\n","\u003cimg src=\"https://image.ibb.co/cJcQYJ/ga_problem.png\" alt=\"ga_problem\" border=\"0\"\u003e\n","\n","Imaginad que tenemos un puzzle, y nos queda solo una pieza por encajar. Lo que pasa es que este puzzle es muy especial, porque nos permite fabricarnos nuestras propias piezas. Para ello, disponemos de varios mecanismos:\n","\n","* **Combinar** partes de piezas (**crossover** o recombinación).\n","* **Modificar** determinadas partes de esas piezas (**mutación**).\n","* **Escoger** las mejores piezas de todas las que hemos hecho, para a partir de ellas, construir nuevas que sean mejores (**selección**).\n","\n","Entonces imaginaos que decidimos cortar 10 trozos de carton, que son nuestras 10 piezas iniciales con las que vamos a probar a ver si alguna encaja perfectamnte. Las probamos todas, y de esas 10, 5 encajan más o menos. Así que seleccionamos esas 5 y fabricamos nuevas a partir de ellas mediante los mecanismos explicados arriba:\n","\n","* De las 5 seleccionadas, sacamos 5 más combinando partes de dos de esas 5 originales escogiéndolas aleatoriamente\n","* De las 5 originales, y las nuevas 5 que nos hemos creado, sacamos 5 más modificando ligeramente una de las puntas de la pieza\n","\n","Ahora resulta que tenemos 15 piezas, y nosotros queremos tener siempre 10, porque si no a la 5 vez que hiciéramos esto tendríamos una barbaridad de piezas!! Así que:\n","\n","* Probamos nuestras 15 piezas y nos quedamos con la que mejor encaja, y luego 9 escogidas al azar\n","\n","Pues ya está, ¡eso es lo que hace un algoritmo genético! ¡Ya sabéis cómo funcionan! Sencillo, ¿verdad? Pues no os hacéis una idea de lo potentes que son :-)\n","\n","Vamos a verlo un poco más concreto siguiendo con nuestro ejemplo:\n","\n","\u003cimg src=\"https://image.ibb.co/b7ySfy/geneticos_puzzle.png\" alt=\"geneticos_puzzle\" border=\"0\"\u003e\n","\n","Como podéis ver:\n","\n","* Cada pieza de nuestro conjunto de piezas (población) es un **cromosoma**\n","* Cada parte de nuestra pieza es un **gen**, por tanto, nuestro cromosoma tiene 4 genes\n","* Los posibles valores o configuraciones que puede tener cada gen se llama **alelo**\n","\n","Esto es exactamente igual que en biología! No os dije que estaban inspirados en la evolución natural? :-)\n","\n","Vale, pues vamos a ir relacionando estas palabrejas con nuestro ejemplo:\n","\n","* Necesitamos encontrar la pieza correcta para nuestro hueco del puzzle\n","* Tenemos un conjunto inicial de piezas (**población**) que pueden encajar bien o no, no lo sabemos\n","* Comprobamos cómo de bien encajan estas piezas (usando la **función de fitness**)\n","* Si ninguna de las piezas encaja como nos gustaría, modificamos las piezas (con los operadores: **crossover** y **mutación**)\n","* Comprobamos como de bien encajan las piezas recien creadas (**función de fitness**)\n","* Seleccionamos las piezas que queremos aguantar para la próxima iteración (**selección**)\n","\n","* Y volvemos a empezar! así, hasta que enocntremos una pieza que encaje con la precisión que nosotros queremos\n","\n","Venga, vamos a ponernos un poco más serios. Veamos el pseudo-algoritmo:\n","\n","**START**\n","\n","Generate the initial population\n","\n","Compute fitness\n","\n","**REPEAT**\n","    \n","    Selection\n","    \n","    Crossover\n","    \n","    Mutation\n","\n","    Compute fitness\n","\n","**UNTIL** population has converged\n","\n","**STOP**\n","\n","¿Se entiende, no? ¡Es exactamente lo mismo que los pasos que acabamos de hablar con el puzzle!\n","\n","\u003cimg src=\"https://image.ibb.co/kQu7Ed/ga_workflow.png\" alt=\"ga_workflow\" border=\"0\" width=\"600\"\u003e\n","\n","Vale, y ahora llega lo interesante, ¿cómo funcionan realmente?\n","\n","Tenemos que entender varios conceptos:\n","\n","* Cómo se inicializa nuestra población\n","* Cómo funciona el crossover\n","* Cómo funciona la mutación\n","* Cómo funciona la seleccion\n","* Cómo podemos definir nuestra función de fitness\n","\n","¿Preparados? ¡Vamos allá!"]},{"cell_type":"markdown","metadata":{"id":"TbgSCrpOcbqt"},"source":["Lo primero es entender que cuando tenemos un problema en el mundo real y queremos solucionarlo en un ordenador, necesitamos **codificarlo** para que el ordenador lo entienda.\n","\n","Así, por ejemplo:\n","\n","* En el mundo real, el cromosoma es la pieza del puzzle. En el ordenador, el cromosoma es un vector con 4 valores (uno para indicar el tamaño de cada punta, donde positivo significa punta, negativo significa hueco hacia dentro de la pieza)\n","\n","Esto es a lo que se llama la codificación.\n","\n","Una vez sabido esto, vamos a ver cómo funcionan los operadores. Antes de nada, debéis saber que xisten muchos tipos de crossover, mutación y selección, pero aquí vamos a ver solo los más sencillos por temas de tiempo. \n","\n","Si estáis interesados en conocerlos más profundamente, en internet hay muchísimo material disponible. Podéis empezar aquí: https://www.tutorialspoint.com/genetic_algorithms/index.htm\n","\n","\n","\u003cimg src=\"https://image.ibb.co/hEwVHd/ga_operators.png\" alt=\"ga_operators\" border=\"0\"\u003e\n","\n","**El crossover de un único punto (single-point crossover)**\n","\n","Nuestro cromosoma es la pieza de puzzle, que tiene los 4 genes que veis en la imagen. Pues el crossover simple sencillamente escoge un punto aleatoriamente de los 4 genes, y combina las partes en nuevos cromosomas, como veis en la imagen.\n","\n","Es importante que entendáis que el crossover **produce nuevos cromosomas**, puesto que tenemos los originales y los **recombinados**.\n","\n","**La mutación uniforme**\n","\n","La mutación uniforme consiste en que para cada cromosoma, lanzamos una moneda al aire. Si sale cara, modificamos un gen escogido aleatoriamente. ¿Qué valor le asignamos? Uno aleatorio dentro del rango que permite dicho gen.\n","\n","**La selección**\n","\n","Para la selección lo que se suele hacer es usar las fitness de los cromosomas (también llamados posibles **soluciones**). En este caso, vamos a ver la Stochastic Universal Sampling, que consiste en que construímos una gráfica de tipo tarta donde cada cromosoma ocupa un espacio que corresponde con su fitness. Después, establecemos N puntos fijos alrededor de la \"tarta\", donde N son el número de cromomsomas que queremos **seleccionar**. Después, se \"gira la tarta\", como si fuese la ruleta de la suerte, y los cromosomas a los que apuntan los puntos fijos son los seleccionados y pasan a la siguiente iteración.\n","\n","Si os fijáis, **los cromosomas no están ordenados de mayor a menor fitness**!! \n","\n","Esto es importante, puesto que si no, las probabilidades de seleccionar un cromosoma con una fitness alta y otro con una fitness baja serían más altas que de seleccionar dos con la fitness alta, ya que al estar los puntos de selección uno enfrente del otro, sería muy complicado seleccionar dos cromosomas con fitness parecidas.\n","\n","Este operador tiene varias formas de funcionar. Siguiendo con nuestro ejemplo de población de 10 cromosomas, las formas son:\n","\n","* Seleccionamos $N=10$ cromosomas, es decir, sustituimos la anterior población por una completamente nueva\n","* Seleccionamos $N=n$ cromosomas, donde n\u003c10. Es decir, sustituímos solo una parte de los crosomomas antiguos. El resto siguen jugando ;-D\n","\n","Vale, pues si seleccionamos los 10 está claro, pero si seleccionamos $n$, cómo elegimos cuales quitamos?\n","\n","Pues las dos formas más comunes son:\n","\n","* Quitamos los cromosomas más antiguos\n","* Quitamos los cromosomas con peor fitness\n","\n","Ya por último, hay veces que seleccionamos al mejor cromosoma (o a los $k$ mejors) para que pase si o si a la siguiente iteración, es decir, hay *elitismo*. Hay que ir con cuidado con esto, puesto que aunque a priori parezca que el elitismo es lo mejor y que solo deberíamos quedarnos con los mejores, si lo hiciésemos nos estaríamos cargando una de las mayores virtudes de los genéticos: **que son capaces de escapar a mínimos locales!!!**\n","\n","Fijaos, aquí podéis ver en plena acción a un genético intentando decidir cual es la mejor configuración para un vehículo de 2 ruedas: http://rednuht.org/genetic_cars_2/\n","\n","\n","\n","Vale, ¿pues ahora qué tal si implementamos un par de ejemplos nosotros?\n","\n","\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":315,"status":"ok","timestamp":1675340291368,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"Nqbm0WeXHw-N","outputId":"a3b350f9-8c82-4157-81bc-f40f2858cfee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Inicializamos la población con 20 individuos.\n","Calculamos el fitness de esos 20 individuos.\n","El mejor individuo de la población inicial es:\n","Individual:  17 Valores:  6 41 8 35 29  Result:  119 Target;  108\n","Comienza la búsqueda:\n","Individual:  0 Valores:  6 41 8 35 29  Result:  119 Target;  108\n","Generación:  0  Fitness medio de todos los individuos de la población: 100.45\n","Individual:  9 Valores:  6 41 34 8 22  Result:  111 Target;  108\n","Generación:  1  Fitness medio de todos los individuos de la población: 71.4\n","Individual:  0 Valores:  6 41 34 8 22  Result:  111 Target;  108\n","Individual:  18 Valores:  6 41 34 8 22  Result:  111 Target;  108\n","Generación:  2  Fitness medio de todos los individuos de la población: 73.9\n","Individual:  11 Valores:  6 16 56 8 22  Result:  108 Target;  108\n","Generación:  3  Fitness medio de todos los individuos de la población: 52.0\n"]}],"source":["# Ejemplo simple de un GA donde tenemos que encontrar N números que sumen X\n","# https://lethain.com/genetic-algorithms-cool-name-damn-simple\n","\n","from random import randint, random\n","from operator import add\n","from functools import reduce\n","import numpy as np\n","\n","def individual(length, min, max):\n","    # creamos un individuo\n","    return [ randint(min,max) for x in range(length) ]\n","\n","def population(count, length, min, max):   \n","    # creamos nuestra población\n","    # count: numero de invidiuos en la población\n","    # length: número de valores por individuo\n","    # min: minimo permitido para cada valor del individuo\n","    # max: maximo permitido para cada valor del individuo\n","\n","    return [ individual(length, min, max) for x in range(count) ]\n","\n","def fitness(individual, target):\n","    # calculamos la fitness de un individuo: más bajo es mejor\n","    \n","    sum = reduce(add, individual, 0)\n","    return abs(target-sum)\n","\n","def grade(pop, target):\n","    # calculamos la media de la población entera\n","    summed = reduce(add, (fitness(x, target) for x in pop))\n","    return summed / (len(pop) * 1.0)\n","  \n","def find_best_solution(pop, target):\n","    # encuentra la mejor solución en la población actual y la imprime\n","    res = [fitness(x, target) for x in pop]\n","    res_min = np.min(res)\n","    res_min_idx = np.where(res == res_min)[0]\n","    for n in res_min_idx:\n","        print('Individual: ', n, 'Valores: ', *pop[n], ' Result: ', np.sum(pop[n]), 'Target; ', target)\n","    return res_min    \n","\n","def evolve(pop, target, retain=0.2, random_select=0.05, mutate=0.01):\n","    graded = [ (fitness(x, target), x) for x in pop]\n","    graded = [ x[1] for x in sorted(graded)]\n","    retain_length = int(len(graded)*retain)\n","    parents = graded[:retain_length]\n","    \n","    # añadimos individuos aleatoriamente para promover la diversidad genética\n","    for individual in graded[retain_length:]:\n","        if random_select \u003e random():\n","            parents.append(individual)\n","    \n","    # mutamos algunos\n","    for individual in parents:\n","        if mutate \u003e random():\n","            pos_to_mutate = randint(0, len(individual)-1)\n","            individual[pos_to_mutate] = randint(i_min, i_max)\n","    \n","    # reproducimos (crossover) nuestros cromosomas (individuals, soluciones)\n","    parents_length = len(parents)\n","    desired_length = len(pop) - parents_length\n","    children = []\n","    while len(children) \u003c desired_length:\n","        male = randint(0, parents_length-1)\n","        female = randint(0, parents_length-1)\n","        if male != female:\n","            male = parents[male]\n","            female = parents[female]\n","            half = round(len(male) / 2)\n","            child = male[:half] + female[half:]\n","            children.append(child)        \n","    parents.extend(children)\n","    return parents\n","\n","# ejecutamos el GA\n","generations = 20\n","target = 108\n","p_count = 20\n","i_length = 5\n","i_min = 0\n","i_max = 100\n","error_accepted = 1\n","print('Inicializamos la población con 20 individuos.')\n","p = population(p_count, i_length, i_min, i_max)\n","print('Calculamos el fitness de esos 20 individuos.')\n","fitness_history = [grade(p, target),]\n","print('El mejor individuo de la población inicial es:')\n","find_best_solution(p, target)\n","\n","print('Comienza la búsqueda:')\n","for i in range(generations):\n","    p = evolve(p, target, retain=0.2, random_select=0.2, mutate=0.4)\n","    res = grade(p, target)\n","    fitness_history.append(res)\n","    \n","    res_min = find_best_solution(p, target)\n","    print('Generación: ', i, ' Fitness medio de todos los individuos de la población:', res)\n","    \n","    if res_min \u003c error_accepted:\n","      break"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1115,"status":"ok","timestamp":1675340297902,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"IJ1OBYY6DwGz","outputId":"7f859746-7943-40f8-c59b-dbcd4630c4f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["[G  10] score=(-157, -293, -470): 'I_\\\\s\\x83\\x14\\x80hncT3'\n","[G  20] score=( -73, -109, -170): ';c`sl\\x1dXtghX!'\n","[G  30] score=( -29,  -51,  -79): 'Idgll\\x1dXosl_*'\n","[G  40] score=( -15,  -25,  -34): 'Ifklo\\x1fXosld*'\n","[G  50] score=(  -7,  -14,  -21): 'Idllo\\x1fXoqld#'\n","[G  60] score=(  -3,   -5,  -14): 'Ifllo Xorld!'\n","[G  70] score=(   0,   -1,   -8): 'Hello World!'\n","[G  80] score=(   0,    0,   -9): 'Hello World!'\n","[G  90] score=(   0,    0,   -6): 'Hello World!'\n","[G 100] score=(   0,    0,   -6): 'Hello World!'\n","[G 110] score=(   0,    0,   -7): 'Hello World!'\n","[G 120] score=(   0,    0,   -7): 'Hello World!'\n","[G 130] score=(   0,    0,   -7): 'Hello World!'\n","[G 140] score=(   0,    0,   -6): 'Hello World!'\n","[G 150] score=(   0,    0,   -7): 'Hello World!'\n","[G 160] score=(   0,    0,   -8): 'Hello World!'\n","[G 170] score=(   0,    0,   -5): 'Hello World!'\n","[G 180] score=(   0,    0,   -7): 'Hello World!'\n","[G 190] score=(   0,    0,   -5): 'Hello World!'\n","[G 200] score=(   0,    0,   -7): 'Hello World!'\n"]}],"source":["# Ejemplo un poco más complejo de un GA que tiene que encontrar la cadena 'Hello Word!'\n","# http://www.obitko.com/tutorials/genetic-algorithms/ga-basic-description.php\n","\n","import random\n","\n","class GeneticAlgorithm(object):\n","    def __init__(self, genetics):\n","        self.genetics = genetics\n","        pass\n","\n","    def run(self):\n","        population = self.genetics.initial()\n","        while True:\n","            fits_pops = [(self.genetics.fitness(ch),  ch) for ch in population]\n","            if self.genetics.check_stop(fits_pops): break\n","            population = self.next(fits_pops)\n","            pass\n","        return population\n","\n","    def next(self, fits):\n","        parents_generator = self.genetics.parents(fits)\n","        size = len(fits)\n","        nexts = []\n","        while len(nexts) \u003c size:\n","            parents = next(parents_generator)\n","            cross = random.random() \u003c self.genetics.probability_crossover()\n","            children = self.genetics.crossover(parents) if cross else parents\n","            for ch in children:\n","                mutate = random.random() \u003c self.genetics.probability_mutation()\n","                nexts.append(self.genetics.mutation(ch) if mutate else ch)\n","                pass\n","            pass\n","        return nexts[0:size]\n","    pass\n","\n","class GeneticFunctions(object):\n","    def probability_crossover(self):\n","        # returns rate of occur crossover(0.0-1.0)\n","        return 1.0\n","\n","    def probability_mutation(self):\n","        # returns rate of occur mutation(0.0-1.0)\n","        return 0.0\n","\n","    def initial(self):\n","        # returns list of initial population        \n","        return []\n","\n","    def fitness(self, chromosome):\n","        # returns domain fitness value of chromosome\n","        return len(chromosome)\n","\n","    def check_stop(self, fits_populations):\n","        # stop run if returns True\n","        # - fits_populations: list of (fitness_value, chromosome)\n","        return False\n","\n","    def parents(self, fits_populations):\n","        r\"\"\"generator of selected parents\n","        \"\"\"\n","        gen = iter(sorted(fits_populations))\n","        while True:\n","            f1, ch1 = next(gen)\n","            f2, ch2 = next(gen)\n","            yield (ch1, ch2)\n","            pass\n","        return\n","\n","    def crossover(self, parents):\n","        r\"\"\"breed children\n","        \"\"\"\n","        return parents\n","\n","    def mutation(self, chromosome):\n","        r\"\"\"mutate chromosome\n","        \"\"\"\n","        return chromosome\n","    pass\n","\n","if __name__ == \"__main__\":\n","    \"\"\"\n","    example: Mapped guess prepared Text\n","    \"\"\"\n","    class GuessText(GeneticFunctions):\n","        def __init__(self, target_text,\n","                     limit=200, size=400,\n","                     prob_crossover=0.9, prob_mutation=0.2):\n","            self.target = self.text2chromo(target_text)\n","            self.counter = 0\n","\n","            self.limit = limit\n","            self.size = size\n","            self.prob_crossover = prob_crossover\n","            self.prob_mutation = prob_mutation\n","            pass\n","\n","        # GeneticFunctions interface impls\n","        def probability_crossover(self):\n","            return self.prob_crossover\n","\n","        def probability_mutation(self):\n","            return self.prob_mutation\n","\n","        def initial(self):\n","            return [self.random_chromo() for j in range(self.size)]\n","\n","        def fitness(self, chromo):\n","            # larger is better, matched == 0\n","            return -sum(abs(c - t) for c, t in zip(chromo, self.target))\n","\n","        def check_stop(self, fits_populations):\n","            self.counter += 1\n","            if self.counter % 10 == 0:\n","                best_match = list(sorted(fits_populations))[-1][1]\n","                fits = [f for f, ch in fits_populations]\n","                best = max(fits)\n","                worst = min(fits)\n","                ave = sum(fits) / len(fits)\n","                print(\n","                    \"[G %3d] score=(%4d, %4d, %4d): %r\" %\n","                    (self.counter, best, ave, worst,\n","                     self.chromo2text(best_match)))\n","                pass\n","            return self.counter \u003e= self.limit\n","\n","        def parents(self, fits_populations):\n","            while True:\n","                father = self.tournament(fits_populations)\n","                mother = self.tournament(fits_populations)\n","                yield (father, mother)\n","                pass\n","            pass\n","\n","        def crossover(self, parents):\n","            father, mother = parents\n","            index1 = random.randint(1, len(self.target) - 2)\n","            index2 = random.randint(1, len(self.target) - 2)\n","            if index1 \u003e index2: index1, index2 = index2, index1\n","            child1 = father[:index1] + mother[index1:index2] + father[index2:]\n","            child2 = mother[:index1] + father[index1:index2] + mother[index2:]\n","            return (child1, child2)\n","\n","        def mutation(self, chromosome):\n","            index = random.randint(0, len(self.target) - 1)\n","            vary = random.randint(-5, 5)\n","            mutated = list(chromosome)\n","            mutated[index] += vary\n","            return mutated\n","\n","        # internals\n","        def tournament(self, fits_populations):\n","            alicef, alice = self.select_random(fits_populations)\n","            bobf, bob = self.select_random(fits_populations)\n","            return alice if alicef \u003e bobf else bob\n","\n","        def select_random(self, fits_populations):\n","            return fits_populations[random.randint(0, len(fits_populations)-1)]\n","\n","        def text2chromo(self, text):\n","            return [ord(ch) for ch in text]\n","        def chromo2text(self, chromo):\n","            return \"\".join(chr(max(1, min(ch, 255))) for ch in chromo)\n","\n","        def random_chromo(self):\n","            return [random.randint(1, 255) for i in range(len(self.target))]\n","        pass\n","\n","    GeneticAlgorithm(GuessText(\"Hello World!\")).run()\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"Hs1CFgGip95-"},"source":["Fijaos como es capaz de llegar a la cadena \"Hello World!\" tras unas pocas generaciones!\n","\n","Y ahora, vamos a verlo aplicado a una red neuronal. Para ello, vamos a hacer uso de una implementación disponible en Github: https://github.com/jliphard/DeepEvolve\n","\n","Para ello, vamos a clonar un repositorio con git que tiene implementado un GA para evolucionar los hiperparámetros y arquitectura de una red neuronal:"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1285,"status":"ok","timestamp":1675340305313,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"bLw7kZ3KHpMU","outputId":"d5febee4-cd33-4eba-c915-139da731d139"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'DeepEvolve'...\n","remote: Enumerating objects: 163, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 163 (delta 0), reused 0 (delta 0), pack-reused 160\u001b[K\n","Receiving objects: 100% (163/163), 1.52 MiB | 14.69 MiB/s, done.\n","Resolving deltas: 100% (84/84), done.\n"]}],"source":["!rm -rf DeepEvolve\n","!git clone https://github.com/jliphard/DeepEvolve.git"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":499,"status":"ok","timestamp":1675340308322,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"dRYp-2pXH3Kq","outputId":"755714f8-2a00-4d6d-e039-5c266fea024d"},"outputs":[{"name":"stdout","output_type":"stream","text":["DeepEvolve  sample_data\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3715,"status":"ok","timestamp":1675340315860,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"-oN1-i1hIDlT","outputId":"93e9ac1b-5a11-4b1c-f61e-dd4fe0f8f5f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n"]}],"source":["!pip install tqdm"]},{"cell_type":"markdown","metadata":{"id":"AtNOyWqfJk_t"},"source":["Quiero que veáis los parámetros entre los que va a buscar hasta encontrar la mejor combinación posible:"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1675340318052,"user":{"displayName":"Rocio Del Amor Del amor","userId":"03339734078529504323"},"user_tz":-60},"id":"8UAgRuhIJjLl"},"outputs":[],"source":["dataset='mnist_cnn'\n","if dataset == 'mnist_cnn':\n","        generations = 8 # Number of times to evolve the population.\n","        all_possible_genes = {\n","            'nb_neurons': [16, 32, 64, 128],\n","            'nb_layers':  [1, 2, 3, 4 ,5],\n","            'activation': ['relu', 'elu', 'tanh', 'sigmoid', 'hard_sigmoid','softplus','linear'],\n","            'optimizer':  ['rmsprop', 'adam', 'sgd', 'adagrad','adadelta', 'adamax', 'nadam']\n","        }"]},{"cell_type":"markdown","metadata":{"id":"kCNfBWJHGkLF"},"source":["Y ahora ejecutamos nuestro algoritmo genético:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"48cjQV0TH8vj"},"outputs":[{"name":"stdout","output_type":"stream","text":["***Dataset: cifar10_cnn\n","***Evolving for 8 generations with population size = 30***\n","  0% 0/30 [00:00\u003c?, ?it/s]2023-02-02 12:18:53.182937: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","Epoch 1/4\n","391/391 [==============================] - 5s 6ms/step - loss: 2.3546 - accuracy: 0.1019 - val_loss: 2.3001 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 2s 5ms/step - loss: 2.3083 - accuracy: 0.1036 - val_loss: 2.2996 - val_accuracy: 0.1642\n","Epoch 3/4\n","391/391 [==============================] - 2s 5ms/step - loss: 2.3043 - accuracy: 0.1055 - val_loss: 2.2990 - val_accuracy: 0.1055\n","Test loss: 2.2989985942840576\n","Test accuracy: 0.1054999977350235\n","  3% 1/30 [00:16\u003c07:50, 16.22s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 2.3027 - accuracy: 0.1016 - val_loss: 2.3022 - val_accuracy: 0.1007\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3021 - val_accuracy: 0.1008\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 2.3024 - accuracy: 0.1003 - val_loss: 2.3020 - val_accuracy: 0.1011\n","Test loss: 2.301966905593872\n","Test accuracy: 0.10109999775886536\n","  7% 2/30 [00:28\u003c06:30, 13.96s/it]Epoch 1/4\n","391/391 [==============================] - 3s 6ms/step - loss: 2.3117 - accuracy: 0.1029 - val_loss: 2.2864 - val_accuracy: 0.1267\n","Epoch 2/4\n","391/391 [==============================] - 2s 6ms/step - loss: 2.1864 - accuracy: 0.1811 - val_loss: 2.0241 - val_accuracy: 0.2831\n","Epoch 3/4\n","391/391 [==============================] - 2s 5ms/step - loss: 2.0521 - accuracy: 0.2477 - val_loss: 1.9038 - val_accuracy: 0.3292\n","Epoch 4/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.9705 - accuracy: 0.2833 - val_loss: 1.8148 - val_accuracy: 0.3593\n","Test loss: 1.8148365020751953\n","Test accuracy: 0.35929998755455017\n"," 10% 3/30 [00:42\u003c06:18, 14.03s/it]Epoch 1/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.8165 - accuracy: 0.3578 - val_loss: 1.5355 - val_accuracy: 0.4694\n","Epoch 2/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.5747 - accuracy: 0.4423 - val_loss: 1.3974 - val_accuracy: 0.5144\n","Epoch 3/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.4939 - accuracy: 0.4719 - val_loss: 1.3541 - val_accuracy: 0.5354\n","Epoch 4/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.4350 - accuracy: 0.4982 - val_loss: 1.3142 - val_accuracy: 0.5421\n","Test loss: 1.3141684532165527\n","Test accuracy: 0.5421000123023987\n"," 13% 4/30 [00:55\u003c05:47, 13.38s/it]Epoch 1/4\n","391/391 [==============================] - 6s 13ms/step - loss: 1.8270 - accuracy: 0.3387 - val_loss: 1.6037 - val_accuracy: 0.4189\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.5494 - accuracy: 0.4476 - val_loss: 1.3405 - val_accuracy: 0.5356\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.4356 - accuracy: 0.4902 - val_loss: 1.2633 - val_accuracy: 0.5583\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.3697 - accuracy: 0.5209 - val_loss: 1.1606 - val_accuracy: 0.6052\n","Test loss: 1.160584807395935\n","Test accuracy: 0.6051999926567078\n"," 17% 5/30 [01:19\u003c07:14, 17.39s/it]Epoch 1/4\n","391/391 [==============================] - 3s 8ms/step - loss: 2.3198 - accuracy: 0.1025 - val_loss: 2.3013 - val_accuracy: 0.1302\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 2.3016 - accuracy: 0.1057 - val_loss: 2.2996 - val_accuracy: 0.1413\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 2.2972 - accuracy: 0.1118 - val_loss: 2.2845 - val_accuracy: 0.1334\n","Test loss: 2.2844913005828857\n","Test accuracy: 0.13339999318122864\n"," 20% 6/30 [01:32\u003c06:22, 15.94s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 2.3375 - accuracy: 0.1003 - val_loss: 2.3031 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 2.3090 - accuracy: 0.0992 - val_loss: 2.3030 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 2.3052 - accuracy: 0.1015 - val_loss: 2.3027 - val_accuracy: 0.1000\n","Test loss: 2.3026838302612305\n","Test accuracy: 0.10000000149011612\n"," 23% 7/30 [01:46\u003c05:48, 15.16s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 2.3047 - accuracy: 0.1046 - val_loss: 2.2942 - val_accuracy: 0.1338\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.2959 - accuracy: 0.1078 - val_loss: 2.2881 - val_accuracy: 0.1487\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 2.2889 - accuracy: 0.1126 - val_loss: 2.2807 - val_accuracy: 0.1617\n","Test loss: 2.2807061672210693\n","Test accuracy: 0.16169999539852142\n"," 27% 8/30 [02:01\u003c05:35, 15.26s/it]Epoch 1/4\n","391/391 [==============================] - 3s 7ms/step - loss: 2.3134 - accuracy: 0.0992 - val_loss: 2.3024 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 2s 6ms/step - loss: 2.3028 - accuracy: 0.1028 - val_loss: 2.3019 - val_accuracy: 0.1062\n","Epoch 3/4\n","391/391 [==============================] - 2s 6ms/step - loss: 2.2856 - accuracy: 0.1196 - val_loss: 2.1410 - val_accuracy: 0.1992\n","Epoch 4/4\n","391/391 [==============================] - 2s 6ms/step - loss: 2.1143 - accuracy: 0.2117 - val_loss: 1.9665 - val_accuracy: 0.3028\n","Test loss: 1.9664793014526367\n","Test accuracy: 0.3027999997138977\n"," 30% 9/30 [02:16\u003c05:14, 15.00s/it]Epoch 1/4\n","391/391 [==============================] - 5s 12ms/step - loss: 2.3173 - accuracy: 0.0991 - val_loss: 2.3029 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.3035 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.1002\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.3033 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.1004\n","Test loss: 2.302625894546509\n","Test accuracy: 0.10040000081062317\n"," 33% 10/30 [02:32\u003c05:06, 15.31s/it]Epoch 1/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.7982 - accuracy: 0.3676 - val_loss: 1.7338 - val_accuracy: 0.3817\n","Epoch 2/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.5381 - accuracy: 0.4650 - val_loss: 1.5812 - val_accuracy: 0.4310\n","Epoch 3/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.3909 - accuracy: 0.5150 - val_loss: 1.3090 - val_accuracy: 0.5423\n","Epoch 4/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.2884 - accuracy: 0.5528 - val_loss: 1.2825 - val_accuracy: 0.5469\n","Test loss: 1.2825453281402588\n","Test accuracy: 0.5468999743461609\n"," 37% 11/30 [02:45\u003c04:38, 14.68s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 2.2354 - accuracy: 0.1623 - val_loss: 2.1301 - val_accuracy: 0.2566\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 2.0968 - accuracy: 0.2379 - val_loss: 2.0167 - val_accuracy: 0.3000\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 2.0263 - accuracy: 0.2683 - val_loss: 1.9606 - val_accuracy: 0.3158\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.9805 - accuracy: 0.2910 - val_loss: 1.9159 - val_accuracy: 0.3342\n","Test loss: 1.9159144163131714\n","Test accuracy: 0.334199994802475\n"," 40% 12/30 [03:05\u003c04:53, 16.30s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.6283 - accuracy: 0.4235 - val_loss: 1.2938 - val_accuracy: 0.5524\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3222 - accuracy: 0.5413 - val_loss: 1.1558 - val_accuracy: 0.6005\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2296 - accuracy: 0.5757 - val_loss: 1.1590 - val_accuracy: 0.5929\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1770 - accuracy: 0.5956 - val_loss: 1.0631 - val_accuracy: 0.6379\n","Test loss: 1.063092827796936\n","Test accuracy: 0.6378999948501587\n"," 43% 13/30 [03:21\u003c04:34, 16.14s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 2.3342 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 2.3029 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 2.3028 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Test loss: 2.3025901317596436\n","Test accuracy: 0.10000000149011612\n"," 47% 14/30 [03:44\u003c04:53, 18.34s/it]Epoch 1/4\n","391/391 [==============================] - 3s 8ms/step - loss: 2.1505 - accuracy: 0.2059 - val_loss: 1.9766 - val_accuracy: 0.3164\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.9740 - accuracy: 0.2876 - val_loss: 1.8519 - val_accuracy: 0.3668\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.8863 - accuracy: 0.3294 - val_loss: 1.7700 - val_accuracy: 0.3971\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.8145 - accuracy: 0.3579 - val_loss: 1.6977 - val_accuracy: 0.4145\n","Test loss: 1.6977312564849854\n","Test accuracy: 0.41449999809265137\n"," 50% 15/30 [04:07\u003c04:56, 19.80s/it]Epoch 1/4\n","391/391 [==============================] - 3s 7ms/step - loss: 2.3405 - accuracy: 0.1022 - val_loss: 2.3027 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 2s 6ms/step - loss: 2.3074 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 2s 6ms/step - loss: 2.3050 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Test loss: 2.302600622177124\n","Test accuracy: 0.10000000149011612\n"," 53% 16/30 [04:18\u003c03:58, 17.02s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 2.2998 - accuracy: 0.1116 - val_loss: 2.2901 - val_accuracy: 0.1402\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 2.2877 - accuracy: 0.1239 - val_loss: 2.2761 - val_accuracy: 0.1527\n","Epoch 3/4\n","391/391 [==============================] - 4s 9ms/step - loss: 2.2728 - accuracy: 0.1452 - val_loss: 2.2558 - val_accuracy: 0.1994\n","Test loss: 2.2558209896087646\n","Test accuracy: 0.19939999282360077\n"," 57% 17/30 [04:42\u003c04:08, 19.15s/it]Epoch 1/4\n","391/391 [==============================] - 5s 9ms/step - loss: 2.3219 - accuracy: 0.1020 - val_loss: 2.3027 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 2.3038 - accuracy: 0.1018 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 2.3033 - accuracy: 0.1003 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Test loss: 2.3026106357574463\n","Test accuracy: 0.10000000149011612\n"," 60% 18/30 [04:56\u003c03:32, 17.72s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.7793 - accuracy: 0.3545 - val_loss: 1.4168 - val_accuracy: 0.5044\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.5091 - accuracy: 0.4582 - val_loss: 1.2625 - val_accuracy: 0.5842\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4213 - accuracy: 0.4941 - val_loss: 1.1818 - val_accuracy: 0.6030\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3763 - accuracy: 0.5163 - val_loss: 1.1449 - val_accuracy: 0.6177\n","Test loss: 1.1449452638626099\n","Test accuracy: 0.6176999807357788\n"," 63% 19/30 [05:11\u003c03:04, 16.76s/it]Epoch 1/4\n","391/391 [==============================] - 5s 12ms/step - loss: 2.3082 - accuracy: 0.1165 - val_loss: 2.2509 - val_accuracy: 0.2056\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.2329 - accuracy: 0.1616 - val_loss: 2.1511 - val_accuracy: 0.2195\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.1550 - accuracy: 0.1952 - val_loss: 2.0710 - val_accuracy: 0.2358\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.1063 - accuracy: 0.2158 - val_loss: 2.0130 - val_accuracy: 0.2650\n","Test loss: 2.012993335723877\n","Test accuracy: 0.26499998569488525\n"," 67% 20/30 [05:35\u003c03:08, 18.82s/it]Epoch 1/4\n","391/391 [==============================] - 6s 13ms/step - loss: 2.3012 - accuracy: 0.1053 - val_loss: 2.2928 - val_accuracy: 0.1392\n","Epoch 2/4\n","391/391 [==============================] - 5s 12ms/step - loss: 2.2647 - accuracy: 0.1370 - val_loss: 2.1988 - val_accuracy: 0.1870\n","Epoch 3/4\n","391/391 [==============================] - 5s 12ms/step - loss: 2.1810 - accuracy: 0.1848 - val_loss: 2.1052 - val_accuracy: 0.2215\n","Epoch 4/4\n","391/391 [==============================] - 5s 13ms/step - loss: 2.1232 - accuracy: 0.2056 - val_loss: 2.0894 - val_accuracy: 0.2360\n","Test loss: 2.0893898010253906\n","Test accuracy: 0.23600000143051147\n"," 70% 21/30 [05:57\u003c03:00, 20.05s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 2.3739 - accuracy: 0.1026 - val_loss: 2.3069 - val_accuracy: 0.0991\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 2.3540 - accuracy: 0.1028 - val_loss: 2.2987 - val_accuracy: 0.1010\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 2.3385 - accuracy: 0.1037 - val_loss: 2.2917 - val_accuracy: 0.1047\n","Test loss: 2.2917234897613525\n","Test accuracy: 0.1046999990940094\n"," 73% 22/30 [06:10\u003c02:23, 17.90s/it]Epoch 1/4\n","391/391 [==============================] - 3s 7ms/step - loss: 2.5974 - accuracy: 0.0981 - val_loss: 2.3557 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 2s 6ms/step - loss: 2.5592 - accuracy: 0.1002 - val_loss: 2.3301 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 2s 6ms/step - loss: 2.5262 - accuracy: 0.1012 - val_loss: 2.3164 - val_accuracy: 0.1000\n","Test loss: 2.3163609504699707\n","Test accuracy: 0.10000000149011612\n"," 77% 23/30 [06:24\u003c01:55, 16.57s/it]Epoch 1/4\n","391/391 [==============================] - 6s 13ms/step - loss: 1.8460 - accuracy: 0.3332 - val_loss: 1.5743 - val_accuracy: 0.4444\n","Epoch 2/4\n","391/391 [==============================] - 5s 13ms/step - loss: 1.5730 - accuracy: 0.4446 - val_loss: 1.3001 - val_accuracy: 0.5371\n","Epoch 3/4\n","391/391 [==============================] - 5s 13ms/step - loss: 1.4556 - accuracy: 0.4909 - val_loss: 1.4381 - val_accuracy: 0.5048\n","Epoch 4/4\n","391/391 [==============================] - 5s 13ms/step - loss: 1.3901 - accuracy: 0.5171 - val_loss: 1.3597 - val_accuracy: 0.5288\n","Test loss: 1.35965096950531\n","Test accuracy: 0.5288000106811523\n"," 80% 24/30 [06:48\u003c01:52, 18.72s/it]Epoch 1/4\n","391/391 [==============================] - 7s 15ms/step - loss: 2.3646 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 5s 14ms/step - loss: 2.3046 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 5s 14ms/step - loss: 2.3035 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Test loss: 2.302590847015381\n","Test accuracy: 0.10000000149011612\n"," 83% 25/30 [07:11\u003c01:40, 20.18s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.7036 - accuracy: 0.3942 - val_loss: 1.5102 - val_accuracy: 0.4583\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4121 - accuracy: 0.5018 - val_loss: 1.4258 - val_accuracy: 0.4902\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2847 - accuracy: 0.5512 - val_loss: 1.2060 - val_accuracy: 0.5748\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2105 - accuracy: 0.5809 - val_loss: 1.1041 - val_accuracy: 0.6181\n","Test loss: 1.1040948629379272\n","Test accuracy: 0.6180999875068665\n"," 87% 26/30 [07:35\u003c01:25, 21.26s/it]Epoch 1/4\n","391/391 [==============================] - 6s 12ms/step - loss: 2.3335 - accuracy: 0.0990 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 2.3032 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 2.3029 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Test loss: 2.3025927543640137\n","Test accuracy: 0.10000000149011612\n"," 90% 27/30 [07:59\u003c01:06, 22.23s/it]Epoch 1/4\n","391/391 [==============================] - 4s 7ms/step - loss: 1.8208 - accuracy: 0.3198 - val_loss: 1.4921 - val_accuracy: 0.4591\n","Epoch 2/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.5523 - accuracy: 0.4333 - val_loss: 1.4219 - val_accuracy: 0.4723\n","Epoch 3/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.4475 - accuracy: 0.4800 - val_loss: 1.3260 - val_accuracy: 0.5235\n","Epoch 4/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.3984 - accuracy: 0.4973 - val_loss: 1.3111 - val_accuracy: 0.5283\n","Test loss: 1.3110660314559937\n","Test accuracy: 0.5282999873161316\n"," 93% 28/30 [08:23\u003c00:45, 22.71s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 2.3075 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 2.3027 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Test loss: 2.3025903701782227\n","Test accuracy: 0.10000000149011612\n"," 97% 29/30 [08:36\u003c00:19, 19.60s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 2.3561 - accuracy: 0.1008 - val_loss: 2.3031 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 2.3080 - accuracy: 0.1012 - val_loss: 2.3027 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 2.3044 - accuracy: 0.1005 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Test loss: 2.3026177883148193\n","Test accuracy: 0.10000000149011612\n","100% 30/30 [08:49\u003c00:00, 17.64s/it]\n","  0% 0/30 [00:00\u003c?, ?it/s]Epoch 1/4\n","391/391 [==============================] - 5s 12ms/step - loss: 2.3555 - accuracy: 0.1001 - val_loss: 2.3028 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.3082 - accuracy: 0.1009 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.3055 - accuracy: 0.0994 - val_loss: 2.3025 - val_accuracy: 0.1000\n","Test loss: 2.302544355392456\n","Test accuracy: 0.10000000149011612\n"," 17% 5/30 [00:23\u003c01:58,  4.72s/it]Epoch 1/4\n","391/391 [==============================] - 3s 6ms/step - loss: 2.3066 - accuracy: 0.0990 - val_loss: 2.3057 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 2s 5ms/step - loss: 2.3091 - accuracy: 0.1093 - val_loss: 2.2534 - val_accuracy: 0.1261\n","Epoch 3/4\n","391/391 [==============================] - 2s 5ms/step - loss: 2.1901 - accuracy: 0.1639 - val_loss: 2.0500 - val_accuracy: 0.2651\n","Epoch 4/4\n","391/391 [==============================] - 2s 5ms/step - loss: 2.0510 - accuracy: 0.2340 - val_loss: 1.9233 - val_accuracy: 0.3229\n","Test loss: 1.9233462810516357\n","Test accuracy: 0.3228999972343445\n"," 20% 6/30 [00:36\u003c02:38,  6.60s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 2.1499 - accuracy: 0.2001 - val_loss: 1.9592 - val_accuracy: 0.3258\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.9448 - accuracy: 0.2976 - val_loss: 1.8121 - val_accuracy: 0.3695\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.8339 - accuracy: 0.3463 - val_loss: 1.8019 - val_accuracy: 0.3474\n","Epoch 4/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.7610 - accuracy: 0.3731 - val_loss: 1.6244 - val_accuracy: 0.4361\n","Test loss: 1.624367594718933\n","Test accuracy: 0.4361000061035156\n"," 23% 7/30 [00:55\u003c03:37,  9.44s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 2.3179 - accuracy: 0.1007 - val_loss: 2.3027 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 2.3044 - accuracy: 0.1020 - val_loss: 2.3028 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 2.3034 - accuracy: 0.1009 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Test loss: 2.302635431289673\n","Test accuracy: 0.10000000149011612\n"," 27% 8/30 [01:07\u003c03:44, 10.22s/it]Epoch 1/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.8131 - accuracy: 0.3436 - val_loss: 1.4568 - val_accuracy: 0.4974\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.5425 - accuracy: 0.4476 - val_loss: 1.2940 - val_accuracy: 0.5656\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4509 - accuracy: 0.4820 - val_loss: 1.2363 - val_accuracy: 0.5798\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3963 - accuracy: 0.5051 - val_loss: 1.2377 - val_accuracy: 0.5643\n","Test loss: 1.2377216815948486\n","Test accuracy: 0.564300000667572\n"," 30% 9/30 [01:30\u003c04:47, 13.68s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.6806 - accuracy: 0.4111 - val_loss: 1.5333 - val_accuracy: 0.4446\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3963 - accuracy: 0.5114 - val_loss: 1.3413 - val_accuracy: 0.5260\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2820 - accuracy: 0.5522 - val_loss: 1.1950 - val_accuracy: 0.5856\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2023 - accuracy: 0.5850 - val_loss: 1.2095 - val_accuracy: 0.5822\n","Test loss: 1.209549069404602\n","Test accuracy: 0.5821999907493591\n"," 33% 10/30 [01:54\u003c05:26, 16.34s/it]Epoch 1/4\n","391/391 [==============================] - 6s 13ms/step - loss: 2.3143 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 5s 12ms/step - loss: 2.3029 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.3028 - accuracy: 0.0994 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Test loss: 2.3025882244110107\n","Test accuracy: 0.10000000149011612\n"," 37% 11/30 [02:17\u003c05:50, 18.44s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 2.1492 - accuracy: 0.1968 - val_loss: 1.9963 - val_accuracy: 0.3030\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.9865 - accuracy: 0.2823 - val_loss: 1.8563 - val_accuracy: 0.3635\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.8791 - accuracy: 0.3226 - val_loss: 1.7429 - val_accuracy: 0.3950\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.7956 - accuracy: 0.3581 - val_loss: 1.6632 - val_accuracy: 0.4246\n","Test loss: 1.6631877422332764\n","Test accuracy: 0.4246000051498413\n"," 40% 12/30 [02:33\u003c05:19, 17.77s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.7273 - accuracy: 0.3887 - val_loss: 1.3374 - val_accuracy: 0.5364\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4002 - accuracy: 0.5109 - val_loss: 1.2129 - val_accuracy: 0.5823\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3057 - accuracy: 0.5473 - val_loss: 1.1494 - val_accuracy: 0.6043\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2457 - accuracy: 0.5726 - val_loss: 1.1778 - val_accuracy: 0.5887\n","Test loss: 1.1778037548065186\n","Test accuracy: 0.588699996471405\n"," 43% 13/30 [02:57\u003c05:33, 19.60s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.8132 - accuracy: 0.3391 - val_loss: 1.4603 - val_accuracy: 0.4896\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.5311 - accuracy: 0.4539 - val_loss: 1.2909 - val_accuracy: 0.5513\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.4088 - accuracy: 0.5006 - val_loss: 1.2079 - val_accuracy: 0.5800\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.3500 - accuracy: 0.5220 - val_loss: 1.1792 - val_accuracy: 0.5892\n","Test loss: 1.1791893243789673\n","Test accuracy: 0.5892000198364258\n"," 47% 14/30 [03:21\u003c05:33, 20.84s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.6005 - accuracy: 0.4317 - val_loss: 1.2839 - val_accuracy: 0.5391\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3057 - accuracy: 0.5451 - val_loss: 1.1306 - val_accuracy: 0.6085\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2009 - accuracy: 0.5829 - val_loss: 1.0745 - val_accuracy: 0.6298\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1545 - accuracy: 0.5996 - val_loss: 1.0289 - val_accuracy: 0.6435\n","Test loss: 1.0289055109024048\n","Test accuracy: 0.6434999704360962\n"," 50% 15/30 [03:38\u003c04:53, 19.60s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.7211 - accuracy: 0.3883 - val_loss: 1.5010 - val_accuracy: 0.4776\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4350 - accuracy: 0.4965 - val_loss: 1.2814 - val_accuracy: 0.5575\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3014 - accuracy: 0.5496 - val_loss: 1.2194 - val_accuracy: 0.5686\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2157 - accuracy: 0.5798 - val_loss: 1.1486 - val_accuracy: 0.5993\n","Test loss: 1.1485873460769653\n","Test accuracy: 0.5993000268936157\n"," 53% 16/30 [03:53\u003c04:17, 18.36s/it]Epoch 1/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.6505 - accuracy: 0.4177 - val_loss: 1.3106 - val_accuracy: 0.5363\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3202 - accuracy: 0.5426 - val_loss: 1.2389 - val_accuracy: 0.5607\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2207 - accuracy: 0.5787 - val_loss: 1.2282 - val_accuracy: 0.5656\n","Test loss: 1.2282369136810303\n","Test accuracy: 0.5655999779701233\n"," 57% 17/30 [04:06\u003c03:37, 16.75s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.8385 - accuracy: 0.3339 - val_loss: 1.4333 - val_accuracy: 0.4968\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.5428 - accuracy: 0.4450 - val_loss: 1.3164 - val_accuracy: 0.5332\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4412 - accuracy: 0.4906 - val_loss: 1.2122 - val_accuracy: 0.5848\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3984 - accuracy: 0.5033 - val_loss: 1.1628 - val_accuracy: 0.6162\n","Test loss: 1.1628166437149048\n","Test accuracy: 0.6161999702453613\n"," 60% 18/30 [04:21\u003c03:14, 16.20s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.5800 - accuracy: 0.4401 - val_loss: 1.2584 - val_accuracy: 0.5665\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2760 - accuracy: 0.5566 - val_loss: 1.1674 - val_accuracy: 0.5945\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.1998 - accuracy: 0.5855 - val_loss: 1.1120 - val_accuracy: 0.6172\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.1446 - accuracy: 0.6058 - val_loss: 1.0583 - val_accuracy: 0.6335\n","Test loss: 1.0583165884017944\n","Test accuracy: 0.6334999799728394\n"," 63% 19/30 [04:45\u003c03:23, 18.46s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.7098 - accuracy: 0.3911 - val_loss: 1.3547 - val_accuracy: 0.5275\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4012 - accuracy: 0.5105 - val_loss: 1.1933 - val_accuracy: 0.5871\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3171 - accuracy: 0.5442 - val_loss: 1.1461 - val_accuracy: 0.6028\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2677 - accuracy: 0.5638 - val_loss: 1.1398 - val_accuracy: 0.6064\n","Test loss: 1.1398112773895264\n","Test accuracy: 0.6064000129699707\n"," 67% 20/30 [05:00\u003c02:54, 17.48s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.7498 - accuracy: 0.3794 - val_loss: 1.6028 - val_accuracy: 0.4266\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4620 - accuracy: 0.4880 - val_loss: 1.3079 - val_accuracy: 0.5521\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3137 - accuracy: 0.5433 - val_loss: 1.2467 - val_accuracy: 0.5617\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2361 - accuracy: 0.5723 - val_loss: 1.2122 - val_accuracy: 0.5796\n","Test loss: 1.212151050567627\n","Test accuracy: 0.5795999765396118\n"," 70% 21/30 [05:23\u003c02:52, 19.19s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.6100 - accuracy: 0.4256 - val_loss: 1.2600 - val_accuracy: 0.5606\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3102 - accuracy: 0.5406 - val_loss: 1.1308 - val_accuracy: 0.6079\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2061 - accuracy: 0.5806 - val_loss: 1.1033 - val_accuracy: 0.6129\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1628 - accuracy: 0.5981 - val_loss: 1.0376 - val_accuracy: 0.6411\n","Test loss: 1.0376169681549072\n","Test accuracy: 0.6410999894142151\n"," 73% 22/30 [05:47\u003c02:44, 20.54s/it]Epoch 1/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.6974 - accuracy: 0.3888 - val_loss: 1.3817 - val_accuracy: 0.5165\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.4405 - accuracy: 0.4913 - val_loss: 1.2440 - val_accuracy: 0.5670\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.3304 - accuracy: 0.5332 - val_loss: 1.1892 - val_accuracy: 0.5845\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.2664 - accuracy: 0.5552 - val_loss: 1.1541 - val_accuracy: 0.5992\n","Test loss: 1.1540569067001343\n","Test accuracy: 0.5992000102996826\n"," 77% 23/30 [06:11\u003c02:30, 21.47s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.7479 - accuracy: 0.3749 - val_loss: 1.4304 - val_accuracy: 0.4957\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4255 - accuracy: 0.5013 - val_loss: 1.3003 - val_accuracy: 0.5525\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3239 - accuracy: 0.5440 - val_loss: 1.1706 - val_accuracy: 0.6016\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2672 - accuracy: 0.5627 - val_loss: 1.1667 - val_accuracy: 0.5937\n","Test loss: 1.1666909456253052\n","Test accuracy: 0.5936999917030334\n"," 80% 24/30 [06:35\u003c02:13, 22.26s/it]Epoch 1/4\n","391/391 [==============================] - 6s 13ms/step - loss: 2.3062 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 5s 12ms/step - loss: 2.3027 - accuracy: 0.0960 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 5s 12ms/step - loss: 2.1508 - accuracy: 0.1921 - val_loss: 1.9146 - val_accuracy: 0.3268\n","Epoch 4/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.8961 - accuracy: 0.3064 - val_loss: 1.7141 - val_accuracy: 0.3974\n","Test loss: 1.71409273147583\n","Test accuracy: 0.39739999175071716\n"," 83% 25/30 [06:57\u003c01:51, 22.37s/it]Epoch 1/4\n","391/391 [==============================] - 5s 12ms/step - loss: 2.2135 - accuracy: 0.1752 - val_loss: 2.0480 - val_accuracy: 0.2892\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.0272 - accuracy: 0.2612 - val_loss: 1.8752 - val_accuracy: 0.3692\n","Epoch 3/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.8980 - accuracy: 0.3123 - val_loss: 1.7599 - val_accuracy: 0.3905\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.8111 - accuracy: 0.3494 - val_loss: 1.7115 - val_accuracy: 0.3970\n","Test loss: 1.7114982604980469\n","Test accuracy: 0.3970000147819519\n"," 87% 26/30 [07:18\u003c01:27, 21.90s/it]Epoch 1/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.5976 - accuracy: 0.4350 - val_loss: 1.2727 - val_accuracy: 0.5557\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2951 - accuracy: 0.5498 - val_loss: 1.1710 - val_accuracy: 0.6026\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2115 - accuracy: 0.5818 - val_loss: 1.1336 - val_accuracy: 0.6074\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.1601 - accuracy: 0.6024 - val_loss: 1.2006 - val_accuracy: 0.5753\n","Test loss: 1.2006245851516724\n","Test accuracy: 0.5752999782562256\n"," 90% 27/30 [07:32\u003c00:58, 19.52s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.8477 - accuracy: 0.3378 - val_loss: 1.4447 - val_accuracy: 0.5117\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.5386 - accuracy: 0.4497 - val_loss: 1.2524 - val_accuracy: 0.5706\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4406 - accuracy: 0.4862 - val_loss: 1.2225 - val_accuracy: 0.5764\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3854 - accuracy: 0.5092 - val_loss: 1.1643 - val_accuracy: 0.6087\n","Test loss: 1.1642889976501465\n","Test accuracy: 0.6086999773979187\n"," 93% 28/30 [07:48\u003c00:36, 18.28s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.8906 - accuracy: 0.3074 - val_loss: 1.5438 - val_accuracy: 0.4649\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.6443 - accuracy: 0.4008 - val_loss: 1.3979 - val_accuracy: 0.5170\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.5621 - accuracy: 0.4294 - val_loss: 1.3216 - val_accuracy: 0.5441\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.5076 - accuracy: 0.4546 - val_loss: 1.2739 - val_accuracy: 0.5666\n","Test loss: 1.2738690376281738\n","Test accuracy: 0.5666000247001648\n"," 97% 29/30 [08:08\u003c00:19, 19.04s/it]Epoch 1/4\n","391/391 [==============================] - 6s 13ms/step - loss: 1.6692 - accuracy: 0.4086 - val_loss: 1.3284 - val_accuracy: 0.5345\n","Epoch 2/4\n","391/391 [==============================] - 5s 13ms/step - loss: 1.3732 - accuracy: 0.5241 - val_loss: 1.2130 - val_accuracy: 0.5853\n","Epoch 3/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.2880 - accuracy: 0.5562 - val_loss: 1.1224 - val_accuracy: 0.6136\n","Epoch 4/4\n","391/391 [==============================] - 5s 13ms/step - loss: 1.2182 - accuracy: 0.5807 - val_loss: 1.0862 - val_accuracy: 0.6237\n","Test loss: 1.086181879043579\n","Test accuracy: 0.6237000226974487\n","100% 30/30 [08:32\u003c00:00, 17.09s/it]\n","  0% 0/30 [00:00\u003c?, ?it/s]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.6186 - accuracy: 0.4212 - val_loss: 1.2540 - val_accuracy: 0.5676\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3076 - accuracy: 0.5450 - val_loss: 1.1594 - val_accuracy: 0.6052\n","Epoch 3/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.2140 - accuracy: 0.5790 - val_loss: 1.1314 - val_accuracy: 0.5997\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1552 - accuracy: 0.6014 - val_loss: 1.0397 - val_accuracy: 0.6374\n","Test loss: 1.0397379398345947\n","Test accuracy: 0.6373999714851379\n"," 17% 5/30 [00:17\u003c01:25,  3.40s/it]Epoch 1/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.6808 - accuracy: 0.4075 - val_loss: 1.4202 - val_accuracy: 0.5045\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4364 - accuracy: 0.4964 - val_loss: 1.3073 - val_accuracy: 0.5499\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3355 - accuracy: 0.5357 - val_loss: 1.2247 - val_accuracy: 0.5749\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2678 - accuracy: 0.5554 - val_loss: 1.2392 - val_accuracy: 0.5716\n","Test loss: 1.2392014265060425\n","Test accuracy: 0.5716000199317932\n"," 20% 6/30 [00:30\u003c02:17,  5.71s/it]Epoch 1/4\n","391/391 [==============================] - 5s 12ms/step - loss: 2.3200 - accuracy: 0.0974 - val_loss: 2.3028 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 5s 12ms/step - loss: 2.3046 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.3033 - accuracy: 0.0985 - val_loss: 2.3027 - val_accuracy: 0.1000\n","Test loss: 2.302664279937744\n","Test accuracy: 0.10000000149011612\n"," 23% 7/30 [00:54\u003c03:49,  9.98s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.6173 - accuracy: 0.4259 - val_loss: 1.2844 - val_accuracy: 0.5602\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3183 - accuracy: 0.5417 - val_loss: 1.1615 - val_accuracy: 0.5964\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2332 - accuracy: 0.5729 - val_loss: 1.1373 - val_accuracy: 0.6080\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1791 - accuracy: 0.5960 - val_loss: 1.1411 - val_accuracy: 0.6146\n","Test loss: 1.1410526037216187\n","Test accuracy: 0.6146000027656555\n"," 27% 8/30 [01:09\u003c04:10, 11.37s/it]Epoch 1/4\n","391/391 [==============================] - 5s 12ms/step - loss: 2.3215 - accuracy: 0.1007 - val_loss: 2.3027 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.3040 - accuracy: 0.1011 - val_loss: 2.3028 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 5s 12ms/step - loss: 2.3033 - accuracy: 0.0996 - val_loss: 2.3027 - val_accuracy: 0.1000\n","Test loss: 2.302682876586914\n","Test accuracy: 0.10000000149011612\n"," 30% 9/30 [01:33\u003c05:09, 14.74s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.7856 - accuracy: 0.3617 - val_loss: 1.5407 - val_accuracy: 0.4563\n","Epoch 2/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.5086 - accuracy: 0.4680 - val_loss: 1.3300 - val_accuracy: 0.5360\n","Epoch 3/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.3693 - accuracy: 0.5198 - val_loss: 1.2457 - val_accuracy: 0.5638\n","Epoch 4/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.2832 - accuracy: 0.5552 - val_loss: 1.1912 - val_accuracy: 0.5819\n","Test loss: 1.1912075281143188\n","Test accuracy: 0.5819000005722046\n"," 33% 10/30 [01:57\u003c05:44, 17.24s/it]Epoch 1/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.5891 - accuracy: 0.4397 - val_loss: 1.3355 - val_accuracy: 0.5278\n","Epoch 2/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.2843 - accuracy: 0.5564 - val_loss: 1.1327 - val_accuracy: 0.6060\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1914 - accuracy: 0.5902 - val_loss: 1.0781 - val_accuracy: 0.6301\n","Epoch 4/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.1441 - accuracy: 0.6068 - val_loss: 1.0674 - val_accuracy: 0.6426\n","Test loss: 1.0674082040786743\n","Test accuracy: 0.6425999999046326\n"," 37% 11/30 [02:14\u003c05:28, 17.31s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.8177 - accuracy: 0.3407 - val_loss: 1.4810 - val_accuracy: 0.4849\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.5528 - accuracy: 0.4396 - val_loss: 1.3350 - val_accuracy: 0.5330\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4542 - accuracy: 0.4768 - val_loss: 1.2342 - val_accuracy: 0.5724\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.4021 - accuracy: 0.4994 - val_loss: 1.2031 - val_accuracy: 0.5923\n","Test loss: 1.2031422853469849\n","Test accuracy: 0.5922999978065491\n"," 40% 12/30 [02:31\u003c05:09, 17.21s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.7112 - accuracy: 0.3854 - val_loss: 1.4258 - val_accuracy: 0.4847\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4078 - accuracy: 0.5076 - val_loss: 1.2390 - val_accuracy: 0.5717\n","Epoch 3/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.3080 - accuracy: 0.5424 - val_loss: 1.1714 - val_accuracy: 0.5882\n","Epoch 4/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.2482 - accuracy: 0.5664 - val_loss: 1.1500 - val_accuracy: 0.5956\n","Test loss: 1.1499954462051392\n","Test accuracy: 0.5956000089645386\n"," 43% 13/30 [02:49\u003c04:53, 17.28s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.6250 - accuracy: 0.4238 - val_loss: 1.3076 - val_accuracy: 0.5378\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3208 - accuracy: 0.5400 - val_loss: 1.1572 - val_accuracy: 0.6004\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2314 - accuracy: 0.5752 - val_loss: 1.1381 - val_accuracy: 0.6046\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1776 - accuracy: 0.5962 - val_loss: 1.1184 - val_accuracy: 0.6180\n","Test loss: 1.1183947324752808\n","Test accuracy: 0.6179999709129333\n"," 47% 14/30 [03:04\u003c04:26, 16.67s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.7465 - accuracy: 0.3637 - val_loss: 1.4395 - val_accuracy: 0.4848\n","Epoch 2/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.4498 - accuracy: 0.4869 - val_loss: 1.3087 - val_accuracy: 0.5439\n","Epoch 3/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.3613 - accuracy: 0.5241 - val_loss: 1.2217 - val_accuracy: 0.5730\n","Epoch 4/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.3130 - accuracy: 0.5425 - val_loss: 1.2078 - val_accuracy: 0.5791\n","Test loss: 1.207834243774414\n","Test accuracy: 0.5791000127792358\n"," 50% 15/30 [03:21\u003c04:10, 16.73s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 2.2637 - accuracy: 0.1513 - val_loss: 2.1758 - val_accuracy: 0.2519\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 2.1320 - accuracy: 0.2199 - val_loss: 2.0486 - val_accuracy: 0.2903\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 2.0432 - accuracy: 0.2571 - val_loss: 1.9729 - val_accuracy: 0.3269\n","Epoch 4/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.9896 - accuracy: 0.2828 - val_loss: 1.9290 - val_accuracy: 0.3361\n","Test loss: 1.9289597272872925\n","Test accuracy: 0.3361000120639801\n"," 53% 16/30 [03:44\u003c04:22, 18.74s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.6230 - accuracy: 0.4169 - val_loss: 1.3804 - val_accuracy: 0.5030\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2967 - accuracy: 0.5435 - val_loss: 1.1902 - val_accuracy: 0.5777\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2058 - accuracy: 0.5816 - val_loss: 1.1424 - val_accuracy: 0.5919\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1566 - accuracy: 0.5980 - val_loss: 1.0717 - val_accuracy: 0.6275\n","Test loss: 1.0717111825942993\n","Test accuracy: 0.6274999976158142\n"," 57% 17/30 [04:01\u003c03:56, 18.19s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.6382 - accuracy: 0.4176 - val_loss: 1.3272 - val_accuracy: 0.5341\n","Epoch 2/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.3250 - accuracy: 0.5395 - val_loss: 1.1343 - val_accuracy: 0.6085\n","Epoch 3/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.2115 - accuracy: 0.5772 - val_loss: 1.0950 - val_accuracy: 0.6141\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1697 - accuracy: 0.5961 - val_loss: 1.0531 - val_accuracy: 0.6354\n","Test loss: 1.0531247854232788\n","Test accuracy: 0.6353999972343445\n"," 60% 18/30 [04:24\u003c03:56, 19.69s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.5685 - accuracy: 0.4429 - val_loss: 1.3263 - val_accuracy: 0.5360\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2633 - accuracy: 0.5574 - val_loss: 1.1379 - val_accuracy: 0.6107\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1627 - accuracy: 0.5953 - val_loss: 1.1029 - val_accuracy: 0.6139\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1080 - accuracy: 0.6148 - val_loss: 1.0274 - val_accuracy: 0.6483\n","Test loss: 1.0274180173873901\n","Test accuracy: 0.6482999920845032\n"," 63% 19/30 [04:48\u003c03:49, 20.91s/it]Epoch 1/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.6394 - accuracy: 0.4159 - val_loss: 1.2830 - val_accuracy: 0.5568\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3245 - accuracy: 0.5383 - val_loss: 1.2530 - val_accuracy: 0.5496\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2249 - accuracy: 0.5735 - val_loss: 1.0867 - val_accuracy: 0.6219\n","Epoch 4/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.1633 - accuracy: 0.5974 - val_loss: 1.0878 - val_accuracy: 0.6210\n","Test loss: 1.0878281593322754\n","Test accuracy: 0.6209999918937683\n"," 67% 20/30 [05:12\u003c03:37, 21.77s/it]Epoch 1/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.6574 - accuracy: 0.4089 - val_loss: 1.3413 - val_accuracy: 0.5376\n","Epoch 2/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.3449 - accuracy: 0.5288 - val_loss: 1.2350 - val_accuracy: 0.5569\n","Epoch 3/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.2364 - accuracy: 0.5703 - val_loss: 1.0884 - val_accuracy: 0.6220\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.1874 - accuracy: 0.5888 - val_loss: 1.1111 - val_accuracy: 0.6135\n","Test loss: 1.111117959022522\n","Test accuracy: 0.6134999990463257\n"," 70% 21/30 [05:35\u003c03:20, 22.23s/it]Epoch 1/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.7822 - accuracy: 0.3583 - val_loss: 1.4458 - val_accuracy: 0.4983\n","Epoch 2/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.4758 - accuracy: 0.4816 - val_loss: 1.2831 - val_accuracy: 0.5603\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3679 - accuracy: 0.5232 - val_loss: 1.2512 - val_accuracy: 0.5679\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3017 - accuracy: 0.5468 - val_loss: 1.2347 - val_accuracy: 0.5648\n","Test loss: 1.234697937965393\n","Test accuracy: 0.5648000240325928\n"," 73% 22/30 [05:59\u003c03:01, 22.68s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.6359 - accuracy: 0.4188 - val_loss: 1.3234 - val_accuracy: 0.5254\n","Epoch 2/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.3192 - accuracy: 0.5396 - val_loss: 1.1458 - val_accuracy: 0.6054\n","Epoch 3/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.2162 - accuracy: 0.5777 - val_loss: 1.1402 - val_accuracy: 0.5983\n","Epoch 4/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.1597 - accuracy: 0.5975 - val_loss: 1.0637 - val_accuracy: 0.6355\n","Test loss: 1.0636948347091675\n","Test accuracy: 0.6355000138282776\n"," 77% 23/30 [06:23\u003c02:40, 23.00s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.6389 - accuracy: 0.4186 - val_loss: 1.3395 - val_accuracy: 0.5331\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3346 - accuracy: 0.5374 - val_loss: 1.1621 - val_accuracy: 0.5973\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2274 - accuracy: 0.5775 - val_loss: 1.1116 - val_accuracy: 0.6206\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1832 - accuracy: 0.5953 - val_loss: 1.1091 - val_accuracy: 0.6054\n","Test loss: 1.1091150045394897\n","Test accuracy: 0.605400025844574\n"," 80% 24/30 [06:39\u003c02:05, 20.94s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.7463 - accuracy: 0.3722 - val_loss: 1.3747 - val_accuracy: 0.5247\n","Epoch 2/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.4359 - accuracy: 0.4923 - val_loss: 1.1947 - val_accuracy: 0.5933\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3216 - accuracy: 0.5399 - val_loss: 1.2030 - val_accuracy: 0.5715\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2624 - accuracy: 0.5599 - val_loss: 1.1034 - val_accuracy: 0.6147\n","Test loss: 1.1034386157989502\n","Test accuracy: 0.6147000193595886\n"," 83% 25/30 [06:56\u003c01:38, 19.65s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.8011 - accuracy: 0.3461 - val_loss: 1.4415 - val_accuracy: 0.4996\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.5355 - accuracy: 0.4509 - val_loss: 1.2847 - val_accuracy: 0.5629\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4452 - accuracy: 0.4833 - val_loss: 1.1900 - val_accuracy: 0.5982\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3962 - accuracy: 0.5044 - val_loss: 1.1999 - val_accuracy: 0.5982\n","Test loss: 1.1998521089553833\n","Test accuracy: 0.5982000231742859\n"," 87% 26/30 [07:19\u003c01:22, 20.72s/it]Epoch 1/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.6498 - accuracy: 0.4144 - val_loss: 1.3721 - val_accuracy: 0.5129\n","Epoch 2/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.3454 - accuracy: 0.5305 - val_loss: 1.1980 - val_accuracy: 0.5797\n","Epoch 3/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.2465 - accuracy: 0.5708 - val_loss: 1.1447 - val_accuracy: 0.5986\n","Epoch 4/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.1954 - accuracy: 0.5886 - val_loss: 1.0957 - val_accuracy: 0.6166\n","Test loss: 1.095690131187439\n","Test accuracy: 0.616599977016449\n"," 90% 27/30 [07:32\u003c00:55, 18.41s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.8816 - accuracy: 0.3155 - val_loss: 1.6070 - val_accuracy: 0.4337\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.6367 - accuracy: 0.4122 - val_loss: 1.4861 - val_accuracy: 0.4751\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.5267 - accuracy: 0.4554 - val_loss: 1.3999 - val_accuracy: 0.5111\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4435 - accuracy: 0.4889 - val_loss: 1.3016 - val_accuracy: 0.5456\n","Test loss: 1.3016000986099243\n","Test accuracy: 0.5455999970436096\n"," 93% 28/30 [07:46\u003c00:34, 17.28s/it]Epoch 1/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.6880 - accuracy: 0.4020 - val_loss: 1.3354 - val_accuracy: 0.5377\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3621 - accuracy: 0.5271 - val_loss: 1.2044 - val_accuracy: 0.5812\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2647 - accuracy: 0.5633 - val_loss: 1.1147 - val_accuracy: 0.6183\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2168 - accuracy: 0.5824 - val_loss: 1.1949 - val_accuracy: 0.5773\n","Test loss: 1.194929838180542\n","Test accuracy: 0.5773000121116638\n"," 97% 29/30 [08:00\u003c00:16, 16.24s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.7644 - accuracy: 0.3459 - val_loss: 1.4182 - val_accuracy: 0.4868\n","Epoch 2/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.4498 - accuracy: 0.4808 - val_loss: 1.2438 - val_accuracy: 0.5564\n","Epoch 3/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.3459 - accuracy: 0.5235 - val_loss: 1.1622 - val_accuracy: 0.5834\n","Epoch 4/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.2953 - accuracy: 0.5469 - val_loss: 1.1262 - val_accuracy: 0.6047\n","Test loss: 1.1261523962020874\n","Test accuracy: 0.6047000288963318\n","100% 30/30 [08:19\u003c00:00, 16.66s/it]\n","  0% 0/31 [00:00\u003c?, ?it/s]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.8053 - accuracy: 0.3450 - val_loss: 1.4831 - val_accuracy: 0.4747\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.5358 - accuracy: 0.4490 - val_loss: 1.3481 - val_accuracy: 0.5322\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4441 - accuracy: 0.4866 - val_loss: 1.2441 - val_accuracy: 0.5690\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3817 - accuracy: 0.5119 - val_loss: 1.2110 - val_accuracy: 0.5851\n","Test loss: 1.2109593152999878\n","Test accuracy: 0.585099995136261\n"," 16% 5/31 [00:14\u003c01:15,  2.92s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.6197 - accuracy: 0.4207 - val_loss: 1.3227 - val_accuracy: 0.5345\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3149 - accuracy: 0.5383 - val_loss: 1.2160 - val_accuracy: 0.5707\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2127 - accuracy: 0.5760 - val_loss: 1.0962 - val_accuracy: 0.6229\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1717 - accuracy: 0.5953 - val_loss: 1.1428 - val_accuracy: 0.5969\n","Test loss: 1.142805576324463\n","Test accuracy: 0.5968999862670898\n"," 19% 6/31 [00:30\u003c02:23,  5.76s/it]Epoch 1/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.6909 - accuracy: 0.4094 - val_loss: 1.4060 - val_accuracy: 0.5218\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4379 - accuracy: 0.4976 - val_loss: 1.3185 - val_accuracy: 0.5430\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3388 - accuracy: 0.5333 - val_loss: 1.3132 - val_accuracy: 0.5416\n","Test loss: 1.3132100105285645\n","Test accuracy: 0.5415999889373779\n"," 23% 7/31 [00:41\u003c02:52,  7.18s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.7579 - accuracy: 0.3646 - val_loss: 1.4674 - val_accuracy: 0.4824\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4766 - accuracy: 0.4750 - val_loss: 1.2891 - val_accuracy: 0.5525\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3689 - accuracy: 0.5187 - val_loss: 1.2346 - val_accuracy: 0.5685\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3006 - accuracy: 0.5436 - val_loss: 1.1606 - val_accuracy: 0.5971\n","Test loss: 1.1606271266937256\n","Test accuracy: 0.597100019454956\n"," 26% 8/31 [01:05\u003c04:22, 11.43s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.6176 - accuracy: 0.4224 - val_loss: 1.2860 - val_accuracy: 0.5498\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3139 - accuracy: 0.5404 - val_loss: 1.1489 - val_accuracy: 0.5991\n","Epoch 3/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.2134 - accuracy: 0.5799 - val_loss: 1.0724 - val_accuracy: 0.6318\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1631 - accuracy: 0.5947 - val_loss: 1.0481 - val_accuracy: 0.6383\n","Test loss: 1.0480937957763672\n","Test accuracy: 0.6383000016212463\n"," 29% 9/31 [01:29\u003c05:21, 14.61s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 2.1264 - accuracy: 0.2155 - val_loss: 1.9231 - val_accuracy: 0.3405\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.9046 - accuracy: 0.3195 - val_loss: 1.7830 - val_accuracy: 0.3802\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.7887 - accuracy: 0.3648 - val_loss: 1.6535 - val_accuracy: 0.4256\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.7136 - accuracy: 0.3893 - val_loss: 1.6195 - val_accuracy: 0.4321\n","Test loss: 1.6194827556610107\n","Test accuracy: 0.43209999799728394\n"," 32% 10/31 [01:52\u003c05:59, 17.12s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.6903 - accuracy: 0.3944 - val_loss: 1.3976 - val_accuracy: 0.5031\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3737 - accuracy: 0.5172 - val_loss: 1.1815 - val_accuracy: 0.5866\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2731 - accuracy: 0.5544 - val_loss: 1.1221 - val_accuracy: 0.6069\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2137 - accuracy: 0.5750 - val_loss: 1.0833 - val_accuracy: 0.6230\n","Test loss: 1.083345651626587\n","Test accuracy: 0.6230000257492065\n"," 35% 11/31 [02:08\u003c05:34, 16.73s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.6083 - accuracy: 0.4294 - val_loss: 1.4047 - val_accuracy: 0.4919\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.2708 - accuracy: 0.5577 - val_loss: 1.0984 - val_accuracy: 0.6198\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1768 - accuracy: 0.5913 - val_loss: 1.0505 - val_accuracy: 0.6453\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1165 - accuracy: 0.6157 - val_loss: 1.0086 - val_accuracy: 0.6511\n","Test loss: 1.008610486984253\n","Test accuracy: 0.6510999798774719\n"," 39% 12/31 [02:32\u003c05:56, 18.74s/it]Epoch 1/4\n","391/391 [==============================] - 5s 10ms/step - loss: 1.5285 - accuracy: 0.4626 - val_loss: 1.2582 - val_accuracy: 0.5576\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2236 - accuracy: 0.5765 - val_loss: 1.1186 - val_accuracy: 0.6136\n","Epoch 3/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.1486 - accuracy: 0.6064 - val_loss: 1.1248 - val_accuracy: 0.6117\n","Epoch 4/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.0850 - accuracy: 0.6306 - val_loss: 1.0565 - val_accuracy: 0.6424\n","Test loss: 1.056470274925232\n","Test accuracy: 0.6424000263214111\n"," 42% 13/31 [02:50\u003c05:34, 18.58s/it]Epoch 1/4\n","391/391 [==============================] - 5s 13ms/step - loss: 1.6381 - accuracy: 0.4134 - val_loss: 1.3304 - val_accuracy: 0.5269\n","Epoch 2/4\n","391/391 [==============================] - 5s 13ms/step - loss: 1.2999 - accuracy: 0.5450 - val_loss: 1.1263 - val_accuracy: 0.6114\n","Epoch 3/4\n","391/391 [==============================] - 5s 13ms/step - loss: 1.2019 - accuracy: 0.5827 - val_loss: 1.0723 - val_accuracy: 0.6309\n","Epoch 4/4\n","391/391 [==============================] - 5s 13ms/step - loss: 1.1479 - accuracy: 0.6032 - val_loss: 1.0597 - val_accuracy: 0.6261\n","Test loss: 1.0596942901611328\n","Test accuracy: 0.6261000037193298\n"," 45% 14/31 [03:14\u003c05:41, 20.08s/it]Epoch 1/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.7132 - accuracy: 0.3886 - val_loss: 1.4810 - val_accuracy: 0.4747\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4380 - accuracy: 0.4924 - val_loss: 1.3038 - val_accuracy: 0.5446\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3257 - accuracy: 0.5392 - val_loss: 1.2943 - val_accuracy: 0.5355\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2657 - accuracy: 0.5585 - val_loss: 1.1597 - val_accuracy: 0.6016\n","Test loss: 1.1596587896347046\n","Test accuracy: 0.6015999913215637\n"," 48% 15/31 [03:28\u003c04:54, 18.42s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.6752 - accuracy: 0.4189 - val_loss: 1.3146 - val_accuracy: 0.5410\n","Epoch 2/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.3464 - accuracy: 0.5346 - val_loss: 1.2196 - val_accuracy: 0.5694\n","Epoch 3/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.2576 - accuracy: 0.5693 - val_loss: 1.1624 - val_accuracy: 0.6038\n","Epoch 4/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.1966 - accuracy: 0.5888 - val_loss: 1.0845 - val_accuracy: 0.6285\n","Test loss: 1.0844591856002808\n","Test accuracy: 0.6284999847412109\n"," 52% 16/31 [03:52\u003c05:00, 20.03s/it]Epoch 1/4\n","391/391 [==============================] - 3s 7ms/step - loss: 2.1453 - accuracy: 0.2171 - val_loss: 1.9922 - val_accuracy: 0.3219\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.9850 - accuracy: 0.2910 - val_loss: 1.8973 - val_accuracy: 0.3535\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.9177 - accuracy: 0.3217 - val_loss: 1.8447 - val_accuracy: 0.3745\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.8769 - accuracy: 0.3394 - val_loss: 1.8073 - val_accuracy: 0.3916\n","Test loss: 1.8073372840881348\n","Test accuracy: 0.39160001277923584\n"," 55% 17/31 [04:06\u003c04:14, 18.17s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.7230 - accuracy: 0.3741 - val_loss: 1.3818 - val_accuracy: 0.5138\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4409 - accuracy: 0.4878 - val_loss: 1.3567 - val_accuracy: 0.5195\n","Epoch 3/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.3433 - accuracy: 0.5246 - val_loss: 1.2841 - val_accuracy: 0.5449\n","Test loss: 1.2841432094573975\n","Test accuracy: 0.5449000000953674\n"," 58% 18/31 [04:29\u003c04:16, 19.75s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.6074 - accuracy: 0.4242 - val_loss: 1.2961 - val_accuracy: 0.5403\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2957 - accuracy: 0.5457 - val_loss: 1.2037 - val_accuracy: 0.5754\n","Epoch 3/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.2050 - accuracy: 0.5806 - val_loss: 1.0784 - val_accuracy: 0.6293\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1425 - accuracy: 0.5998 - val_loss: 1.1726 - val_accuracy: 0.5826\n","Test loss: 1.1725767850875854\n","Test accuracy: 0.5825999975204468\n"," 61% 19/31 [04:47\u003c03:51, 19.29s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.6497 - accuracy: 0.4116 - val_loss: 1.3092 - val_accuracy: 0.5438\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3226 - accuracy: 0.5361 - val_loss: 1.1247 - val_accuracy: 0.6149\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2161 - accuracy: 0.5768 - val_loss: 1.0987 - val_accuracy: 0.6174\n","Epoch 4/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.1696 - accuracy: 0.5944 - val_loss: 1.0846 - val_accuracy: 0.6231\n","Test loss: 1.0846303701400757\n","Test accuracy: 0.6230999827384949\n"," 65% 20/31 [05:04\u003c03:23, 18.46s/it]Epoch 1/4\n","391/391 [==============================] - 4s 10ms/step - loss: 2.1427 - accuracy: 0.2143 - val_loss: 1.9609 - val_accuracy: 0.3118\n","Epoch 2/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.9116 - accuracy: 0.3153 - val_loss: 1.7799 - val_accuracy: 0.3865\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.7955 - accuracy: 0.3595 - val_loss: 1.6869 - val_accuracy: 0.4099\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.7298 - accuracy: 0.3844 - val_loss: 1.6305 - val_accuracy: 0.4199\n","Test loss: 1.630543828010559\n","Test accuracy: 0.41990000009536743\n"," 68% 21/31 [05:20\u003c02:59, 17.91s/it]Epoch 1/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.6686 - accuracy: 0.4127 - val_loss: 1.4131 - val_accuracy: 0.5068\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4358 - accuracy: 0.4987 - val_loss: 1.3107 - val_accuracy: 0.5475\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3295 - accuracy: 0.5373 - val_loss: 1.2393 - val_accuracy: 0.5659\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2657 - accuracy: 0.5600 - val_loss: 1.1865 - val_accuracy: 0.5882\n","Test loss: 1.1864603757858276\n","Test accuracy: 0.5881999731063843\n"," 71% 22/31 [05:35\u003c02:31, 16.86s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.6293 - accuracy: 0.4195 - val_loss: 1.2980 - val_accuracy: 0.5508\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3268 - accuracy: 0.5391 - val_loss: 1.1873 - val_accuracy: 0.5880\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2297 - accuracy: 0.5763 - val_loss: 1.1117 - val_accuracy: 0.6209\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1798 - accuracy: 0.5959 - val_loss: 1.0847 - val_accuracy: 0.6274\n","Test loss: 1.084657073020935\n","Test accuracy: 0.6273999810218811\n"," 74% 23/31 [05:58\u003c02:30, 18.84s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.6853 - accuracy: 0.3983 - val_loss: 1.3695 - val_accuracy: 0.5175\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4013 - accuracy: 0.5063 - val_loss: 1.2229 - val_accuracy: 0.5723\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2897 - accuracy: 0.5496 - val_loss: 1.1503 - val_accuracy: 0.6005\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2294 - accuracy: 0.5707 - val_loss: 1.1124 - val_accuracy: 0.6173\n","Test loss: 1.1124155521392822\n","Test accuracy: 0.6172999739646912\n"," 77% 24/31 [06:22\u003c02:22, 20.31s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.7385 - accuracy: 0.3768 - val_loss: 1.4220 - val_accuracy: 0.4992\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4117 - accuracy: 0.5023 - val_loss: 1.2057 - val_accuracy: 0.5809\n","Epoch 3/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.3060 - accuracy: 0.5440 - val_loss: 1.1150 - val_accuracy: 0.6196\n","Epoch 4/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.2518 - accuracy: 0.5644 - val_loss: 1.0689 - val_accuracy: 0.6293\n","Test loss: 1.0689477920532227\n","Test accuracy: 0.6292999982833862\n"," 81% 25/31 [06:45\u003c02:07, 21.21s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.6060 - accuracy: 0.4291 - val_loss: 1.2982 - val_accuracy: 0.5400\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2971 - accuracy: 0.5475 - val_loss: 1.1244 - val_accuracy: 0.6113\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1866 - accuracy: 0.5859 - val_loss: 1.0566 - val_accuracy: 0.6382\n","Epoch 4/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.1467 - accuracy: 0.6027 - val_loss: 1.1131 - val_accuracy: 0.6033\n","Test loss: 1.1130892038345337\n","Test accuracy: 0.6032999753952026\n"," 84% 26/31 [07:09\u003c01:49, 21.95s/it]Epoch 1/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.6203 - accuracy: 0.4247 - val_loss: 1.3148 - val_accuracy: 0.5436\n","Epoch 2/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.3285 - accuracy: 0.5355 - val_loss: 1.2071 - val_accuracy: 0.5746\n","Epoch 3/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.2314 - accuracy: 0.5757 - val_loss: 1.1233 - val_accuracy: 0.6101\n","Epoch 4/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.1941 - accuracy: 0.5875 - val_loss: 1.1449 - val_accuracy: 0.5995\n","Test loss: 1.144853949546814\n","Test accuracy: 0.5995000004768372\n"," 87% 27/31 [07:23\u003c01:17, 19.43s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.6914 - accuracy: 0.3980 - val_loss: 1.3339 - val_accuracy: 0.5408\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.3798 - accuracy: 0.5142 - val_loss: 1.1911 - val_accuracy: 0.5894\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.2801 - accuracy: 0.5564 - val_loss: 1.1306 - val_accuracy: 0.6127\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2322 - accuracy: 0.5723 - val_loss: 1.0663 - val_accuracy: 0.6336\n","Test loss: 1.0662671327590942\n","Test accuracy: 0.6335999965667725\n"," 90% 28/31 [07:46\u003c01:02, 20.72s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 2.3104 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 2.3027 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Test loss: 2.302574634552002\n","Test accuracy: 0.10000000149011612\n"," 94% 29/31 [08:00\u003c00:37, 18.53s/it]Epoch 1/4\n","391/391 [==============================] - 5s 10ms/step - loss: 1.6754 - accuracy: 0.4091 - val_loss: 1.3735 - val_accuracy: 0.5309\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.3547 - accuracy: 0.5275 - val_loss: 1.3680 - val_accuracy: 0.5085\n","Epoch 3/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.2547 - accuracy: 0.5635 - val_loss: 1.1492 - val_accuracy: 0.6012\n","Epoch 4/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.1986 - accuracy: 0.5831 - val_loss: 1.0725 - val_accuracy: 0.6317\n","Test loss: 1.0724592208862305\n","Test accuracy: 0.6316999793052673\n"," 97% 30/31 [08:24\u003c00:20, 20.14s/it]Epoch 1/4\n","391/391 [==============================] - 5s 10ms/step - loss: 1.5921 - accuracy: 0.4393 - val_loss: 1.2435 - val_accuracy: 0.5654\n","Epoch 2/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.2845 - accuracy: 0.5569 - val_loss: 1.1448 - val_accuracy: 0.6054\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1993 - accuracy: 0.5883 - val_loss: 1.0880 - val_accuracy: 0.6306\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1425 - accuracy: 0.6089 - val_loss: 1.0967 - val_accuracy: 0.6173\n","Test loss: 1.0966581106185913\n","Test accuracy: 0.6172999739646912\n","100% 31/31 [08:48\u003c00:00, 17.04s/it]\n","  0% 0/32 [00:00\u003c?, ?it/s]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.7097 - accuracy: 0.3868 - val_loss: 1.3736 - val_accuracy: 0.5278\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4102 - accuracy: 0.5017 - val_loss: 1.1862 - val_accuracy: 0.5872\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3164 - accuracy: 0.5411 - val_loss: 1.1447 - val_accuracy: 0.6051\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2553 - accuracy: 0.5627 - val_loss: 1.1299 - val_accuracy: 0.5983\n","Test loss: 1.1299110651016235\n","Test accuracy: 0.5982999801635742\n"," 16% 5/32 [00:16\u003c01:27,  3.25s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.8342 - accuracy: 0.3399 - val_loss: 1.4344 - val_accuracy: 0.5051\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.5507 - accuracy: 0.4533 - val_loss: 1.3234 - val_accuracy: 0.5351\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.4410 - accuracy: 0.4950 - val_loss: 1.4098 - val_accuracy: 0.5205\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.3764 - accuracy: 0.5243 - val_loss: 1.1885 - val_accuracy: 0.5849\n","Test loss: 1.1884939670562744\n","Test accuracy: 0.5849000215530396\n"," 19% 6/32 [00:40\u003c03:25,  7.90s/it]Epoch 1/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.6712 - accuracy: 0.4042 - val_loss: 1.4409 - val_accuracy: 0.4672\n","Epoch 2/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.3651 - accuracy: 0.5185 - val_loss: 1.2659 - val_accuracy: 0.5442\n","Epoch 3/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.2631 - accuracy: 0.5578 - val_loss: 1.1995 - val_accuracy: 0.5711\n","Epoch 4/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.2072 - accuracy: 0.5803 - val_loss: 1.1326 - val_accuracy: 0.5974\n","Test loss: 1.1326425075531006\n","Test accuracy: 0.5974000096321106\n"," 22% 7/32 [00:52\u003c03:39,  8.80s/it]Epoch 1/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.6332 - accuracy: 0.4188 - val_loss: 1.3525 - val_accuracy: 0.5353\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3218 - accuracy: 0.5400 - val_loss: 1.1643 - val_accuracy: 0.5977\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2322 - accuracy: 0.5745 - val_loss: 1.2088 - val_accuracy: 0.5794\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.1770 - accuracy: 0.5944 - val_loss: 1.0991 - val_accuracy: 0.6212\n","Test loss: 1.0991368293762207\n","Test accuracy: 0.6212000250816345\n"," 25% 8/32 [01:15\u003c05:02, 12.60s/it]Epoch 1/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.7417 - accuracy: 0.3727 - val_loss: 1.4269 - val_accuracy: 0.4928\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.4411 - accuracy: 0.4902 - val_loss: 1.2380 - val_accuracy: 0.5701\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.3373 - accuracy: 0.5332 - val_loss: 1.1585 - val_accuracy: 0.5985\n","Epoch 4/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.2646 - accuracy: 0.5605 - val_loss: 1.1154 - val_accuracy: 0.6139\n","Test loss: 1.1154394149780273\n","Test accuracy: 0.6139000058174133\n"," 28% 9/32 [01:39\u003c05:58, 15.59s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.7715 - accuracy: 0.3665 - val_loss: 1.5276 - val_accuracy: 0.4489\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4873 - accuracy: 0.4733 - val_loss: 1.3721 - val_accuracy: 0.5132\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3741 - accuracy: 0.5178 - val_loss: 1.2823 - val_accuracy: 0.5479\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2959 - accuracy: 0.5456 - val_loss: 1.1829 - val_accuracy: 0.5903\n","Test loss: 1.182906985282898\n","Test accuracy: 0.5903000235557556\n"," 31% 10/32 [02:02\u003c06:29, 17.71s/it]Epoch 1/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.6854 - accuracy: 0.4030 - val_loss: 1.3923 - val_accuracy: 0.5169\n","Epoch 2/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.3739 - accuracy: 0.5184 - val_loss: 1.2751 - val_accuracy: 0.5401\n","Epoch 3/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.2691 - accuracy: 0.5580 - val_loss: 1.2080 - val_accuracy: 0.5637\n","Epoch 4/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.2049 - accuracy: 0.5806 - val_loss: 1.1881 - val_accuracy: 0.5787\n","Test loss: 1.188139796257019\n","Test accuracy: 0.5787000060081482\n"," 34% 11/32 [02:14\u003c05:38, 16.14s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.7344 - accuracy: 0.3779 - val_loss: 1.4747 - val_accuracy: 0.4807\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4682 - accuracy: 0.4802 - val_loss: 1.3160 - val_accuracy: 0.5256\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3486 - accuracy: 0.5258 - val_loss: 1.2059 - val_accuracy: 0.5877\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2737 - accuracy: 0.5552 - val_loss: 1.1113 - val_accuracy: 0.6206\n","Test loss: 1.1112873554229736\n","Test accuracy: 0.6205999851226807\n"," 38% 12/32 [02:30\u003c05:19, 15.95s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.5732 - accuracy: 0.4420 - val_loss: 1.2269 - val_accuracy: 0.5680\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2682 - accuracy: 0.5583 - val_loss: 1.0910 - val_accuracy: 0.6216\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1777 - accuracy: 0.5910 - val_loss: 1.1402 - val_accuracy: 0.5962\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1275 - accuracy: 0.6126 - val_loss: 1.0145 - val_accuracy: 0.6456\n","Test loss: 1.0145319700241089\n","Test accuracy: 0.6456000208854675\n"," 41% 13/32 [02:49\u003c05:23, 17.01s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.5521 - accuracy: 0.4507 - val_loss: 1.3550 - val_accuracy: 0.5194\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2277 - accuracy: 0.5728 - val_loss: 1.1302 - val_accuracy: 0.5971\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1260 - accuracy: 0.6102 - val_loss: 1.0550 - val_accuracy: 0.6343\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.0799 - accuracy: 0.6271 - val_loss: 0.9979 - val_accuracy: 0.6561\n","Test loss: 0.9978600740432739\n","Test accuracy: 0.6560999751091003\n"," 44% 14/32 [03:13\u003c05:39, 18.88s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.7363 - accuracy: 0.3871 - val_loss: 1.4455 - val_accuracy: 0.4916\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4251 - accuracy: 0.5034 - val_loss: 1.3147 - val_accuracy: 0.5346\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3227 - accuracy: 0.5430 - val_loss: 1.1673 - val_accuracy: 0.6008\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2775 - accuracy: 0.5593 - val_loss: 1.2550 - val_accuracy: 0.5549\n","Test loss: 1.2549549341201782\n","Test accuracy: 0.5548999905586243\n"," 47% 15/32 [03:27\u003c04:56, 17.43s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.7442 - accuracy: 0.3579 - val_loss: 1.4493 - val_accuracy: 0.4835\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4604 - accuracy: 0.4775 - val_loss: 1.2712 - val_accuracy: 0.5530\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3797 - accuracy: 0.5135 - val_loss: 1.2089 - val_accuracy: 0.5787\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3204 - accuracy: 0.5394 - val_loss: 1.2045 - val_accuracy: 0.5805\n","Test loss: 1.204511284828186\n","Test accuracy: 0.5805000066757202\n"," 50% 16/32 [03:51\u003c05:09, 19.32s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.6023 - accuracy: 0.4328 - val_loss: 1.3053 - val_accuracy: 0.5386\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2942 - accuracy: 0.5479 - val_loss: 1.1629 - val_accuracy: 0.5934\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1886 - accuracy: 0.5858 - val_loss: 1.1902 - val_accuracy: 0.5765\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1387 - accuracy: 0.6057 - val_loss: 1.0265 - val_accuracy: 0.6408\n","Test loss: 1.0264908075332642\n","Test accuracy: 0.6407999992370605\n"," 53% 17/32 [04:06\u003c04:33, 18.22s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.7284 - accuracy: 0.3805 - val_loss: 1.4228 - val_accuracy: 0.4891\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4101 - accuracy: 0.5076 - val_loss: 1.1726 - val_accuracy: 0.6032\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3140 - accuracy: 0.5450 - val_loss: 1.1383 - val_accuracy: 0.6201\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2613 - accuracy: 0.5631 - val_loss: 1.0888 - val_accuracy: 0.6280\n","Test loss: 1.0887526273727417\n","Test accuracy: 0.628000020980835\n"," 56% 18/32 [04:21\u003c04:00, 17.17s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.7068 - accuracy: 0.3870 - val_loss: 1.3628 - val_accuracy: 0.5262\n","Epoch 2/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.4144 - accuracy: 0.5020 - val_loss: 1.2255 - val_accuracy: 0.5726\n","Epoch 3/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.3068 - accuracy: 0.5439 - val_loss: 1.1501 - val_accuracy: 0.5914\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2501 - accuracy: 0.5644 - val_loss: 1.0709 - val_accuracy: 0.6356\n","Test loss: 1.0708874464035034\n","Test accuracy: 0.6355999708175659\n"," 59% 19/32 [04:45\u003c04:09, 19.16s/it]Epoch 1/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.8586 - accuracy: 0.3255 - val_loss: 1.4984 - val_accuracy: 0.4871\n","Epoch 2/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.5764 - accuracy: 0.4257 - val_loss: 1.3350 - val_accuracy: 0.5508\n","Epoch 3/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.4884 - accuracy: 0.4611 - val_loss: 1.2510 - val_accuracy: 0.5683\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4346 - accuracy: 0.4810 - val_loss: 1.2358 - val_accuracy: 0.5749\n","Test loss: 1.2357549667358398\n","Test accuracy: 0.5748999714851379\n"," 62% 20/32 [04:58\u003c03:29, 17.49s/it]Epoch 1/4\n","391/391 [==============================] - 5s 10ms/step - loss: 1.6164 - accuracy: 0.4272 - val_loss: 1.2493 - val_accuracy: 0.5718\n","Epoch 2/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.2836 - accuracy: 0.5574 - val_loss: 1.2702 - val_accuracy: 0.5493\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1900 - accuracy: 0.5911 - val_loss: 1.0677 - val_accuracy: 0.6418\n","Epoch 4/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.1306 - accuracy: 0.6147 - val_loss: 1.0460 - val_accuracy: 0.6435\n","Test loss: 1.046019196510315\n","Test accuracy: 0.6434999704360962\n"," 66% 21/32 [05:22\u003c03:31, 19.25s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.8557 - accuracy: 0.3299 - val_loss: 1.4755 - val_accuracy: 0.4802\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.5362 - accuracy: 0.4495 - val_loss: 1.2867 - val_accuracy: 0.5520\n","Epoch 3/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.4450 - accuracy: 0.4813 - val_loss: 1.1881 - val_accuracy: 0.5942\n","Epoch 4/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.3871 - accuracy: 0.5069 - val_loss: 1.1532 - val_accuracy: 0.6001\n","Test loss: 1.1532492637634277\n","Test accuracy: 0.6000999808311462\n"," 69% 22/32 [05:46\u003c03:26, 20.62s/it]Epoch 1/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.6878 - accuracy: 0.4001 - val_loss: 1.4048 - val_accuracy: 0.5015\n","Epoch 2/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.3980 - accuracy: 0.5077 - val_loss: 1.3524 - val_accuracy: 0.5156\n","Epoch 3/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.2889 - accuracy: 0.5489 - val_loss: 1.1786 - val_accuracy: 0.5897\n","Epoch 4/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.2244 - accuracy: 0.5725 - val_loss: 1.1810 - val_accuracy: 0.5810\n","Test loss: 1.1810108423233032\n","Test accuracy: 0.5809999704360962\n"," 72% 23/32 [05:59\u003c02:46, 18.49s/it]Epoch 1/4\n","391/391 [==============================] - 5s 10ms/step - loss: 1.5680 - accuracy: 0.4494 - val_loss: 1.2437 - val_accuracy: 0.5683\n","Epoch 2/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.2312 - accuracy: 0.5754 - val_loss: 1.1210 - val_accuracy: 0.6186\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1470 - accuracy: 0.6067 - val_loss: 1.0819 - val_accuracy: 0.6291\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.0950 - accuracy: 0.6261 - val_loss: 1.1491 - val_accuracy: 0.5967\n","Test loss: 1.1490918397903442\n","Test accuracy: 0.5967000126838684\n"," 75% 24/32 [06:17\u003c02:26, 18.30s/it]Epoch 1/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.6736 - accuracy: 0.4087 - val_loss: 1.3678 - val_accuracy: 0.5162\n","Epoch 2/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.3611 - accuracy: 0.5268 - val_loss: 1.1576 - val_accuracy: 0.6055\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2704 - accuracy: 0.5630 - val_loss: 1.1148 - val_accuracy: 0.6187\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2233 - accuracy: 0.5807 - val_loss: 1.0915 - val_accuracy: 0.6234\n","Test loss: 1.091535210609436\n","Test accuracy: 0.6233999729156494\n"," 78% 25/32 [06:40\u003c02:18, 19.80s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 2.3652 - accuracy: 0.1059 - val_loss: 2.3037 - val_accuracy: 0.1439\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 2.3289 - accuracy: 0.1143 - val_loss: 2.2859 - val_accuracy: 0.1577\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 2.3094 - accuracy: 0.1233 - val_loss: 2.2705 - val_accuracy: 0.1672\n","Test loss: 2.2704601287841797\n","Test accuracy: 0.1671999990940094\n"," 81% 26/32 [07:03\u003c02:04, 20.81s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.7793 - accuracy: 0.3785 - val_loss: 1.3288 - val_accuracy: 0.5453\n","Epoch 2/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.4212 - accuracy: 0.5058 - val_loss: 1.1908 - val_accuracy: 0.5874\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.3258 - accuracy: 0.5439 - val_loss: 1.1842 - val_accuracy: 0.5930\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2715 - accuracy: 0.5625 - val_loss: 1.1230 - val_accuracy: 0.6145\n","Test loss: 1.1230430603027344\n","Test accuracy: 0.6144999861717224\n"," 84% 27/32 [07:27\u003c01:48, 21.71s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.7403 - accuracy: 0.3637 - val_loss: 1.4630 - val_accuracy: 0.4578\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4560 - accuracy: 0.4789 - val_loss: 1.4442 - val_accuracy: 0.4915\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3641 - accuracy: 0.5197 - val_loss: 1.1760 - val_accuracy: 0.5931\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3183 - accuracy: 0.5372 - val_loss: 1.1845 - val_accuracy: 0.6006\n","Test loss: 1.1844695806503296\n","Test accuracy: 0.600600004196167\n"," 88% 28/32 [07:42\u003c01:19, 19.77s/it]Epoch 1/4\n","391/391 [==============================] - 6s 14ms/step - loss: 2.3573 - accuracy: 0.0991 - val_loss: 2.3028 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 5s 13ms/step - loss: 2.3107 - accuracy: 0.0977 - val_loss: 2.3030 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 5s 14ms/step - loss: 2.3042 - accuracy: 0.0989 - val_loss: 2.3027 - val_accuracy: 0.1000\n","Test loss: 2.3026928901672363\n","Test accuracy: 0.10000000149011612\n"," 91% 29/32 [08:02\u003c00:59, 19.67s/it]Epoch 1/4\n","391/391 [==============================] - 5s 12ms/step - loss: 2.3453 - accuracy: 0.0994 - val_loss: 2.3028 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.3036 - accuracy: 0.1019 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.3032 - accuracy: 0.0994 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Test loss: 2.3025975227355957\n","Test accuracy: 0.10000000149011612\n"," 94% 30/32 [08:19\u003c00:37, 18.80s/it]Epoch 1/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.6259 - accuracy: 0.4193 - val_loss: 1.4304 - val_accuracy: 0.4806\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3187 - accuracy: 0.5372 - val_loss: 1.2027 - val_accuracy: 0.5740\n","Epoch 3/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.2256 - accuracy: 0.5731 - val_loss: 1.1513 - val_accuracy: 0.5940\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.1657 - accuracy: 0.5942 - val_loss: 1.1010 - val_accuracy: 0.6192\n","Test loss: 1.100967526435852\n","Test accuracy: 0.6191999912261963\n"," 97% 31/32 [08:42\u003c00:20, 20.14s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.5623 - accuracy: 0.4476 - val_loss: 1.2104 - val_accuracy: 0.5781\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2579 - accuracy: 0.5606 - val_loss: 1.0930 - val_accuracy: 0.6187\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1656 - accuracy: 0.5945 - val_loss: 1.0229 - val_accuracy: 0.6470\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1058 - accuracy: 0.6154 - val_loss: 1.0227 - val_accuracy: 0.6504\n","Test loss: 1.0227230787277222\n","Test accuracy: 0.6503999829292297\n","100% 32/32 [09:06\u003c00:00, 17.06s/it]\n","  0% 0/33 [00:00\u003c?, ?it/s]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.6329 - accuracy: 0.4255 - val_loss: 1.2724 - val_accuracy: 0.5588\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3017 - accuracy: 0.5474 - val_loss: 1.2760 - val_accuracy: 0.5444\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2126 - accuracy: 0.5789 - val_loss: 1.1762 - val_accuracy: 0.5813\n","Test loss: 1.1762248277664185\n","Test accuracy: 0.5813000202178955\n"," 15% 5/33 [00:13\u003c01:15,  2.70s/it]Epoch 1/4\n","391/391 [==============================] - 6s 14ms/step - loss: 2.3459 - accuracy: 0.1012 - val_loss: 2.3030 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 5s 13ms/step - loss: 2.3071 - accuracy: 0.1014 - val_loss: 2.3029 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 5s 13ms/step - loss: 2.3046 - accuracy: 0.0984 - val_loss: 2.3028 - val_accuracy: 0.1000\n","Test loss: 2.3027703762054443\n","Test accuracy: 0.10000000149011612\n"," 18% 6/33 [00:37\u003c03:19,  7.40s/it]Epoch 1/4\n","391/391 [==============================] - 6s 12ms/step - loss: 2.3544 - accuracy: 0.0983 - val_loss: 2.3028 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.3046 - accuracy: 0.1003 - val_loss: 2.3027 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 5s 12ms/step - loss: 2.3031 - accuracy: 0.1010 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Test loss: 2.302625894546509\n","Test accuracy: 0.10000000149011612\n"," 21% 7/33 [00:54\u003c04:12,  9.71s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.5935 - accuracy: 0.4337 - val_loss: 1.3124 - val_accuracy: 0.5289\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2959 - accuracy: 0.5476 - val_loss: 1.1291 - val_accuracy: 0.6122\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2012 - accuracy: 0.5858 - val_loss: 1.1413 - val_accuracy: 0.5989\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1550 - accuracy: 0.5986 - val_loss: 1.0537 - val_accuracy: 0.6362\n","Test loss: 1.053673505783081\n","Test accuracy: 0.6362000107765198\n"," 24% 8/33 [01:09\u003c04:37, 11.11s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.6447 - accuracy: 0.4268 - val_loss: 1.4231 - val_accuracy: 0.5011\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3878 - accuracy: 0.5168 - val_loss: 1.2805 - val_accuracy: 0.5541\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2779 - accuracy: 0.5524 - val_loss: 1.2071 - val_accuracy: 0.5727\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2140 - accuracy: 0.5770 - val_loss: 1.1592 - val_accuracy: 0.5912\n","Test loss: 1.159199595451355\n","Test accuracy: 0.5911999940872192\n"," 27% 9/33 [01:33\u003c05:47, 14.48s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.5993 - accuracy: 0.4318 - val_loss: 1.2457 - val_accuracy: 0.5655\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2720 - accuracy: 0.5548 - val_loss: 1.0923 - val_accuracy: 0.6215\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1831 - accuracy: 0.5890 - val_loss: 1.0919 - val_accuracy: 0.6186\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1231 - accuracy: 0.6090 - val_loss: 1.0293 - val_accuracy: 0.6407\n","Test loss: 1.0292587280273438\n","Test accuracy: 0.6406999826431274\n"," 30% 10/33 [01:56\u003c06:28, 16.90s/it]Epoch 1/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.7104 - accuracy: 0.4022 - val_loss: 1.4165 - val_accuracy: 0.5036\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4473 - accuracy: 0.4949 - val_loss: 1.3839 - val_accuracy: 0.5172\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3471 - accuracy: 0.5336 - val_loss: 1.2416 - val_accuracy: 0.5707\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2876 - accuracy: 0.5523 - val_loss: 1.2020 - val_accuracy: 0.5818\n","Test loss: 1.20204496383667\n","Test accuracy: 0.5817999839782715\n"," 33% 11/33 [02:10\u003c05:51, 15.99s/it]Epoch 1/4\n","391/391 [==============================] - 6s 14ms/step - loss: 2.3888 - accuracy: 0.0993 - val_loss: 2.3031 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 5s 13ms/step - loss: 2.3165 - accuracy: 0.1003 - val_loss: 2.3030 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 5s 13ms/step - loss: 2.3055 - accuracy: 0.1005 - val_loss: 2.3029 - val_accuracy: 0.1000\n","Test loss: 2.3028764724731445\n","Test accuracy: 0.10000000149011612\n"," 36% 12/33 [02:28\u003c05:51, 16.71s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.8410 - accuracy: 0.3380 - val_loss: 1.4785 - val_accuracy: 0.5002\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.5653 - accuracy: 0.4398 - val_loss: 1.3358 - val_accuracy: 0.5554\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.4706 - accuracy: 0.4778 - val_loss: 1.2542 - val_accuracy: 0.5780\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.4178 - accuracy: 0.4995 - val_loss: 1.1952 - val_accuracy: 0.5987\n","Test loss: 1.1951507329940796\n","Test accuracy: 0.5986999869346619\n"," 39% 13/33 [02:48\u003c05:52, 17.61s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 2.3246 - accuracy: 0.1084 - val_loss: 2.2928 - val_accuracy: 0.0972\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.3004 - accuracy: 0.1241 - val_loss: 2.2751 - val_accuracy: 0.1444\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 2.2819 - accuracy: 0.1371 - val_loss: 2.2589 - val_accuracy: 0.1750\n","Test loss: 2.258894920349121\n","Test accuracy: 0.17499999701976776\n"," 42% 14/33 [03:03\u003c05:22, 16.99s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.7201 - accuracy: 0.3851 - val_loss: 1.4075 - val_accuracy: 0.5065\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4361 - accuracy: 0.4938 - val_loss: 1.2973 - val_accuracy: 0.5387\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3331 - accuracy: 0.5299 - val_loss: 1.2893 - val_accuracy: 0.5431\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2806 - accuracy: 0.5501 - val_loss: 1.1980 - val_accuracy: 0.5808\n","Test loss: 1.1980258226394653\n","Test accuracy: 0.5807999968528748\n"," 45% 15/33 [03:27\u003c05:42, 19.05s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.7822 - accuracy: 0.3548 - val_loss: 1.4114 - val_accuracy: 0.5304\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.5189 - accuracy: 0.4581 - val_loss: 1.2612 - val_accuracy: 0.5725\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.4307 - accuracy: 0.4925 - val_loss: 1.1966 - val_accuracy: 0.5957\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.3796 - accuracy: 0.5145 - val_loss: 1.1470 - val_accuracy: 0.6122\n","Test loss: 1.14701247215271\n","Test accuracy: 0.6122000217437744\n"," 48% 16/33 [03:46\u003c05:23, 19.02s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.5754 - accuracy: 0.4389 - val_loss: 1.2088 - val_accuracy: 0.5786\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2545 - accuracy: 0.5666 - val_loss: 1.1442 - val_accuracy: 0.6097\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1704 - accuracy: 0.5953 - val_loss: 1.0624 - val_accuracy: 0.6293\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1131 - accuracy: 0.6156 - val_loss: 1.0061 - val_accuracy: 0.6585\n","Test loss: 1.0060676336288452\n","Test accuracy: 0.6585000157356262\n"," 52% 17/33 [04:10\u003c05:26, 20.43s/it]Epoch 1/4\n","391/391 [==============================] - 6s 15ms/step - loss: 1.5907 - accuracy: 0.4373 - val_loss: 1.2438 - val_accuracy: 0.5716\n","Epoch 2/4\n","391/391 [==============================] - 5s 14ms/step - loss: 1.2711 - accuracy: 0.5575 - val_loss: 1.1510 - val_accuracy: 0.5943\n","Epoch 3/4\n","391/391 [==============================] - 6s 14ms/step - loss: 1.1862 - accuracy: 0.5889 - val_loss: 1.0795 - val_accuracy: 0.6305\n","Epoch 4/4\n","391/391 [==============================] - 5s 14ms/step - loss: 1.1208 - accuracy: 0.6124 - val_loss: 0.9975 - val_accuracy: 0.6588\n","Test loss: 0.997495710849762\n","Test accuracy: 0.6588000059127808\n"," 55% 18/33 [04:54\u003c06:51, 27.45s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.5303 - accuracy: 0.4588 - val_loss: 1.2456 - val_accuracy: 0.5684\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2089 - accuracy: 0.5787 - val_loss: 1.0938 - val_accuracy: 0.6151\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1154 - accuracy: 0.6113 - val_loss: 1.0208 - val_accuracy: 0.6449\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.0575 - accuracy: 0.6331 - val_loss: 1.0518 - val_accuracy: 0.6349\n","Test loss: 1.0518091917037964\n","Test accuracy: 0.6348999738693237\n"," 58% 19/33 [05:13\u003c05:50, 25.06s/it]Epoch 1/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.7850 - accuracy: 0.3592 - val_loss: 1.4771 - val_accuracy: 0.4814\n","Epoch 2/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.4844 - accuracy: 0.4833 - val_loss: 1.3509 - val_accuracy: 0.5231\n","Epoch 3/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.3730 - accuracy: 0.5239 - val_loss: 1.2203 - val_accuracy: 0.5718\n","Epoch 4/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.3076 - accuracy: 0.5470 - val_loss: 1.1778 - val_accuracy: 0.5953\n","Test loss: 1.1777594089508057\n","Test accuracy: 0.595300018787384\n"," 61% 20/33 [05:26\u003c04:38, 21.45s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.5892 - accuracy: 0.4364 - val_loss: 1.2473 - val_accuracy: 0.5669\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2696 - accuracy: 0.5565 - val_loss: 1.1202 - val_accuracy: 0.6187\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1745 - accuracy: 0.5939 - val_loss: 1.0693 - val_accuracy: 0.6314\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1085 - accuracy: 0.6157 - val_loss: 0.9952 - val_accuracy: 0.6548\n","Test loss: 0.9952397346496582\n","Test accuracy: 0.6547999978065491\n"," 64% 21/33 [05:45\u003c04:08, 20.70s/it]Epoch 1/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.7542 - accuracy: 0.3559 - val_loss: 1.3891 - val_accuracy: 0.4962\n","Epoch 2/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.4265 - accuracy: 0.4877 - val_loss: 1.2343 - val_accuracy: 0.5641\n","Epoch 3/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.2916 - accuracy: 0.5386 - val_loss: 1.1011 - val_accuracy: 0.6122\n","Epoch 4/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.2026 - accuracy: 0.5709 - val_loss: 1.0627 - val_accuracy: 0.6313\n","Test loss: 1.0626775026321411\n","Test accuracy: 0.6312999725341797\n"," 67% 22/33 [06:03\u003c03:38, 19.89s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 2.2257 - accuracy: 0.1724 - val_loss: 2.1151 - val_accuracy: 0.2494\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.0719 - accuracy: 0.2443 - val_loss: 2.0006 - val_accuracy: 0.2985\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.9908 - accuracy: 0.2812 - val_loss: 1.9346 - val_accuracy: 0.3240\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.9401 - accuracy: 0.3075 - val_loss: 1.8903 - val_accuracy: 0.3425\n","Test loss: 1.8902838230133057\n","Test accuracy: 0.3425000011920929\n"," 70% 23/33 [06:23\u003c03:18, 19.81s/it]Epoch 1/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.6416 - accuracy: 0.4194 - val_loss: 1.4202 - val_accuracy: 0.4884\n","Epoch 2/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.3427 - accuracy: 0.5323 - val_loss: 1.2324 - val_accuracy: 0.5693\n","Epoch 3/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.2481 - accuracy: 0.5658 - val_loss: 1.1778 - val_accuracy: 0.5932\n","Epoch 4/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.1992 - accuracy: 0.5858 - val_loss: 1.1272 - val_accuracy: 0.6118\n","Test loss: 1.1271507740020752\n","Test accuracy: 0.6118000149726868\n"," 73% 24/33 [06:36\u003c02:40, 17.83s/it]Epoch 1/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.7752 - accuracy: 0.3637 - val_loss: 1.5094 - val_accuracy: 0.4712\n","Epoch 2/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.5119 - accuracy: 0.4648 - val_loss: 1.3349 - val_accuracy: 0.5307\n","Epoch 3/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.4181 - accuracy: 0.5024 - val_loss: 1.3214 - val_accuracy: 0.5405\n","Epoch 4/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.3649 - accuracy: 0.5249 - val_loss: 1.3295 - val_accuracy: 0.5265\n","Test loss: 1.3294754028320312\n","Test accuracy: 0.5264999866485596\n"," 76% 25/33 [06:48\u003c02:08, 16.11s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 2.3471 - accuracy: 0.1007 - val_loss: 2.2831 - val_accuracy: 0.1022\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 2.1516 - accuracy: 0.2022 - val_loss: 1.9329 - val_accuracy: 0.3185\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.9011 - accuracy: 0.3142 - val_loss: 1.7311 - val_accuracy: 0.3867\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.7800 - accuracy: 0.3645 - val_loss: 1.6233 - val_accuracy: 0.4297\n","Test loss: 1.6232929229736328\n","Test accuracy: 0.42969998717308044\n"," 79% 26/33 [07:08\u003c02:01, 17.31s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.8460 - accuracy: 0.3345 - val_loss: 1.5481 - val_accuracy: 0.4838\n","Epoch 2/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.5780 - accuracy: 0.4344 - val_loss: 1.3290 - val_accuracy: 0.5562\n","Epoch 3/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.4832 - accuracy: 0.4714 - val_loss: 1.2690 - val_accuracy: 0.5666\n","Epoch 4/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.4352 - accuracy: 0.4905 - val_loss: 1.2158 - val_accuracy: 0.5908\n","Test loss: 1.2158194780349731\n","Test accuracy: 0.5907999873161316\n"," 82% 27/33 [07:32\u003c01:54, 19.13s/it]Epoch 1/4\n","391/391 [==============================] - 6s 14ms/step - loss: 2.4336 - accuracy: 0.1001 - val_loss: 2.3031 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 5s 13ms/step - loss: 2.3539 - accuracy: 0.0991 - val_loss: 2.3027 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 5s 13ms/step - loss: 2.3287 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.1000\n","Test loss: 2.302673816680908\n","Test accuracy: 0.10000000149011612\n"," 85% 28/33 [07:51\u003c01:34, 19.00s/it]Epoch 1/4\n","391/391 [==============================] - 5s 10ms/step - loss: 1.7323 - accuracy: 0.3776 - val_loss: 1.3675 - val_accuracy: 0.5205\n","Epoch 2/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.4217 - accuracy: 0.4980 - val_loss: 1.2201 - val_accuracy: 0.5840\n","Epoch 3/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.3129 - accuracy: 0.5393 - val_loss: 1.1746 - val_accuracy: 0.6019\n","Epoch 4/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.2514 - accuracy: 0.5677 - val_loss: 1.1005 - val_accuracy: 0.6147\n","Test loss: 1.1004512310028076\n","Test accuracy: 0.6147000193595886\n"," 88% 29/33 [08:08\u003c01:14, 18.62s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.6282 - accuracy: 0.4200 - val_loss: 1.2893 - val_accuracy: 0.5377\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3031 - accuracy: 0.5453 - val_loss: 1.1203 - val_accuracy: 0.6194\n","Epoch 3/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.1946 - accuracy: 0.5854 - val_loss: 1.0766 - val_accuracy: 0.6237\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1503 - accuracy: 0.6001 - val_loss: 1.0193 - val_accuracy: 0.6495\n","Test loss: 1.019302487373352\n","Test accuracy: 0.6495000123977661\n"," 91% 30/33 [08:25\u003c00:54, 18.11s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.6014 - accuracy: 0.4384 - val_loss: 1.2873 - val_accuracy: 0.5402\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2663 - accuracy: 0.5601 - val_loss: 1.3569 - val_accuracy: 0.5204\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.1738 - accuracy: 0.5940 - val_loss: 1.1065 - val_accuracy: 0.6212\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.1242 - accuracy: 0.6126 - val_loss: 1.0936 - val_accuracy: 0.6193\n","Test loss: 1.0936017036437988\n","Test accuracy: 0.6193000078201294\n"," 94% 31/33 [08:40\u003c00:34, 17.09s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.7320 - accuracy: 0.3869 - val_loss: 1.4751 - val_accuracy: 0.4725\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.4266 - accuracy: 0.5039 - val_loss: 1.2692 - val_accuracy: 0.5715\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.2925 - accuracy: 0.5509 - val_loss: 1.2321 - val_accuracy: 0.5611\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2162 - accuracy: 0.5787 - val_loss: 1.1147 - val_accuracy: 0.6093\n","Test loss: 1.1147063970565796\n","Test accuracy: 0.6093000173568726\n"," 97% 32/33 [09:00\u003c00:17, 17.90s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.7118 - accuracy: 0.3943 - val_loss: 1.4877 - val_accuracy: 0.4754\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.4085 - accuracy: 0.5069 - val_loss: 1.2776 - val_accuracy: 0.5510\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2725 - accuracy: 0.5561 - val_loss: 1.2108 - val_accuracy: 0.5695\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1857 - accuracy: 0.5878 - val_loss: 1.1012 - val_accuracy: 0.6162\n","Test loss: 1.1011571884155273\n","Test accuracy: 0.6161999702453613\n","100% 33/33 [09:23\u003c00:00, 17.09s/it]\n","  0% 0/34 [00:00\u003c?, ?it/s]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.7223 - accuracy: 0.3862 - val_loss: 1.3668 - val_accuracy: 0.5281\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4092 - accuracy: 0.5078 - val_loss: 1.1770 - val_accuracy: 0.5980\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3039 - accuracy: 0.5470 - val_loss: 1.1566 - val_accuracy: 0.6064\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2617 - accuracy: 0.5633 - val_loss: 1.0828 - val_accuracy: 0.6325\n","Test loss: 1.0827531814575195\n","Test accuracy: 0.6324999928474426\n"," 15% 5/34 [00:23\u003c02:14,  4.64s/it]Epoch 1/4\n","391/391 [==============================] - 5s 10ms/step - loss: 1.7214 - accuracy: 0.3886 - val_loss: 1.3489 - val_accuracy: 0.5352\n","Epoch 2/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.4047 - accuracy: 0.5087 - val_loss: 1.1969 - val_accuracy: 0.5882\n","Epoch 3/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.3086 - accuracy: 0.5411 - val_loss: 1.1372 - val_accuracy: 0.6117\n","Epoch 4/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.2490 - accuracy: 0.5657 - val_loss: 1.0870 - val_accuracy: 0.6274\n","Test loss: 1.0870376825332642\n","Test accuracy: 0.6273999810218811\n"," 18% 6/34 [00:47\u003c04:10,  8.95s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.7907 - accuracy: 0.3493 - val_loss: 1.4170 - val_accuracy: 0.5139\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.5175 - accuracy: 0.4599 - val_loss: 1.2812 - val_accuracy: 0.5590\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.4308 - accuracy: 0.4927 - val_loss: 1.1984 - val_accuracy: 0.5932\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.3739 - accuracy: 0.5153 - val_loss: 1.1569 - val_accuracy: 0.6072\n","Test loss: 1.1568586826324463\n","Test accuracy: 0.607200026512146\n"," 21% 7/34 [01:06\u003c05:07, 11.38s/it]Epoch 1/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.7157 - accuracy: 0.3882 - val_loss: 1.4933 - val_accuracy: 0.4593\n","Epoch 2/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.4754 - accuracy: 0.4816 - val_loss: 1.4026 - val_accuracy: 0.4976\n","Epoch 3/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.3898 - accuracy: 0.5135 - val_loss: 1.3333 - val_accuracy: 0.5241\n","Epoch 4/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.3409 - accuracy: 0.5338 - val_loss: 1.2699 - val_accuracy: 0.5692\n","Test loss: 1.2699419260025024\n","Test accuracy: 0.5691999793052673\n"," 24% 8/34 [01:19\u003c05:07, 11.82s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.6003 - accuracy: 0.4328 - val_loss: 1.2860 - val_accuracy: 0.5439\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2933 - accuracy: 0.5471 - val_loss: 1.1482 - val_accuracy: 0.5961\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2049 - accuracy: 0.5828 - val_loss: 1.1352 - val_accuracy: 0.6009\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1453 - accuracy: 0.6016 - val_loss: 1.0565 - val_accuracy: 0.6380\n","Test loss: 1.056485891342163\n","Test accuracy: 0.6380000114440918\n"," 26% 9/34 [01:34\u003c05:18, 12.74s/it]Epoch 1/4\n","391/391 [==============================] - 6s 15ms/step - loss: 1.5252 - accuracy: 0.4597 - val_loss: 1.1849 - val_accuracy: 0.5918\n","Epoch 2/4\n","391/391 [==============================] - 5s 14ms/step - loss: 1.2193 - accuracy: 0.5734 - val_loss: 1.1388 - val_accuracy: 0.6078\n","Epoch 3/4\n","391/391 [==============================] - 5s 14ms/step - loss: 1.1179 - accuracy: 0.6116 - val_loss: 1.0692 - val_accuracy: 0.6329\n","Epoch 4/4\n","391/391 [==============================] - 6s 15ms/step - loss: 1.0582 - accuracy: 0.6343 - val_loss: 1.0302 - val_accuracy: 0.6448\n","Test loss: 1.030248761177063\n","Test accuracy: 0.6448000073432922\n"," 29% 10/34 [02:00\u003c06:30, 16.25s/it]Epoch 1/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.7121 - accuracy: 0.3765 - val_loss: 1.4231 - val_accuracy: 0.4860\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.4036 - accuracy: 0.5019 - val_loss: 1.2149 - val_accuracy: 0.5773\n","Epoch 3/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.2968 - accuracy: 0.5464 - val_loss: 1.1703 - val_accuracy: 0.5946\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2353 - accuracy: 0.5734 - val_loss: 1.2182 - val_accuracy: 0.5793\n","Test loss: 1.2181755304336548\n","Test accuracy: 0.5792999863624573\n"," 32% 11/34 [02:24\u003c07:05, 18.49s/it]Epoch 1/4\n","391/391 [==============================] - 4s 10ms/step - loss: 2.1868 - accuracy: 0.1936 - val_loss: 2.0419 - val_accuracy: 0.2797\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 2.0274 - accuracy: 0.2666 - val_loss: 1.9052 - val_accuracy: 0.3482\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.9299 - accuracy: 0.3043 - val_loss: 1.8099 - val_accuracy: 0.3806\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.8614 - accuracy: 0.3242 - val_loss: 1.7178 - val_accuracy: 0.4088\n","Test loss: 1.7177672386169434\n","Test accuracy: 0.40880000591278076\n"," 35% 12/34 [02:47\u003c07:17, 19.89s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.6748 - accuracy: 0.4040 - val_loss: 1.3360 - val_accuracy: 0.5359\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.3774 - accuracy: 0.5166 - val_loss: 1.1736 - val_accuracy: 0.5977\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.2704 - accuracy: 0.5599 - val_loss: 1.0930 - val_accuracy: 0.6238\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.2139 - accuracy: 0.5792 - val_loss: 1.1111 - val_accuracy: 0.6114\n","Test loss: 1.1110831499099731\n","Test accuracy: 0.6114000082015991\n"," 38% 13/34 [03:07\u003c07:00, 20.02s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.6245 - accuracy: 0.4186 - val_loss: 1.2778 - val_accuracy: 0.5560\n","Epoch 2/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.3181 - accuracy: 0.5382 - val_loss: 1.1364 - val_accuracy: 0.6105\n","Epoch 3/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.2174 - accuracy: 0.5752 - val_loss: 1.0667 - val_accuracy: 0.6340\n","Epoch 4/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.1635 - accuracy: 0.5972 - val_loss: 1.0634 - val_accuracy: 0.6284\n","Test loss: 1.0634137392044067\n","Test accuracy: 0.6284000277519226\n"," 41% 14/34 [03:24\u003c06:22, 19.12s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.5732 - accuracy: 0.4399 - val_loss: 1.2605 - val_accuracy: 0.5504\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2620 - accuracy: 0.5588 - val_loss: 1.1346 - val_accuracy: 0.6034\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1696 - accuracy: 0.5926 - val_loss: 1.0428 - val_accuracy: 0.6375\n","Epoch 4/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.1210 - accuracy: 0.6095 - val_loss: 1.0282 - val_accuracy: 0.6420\n","Test loss: 1.0281686782836914\n","Test accuracy: 0.6420000195503235\n"," 44% 15/34 [03:48\u003c06:26, 20.35s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.8718 - accuracy: 0.3051 - val_loss: 1.4978 - val_accuracy: 0.4865\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.5664 - accuracy: 0.4236 - val_loss: 1.2881 - val_accuracy: 0.5629\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.4329 - accuracy: 0.4735 - val_loss: 1.1354 - val_accuracy: 0.6014\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.3538 - accuracy: 0.5055 - val_loss: 1.0951 - val_accuracy: 0.6198\n","Test loss: 1.0951318740844727\n","Test accuracy: 0.6197999715805054\n"," 47% 16/34 [04:07\u003c06:02, 20.11s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.6246 - accuracy: 0.4279 - val_loss: 1.2989 - val_accuracy: 0.5447\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3035 - accuracy: 0.5473 - val_loss: 1.2574 - val_accuracy: 0.5496\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2163 - accuracy: 0.5806 - val_loss: 1.0742 - val_accuracy: 0.6313\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1722 - accuracy: 0.5988 - val_loss: 1.0668 - val_accuracy: 0.6353\n","Test loss: 1.0667998790740967\n","Test accuracy: 0.6352999806404114\n"," 50% 17/34 [04:22\u003c05:15, 18.57s/it]Epoch 1/4\n","391/391 [==============================] - 6s 12ms/step - loss: 1.8228 - accuracy: 0.3344 - val_loss: 1.4432 - val_accuracy: 0.4777\n","Epoch 2/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.5222 - accuracy: 0.4551 - val_loss: 1.2656 - val_accuracy: 0.5501\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.4050 - accuracy: 0.5051 - val_loss: 1.3425 - val_accuracy: 0.5152\n","Epoch 4/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.3416 - accuracy: 0.5331 - val_loss: 1.1943 - val_accuracy: 0.5786\n","Test loss: 1.1943471431732178\n","Test accuracy: 0.5785999894142151\n"," 53% 18/34 [04:46\u003c05:21, 20.11s/it]Epoch 1/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.8841 - accuracy: 0.2987 - val_loss: 1.5335 - val_accuracy: 0.4778\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.6252 - accuracy: 0.3945 - val_loss: 1.3698 - val_accuracy: 0.5386\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.5214 - accuracy: 0.4356 - val_loss: 1.2911 - val_accuracy: 0.5544\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4575 - accuracy: 0.4582 - val_loss: 1.2369 - val_accuracy: 0.5684\n","Test loss: 1.2368788719177246\n","Test accuracy: 0.5684000253677368\n"," 56% 19/34 [05:09\u003c05:15, 21.06s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.8308 - accuracy: 0.3391 - val_loss: 1.4852 - val_accuracy: 0.4750\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.5284 - accuracy: 0.4560 - val_loss: 1.3166 - val_accuracy: 0.5604\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.4349 - accuracy: 0.4932 - val_loss: 1.2014 - val_accuracy: 0.6052\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.3825 - accuracy: 0.5140 - val_loss: 1.1737 - val_accuracy: 0.6040\n","Test loss: 1.173732042312622\n","Test accuracy: 0.6039999723434448\n"," 59% 20/34 [05:29\u003c04:48, 20.64s/it]Epoch 1/4\n","391/391 [==============================] - 7s 15ms/step - loss: 1.6951 - accuracy: 0.3965 - val_loss: 1.4493 - val_accuracy: 0.4693\n","Epoch 2/4\n","391/391 [==============================] - 6s 15ms/step - loss: 1.3835 - accuracy: 0.5145 - val_loss: 1.1446 - val_accuracy: 0.6102\n","Epoch 3/4\n","391/391 [==============================] - 6s 16ms/step - loss: 1.2745 - accuracy: 0.5578 - val_loss: 1.1667 - val_accuracy: 0.5944\n","Epoch 4/4\n","391/391 [==============================] - 6s 15ms/step - loss: 1.2183 - accuracy: 0.5782 - val_loss: 1.0778 - val_accuracy: 0.6328\n","Test loss: 1.0778290033340454\n","Test accuracy: 0.6327999830245972\n"," 62% 21/34 [05:56\u003c04:53, 22.58s/it]Epoch 1/4\n","391/391 [==============================] - 6s 15ms/step - loss: 1.5931 - accuracy: 0.4333 - val_loss: 1.2263 - val_accuracy: 0.5720\n","Epoch 2/4\n","391/391 [==============================] - 5s 14ms/step - loss: 1.2716 - accuracy: 0.5594 - val_loss: 1.0925 - val_accuracy: 0.6258\n","Epoch 3/4\n","391/391 [==============================] - 5s 14ms/step - loss: 1.1653 - accuracy: 0.5975 - val_loss: 1.0241 - val_accuracy: 0.6491\n","Epoch 4/4\n","391/391 [==============================] - 5s 14ms/step - loss: 1.1070 - accuracy: 0.6203 - val_loss: 1.0274 - val_accuracy: 0.6457\n","Test loss: 1.0274231433868408\n","Test accuracy: 0.6456999778747559\n"," 65% 22/34 [06:21\u003c04:39, 23.25s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.5954 - accuracy: 0.4315 - val_loss: 1.3772 - val_accuracy: 0.5028\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2659 - accuracy: 0.5605 - val_loss: 1.1132 - val_accuracy: 0.6128\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1806 - accuracy: 0.5910 - val_loss: 1.1480 - val_accuracy: 0.5961\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1279 - accuracy: 0.6101 - val_loss: 1.0380 - val_accuracy: 0.6382\n","Test loss: 1.0380092859268188\n","Test accuracy: 0.6381999850273132\n"," 68% 23/34 [06:40\u003c04:02, 22.04s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.8335 - accuracy: 0.3356 - val_loss: 1.5268 - val_accuracy: 0.4651\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.5613 - accuracy: 0.4423 - val_loss: 1.3518 - val_accuracy: 0.5270\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4464 - accuracy: 0.4885 - val_loss: 1.2731 - val_accuracy: 0.5518\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3729 - accuracy: 0.5168 - val_loss: 1.1891 - val_accuracy: 0.5883\n","Test loss: 1.1891214847564697\n","Test accuracy: 0.5882999897003174\n"," 71% 24/34 [06:57\u003c03:25, 20.51s/it]Epoch 1/4\n","391/391 [==============================] - 5s 10ms/step - loss: 1.7148 - accuracy: 0.3757 - val_loss: 1.3882 - val_accuracy: 0.5118\n","Epoch 2/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.4368 - accuracy: 0.4932 - val_loss: 1.2605 - val_accuracy: 0.5679\n","Epoch 3/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.3409 - accuracy: 0.5327 - val_loss: 1.1950 - val_accuracy: 0.5930\n","Epoch 4/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.2913 - accuracy: 0.5517 - val_loss: 1.2146 - val_accuracy: 0.5703\n","Test loss: 1.214632511138916\n","Test accuracy: 0.5702999830245972\n"," 74% 25/34 [07:20\u003c03:12, 21.40s/it]Epoch 1/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.7093 - accuracy: 0.3879 - val_loss: 1.3930 - val_accuracy: 0.5049\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4113 - accuracy: 0.5024 - val_loss: 1.2346 - val_accuracy: 0.5652\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3238 - accuracy: 0.5366 - val_loss: 1.1911 - val_accuracy: 0.5797\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2711 - accuracy: 0.5558 - val_loss: 1.1452 - val_accuracy: 0.6018\n","Test loss: 1.145164132118225\n","Test accuracy: 0.6018000245094299\n"," 76% 26/34 [07:44\u003c02:56, 22.07s/it]Epoch 1/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.7784 - accuracy: 0.3569 - val_loss: 1.4521 - val_accuracy: 0.4729\n","Epoch 2/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.4842 - accuracy: 0.4727 - val_loss: 1.3474 - val_accuracy: 0.5144\n","Epoch 3/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.3964 - accuracy: 0.5104 - val_loss: 1.3486 - val_accuracy: 0.5192\n","Epoch 4/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.3397 - accuracy: 0.5330 - val_loss: 1.2238 - val_accuracy: 0.5722\n","Test loss: 1.22380530834198\n","Test accuracy: 0.5722000002861023\n"," 79% 27/34 [07:57\u003c02:15, 19.40s/it]Epoch 1/4\n","391/391 [==============================] - 6s 14ms/step - loss: 1.6571 - accuracy: 0.4106 - val_loss: 1.2920 - val_accuracy: 0.5589\n","Epoch 2/4\n","391/391 [==============================] - 6s 14ms/step - loss: 1.3534 - accuracy: 0.5262 - val_loss: 1.1141 - val_accuracy: 0.6221\n","Epoch 3/4\n","391/391 [==============================] - 6s 14ms/step - loss: 1.2706 - accuracy: 0.5604 - val_loss: 1.0937 - val_accuracy: 0.6248\n","Epoch 4/4\n","391/391 [==============================] - 5s 14ms/step - loss: 1.2163 - accuracy: 0.5784 - val_loss: 1.0869 - val_accuracy: 0.6213\n","Test loss: 1.0869094133377075\n","Test accuracy: 0.6212999820709229\n"," 82% 28/34 [08:41\u003c02:40, 26.82s/it]Epoch 1/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.6637 - accuracy: 0.3952 - val_loss: 1.3090 - val_accuracy: 0.5363\n","Epoch 2/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.3591 - accuracy: 0.5147 - val_loss: 1.2093 - val_accuracy: 0.5743\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.2676 - accuracy: 0.5520 - val_loss: 1.1027 - val_accuracy: 0.6177\n","Epoch 4/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.1872 - accuracy: 0.5837 - val_loss: 1.0591 - val_accuracy: 0.6260\n","Test loss: 1.0591272115707397\n","Test accuracy: 0.6259999871253967\n"," 85% 29/34 [09:03\u003c02:06, 25.22s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.6720 - accuracy: 0.4061 - val_loss: 1.3466 - val_accuracy: 0.5402\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.3641 - accuracy: 0.5222 - val_loss: 1.1723 - val_accuracy: 0.5935\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2696 - accuracy: 0.5583 - val_loss: 1.1013 - val_accuracy: 0.6170\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2136 - accuracy: 0.5802 - val_loss: 1.0780 - val_accuracy: 0.6322\n","Test loss: 1.0779964923858643\n","Test accuracy: 0.6322000026702881\n"," 88% 30/34 [09:26\u003c01:38, 24.63s/it]Epoch 1/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.5888 - accuracy: 0.4386 - val_loss: 1.2386 - val_accuracy: 0.5709\n","Epoch 2/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.2743 - accuracy: 0.5580 - val_loss: 1.1500 - val_accuracy: 0.6016\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1879 - accuracy: 0.5910 - val_loss: 1.0881 - val_accuracy: 0.6275\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1390 - accuracy: 0.6100 - val_loss: 1.0401 - val_accuracy: 0.6459\n","Test loss: 1.0401209592819214\n","Test accuracy: 0.6459000110626221\n"," 91% 31/34 [09:44\u003c01:07, 22.59s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 2.1727 - accuracy: 0.2032 - val_loss: 1.9905 - val_accuracy: 0.3179\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.9803 - accuracy: 0.2868 - val_loss: 1.8356 - val_accuracy: 0.3771\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.8629 - accuracy: 0.3333 - val_loss: 1.7166 - val_accuracy: 0.4172\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.7906 - accuracy: 0.3587 - val_loss: 1.6409 - val_accuracy: 0.4360\n","Test loss: 1.6408644914627075\n","Test accuracy: 0.4359999895095825\n"," 94% 32/34 [10:08\u003c00:46, 23.06s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.5932 - accuracy: 0.4330 - val_loss: 1.2872 - val_accuracy: 0.5557\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.2560 - accuracy: 0.5639 - val_loss: 1.1125 - val_accuracy: 0.6239\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1642 - accuracy: 0.5962 - val_loss: 1.0930 - val_accuracy: 0.6177\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1138 - accuracy: 0.6140 - val_loss: 1.0372 - val_accuracy: 0.6418\n","Test loss: 1.0372041463851929\n","Test accuracy: 0.6417999863624573\n"," 97% 33/34 [10:32\u003c00:23, 23.24s/it]Epoch 1/4\n","391/391 [==============================] - 6s 12ms/step - loss: 1.5651 - accuracy: 0.4436 - val_loss: 1.2796 - val_accuracy: 0.5433\n","Epoch 2/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.2461 - accuracy: 0.5648 - val_loss: 1.1181 - val_accuracy: 0.6081\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1440 - accuracy: 0.6027 - val_loss: 1.1005 - val_accuracy: 0.6159\n","Epoch 4/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.0823 - accuracy: 0.6246 - val_loss: 1.0216 - val_accuracy: 0.6420\n","Test loss: 1.0215938091278076\n","Test accuracy: 0.6420000195503235\n","100% 34/34 [10:55\u003c00:00, 19.29s/it]\n","  0% 0/34 [00:00\u003c?, ?it/s]Epoch 1/4\n","391/391 [==============================] - 6s 13ms/step - loss: 1.7895 - accuracy: 0.3565 - val_loss: 1.4438 - val_accuracy: 0.5075\n","Epoch 2/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.4784 - accuracy: 0.4789 - val_loss: 1.2199 - val_accuracy: 0.5878\n","Epoch 3/4\n","391/391 [==============================] - 5s 13ms/step - loss: 1.3476 - accuracy: 0.5276 - val_loss: 1.2404 - val_accuracy: 0.5728\n","Epoch 4/4\n","391/391 [==============================] - 5s 13ms/step - loss: 1.2874 - accuracy: 0.5508 - val_loss: 1.0993 - val_accuracy: 0.6161\n","Test loss: 1.0993201732635498\n","Test accuracy: 0.616100013256073\n"," 18% 6/34 [00:23\u003c01:47,  3.84s/it]Epoch 1/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.7713 - accuracy: 0.3638 - val_loss: 1.4325 - val_accuracy: 0.5102\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4792 - accuracy: 0.4805 - val_loss: 1.2615 - val_accuracy: 0.5643\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3684 - accuracy: 0.5207 - val_loss: 1.2078 - val_accuracy: 0.5794\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3189 - accuracy: 0.5412 - val_loss: 1.2212 - val_accuracy: 0.5713\n","Test loss: 1.2212308645248413\n","Test accuracy: 0.5713000297546387\n"," 21% 7/34 [00:46\u003c03:23,  7.54s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.7667 - accuracy: 0.3662 - val_loss: 1.4218 - val_accuracy: 0.4935\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4757 - accuracy: 0.4798 - val_loss: 1.2898 - val_accuracy: 0.5392\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3505 - accuracy: 0.5280 - val_loss: 1.2453 - val_accuracy: 0.5564\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3009 - accuracy: 0.5466 - val_loss: 1.1578 - val_accuracy: 0.5936\n","Test loss: 1.1577653884887695\n","Test accuracy: 0.5935999751091003\n"," 24% 8/34 [01:01\u003c03:58,  9.18s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.6562 - accuracy: 0.4072 - val_loss: 1.3338 - val_accuracy: 0.5265\n","Epoch 2/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.3346 - accuracy: 0.5309 - val_loss: 1.1404 - val_accuracy: 0.6078\n","Epoch 3/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.2217 - accuracy: 0.5754 - val_loss: 1.0979 - val_accuracy: 0.6162\n","Epoch 4/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.1654 - accuracy: 0.5969 - val_loss: 1.0821 - val_accuracy: 0.6250\n","Test loss: 1.082137107849121\n","Test accuracy: 0.625\n"," 26% 9/34 [01:24\u003c05:12, 12.50s/it]Epoch 1/4\n","391/391 [==============================] - 5s 10ms/step - loss: 1.6120 - accuracy: 0.4280 - val_loss: 1.2823 - val_accuracy: 0.5549\n","Epoch 2/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.2725 - accuracy: 0.5539 - val_loss: 1.1333 - val_accuracy: 0.6055\n","Epoch 3/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.1727 - accuracy: 0.5946 - val_loss: 1.0766 - val_accuracy: 0.6299\n","Epoch 4/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.1095 - accuracy: 0.6172 - val_loss: 1.0292 - val_accuracy: 0.6456\n","Test loss: 1.029179573059082\n","Test accuracy: 0.6456000208854675\n"," 29% 10/34 [01:42\u003c05:34, 13.92s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.5858 - accuracy: 0.4351 - val_loss: 1.4204 - val_accuracy: 0.4915\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3021 - accuracy: 0.5434 - val_loss: 1.1674 - val_accuracy: 0.5869\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2139 - accuracy: 0.5769 - val_loss: 1.1037 - val_accuracy: 0.6124\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.1687 - accuracy: 0.5926 - val_loss: 1.1541 - val_accuracy: 0.5918\n","Test loss: 1.1541354656219482\n","Test accuracy: 0.5917999744415283\n"," 32% 11/34 [02:06\u003c06:21, 16.57s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.5342 - accuracy: 0.4568 - val_loss: 1.3860 - val_accuracy: 0.5086\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.2234 - accuracy: 0.5728 - val_loss: 1.1389 - val_accuracy: 0.6054\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1261 - accuracy: 0.6107 - val_loss: 1.0403 - val_accuracy: 0.6426\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.0709 - accuracy: 0.6287 - val_loss: 1.0189 - val_accuracy: 0.6462\n","Test loss: 1.018876075744629\n","Test accuracy: 0.6462000012397766\n"," 35% 12/34 [02:26\u003c06:26, 17.55s/it]Epoch 1/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.6972 - accuracy: 0.3899 - val_loss: 1.3696 - val_accuracy: 0.5130\n","Epoch 2/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.3767 - accuracy: 0.5128 - val_loss: 1.2346 - val_accuracy: 0.5623\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.2583 - accuracy: 0.5597 - val_loss: 1.0954 - val_accuracy: 0.6212\n","Epoch 4/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.1994 - accuracy: 0.5826 - val_loss: 1.0879 - val_accuracy: 0.6255\n","Test loss: 1.0878641605377197\n","Test accuracy: 0.6255000233650208\n"," 38% 13/34 [02:50\u003c06:45, 19.30s/it]Epoch 1/4\n","391/391 [==============================] - 6s 12ms/step - loss: 1.6598 - accuracy: 0.4102 - val_loss: 1.3055 - val_accuracy: 0.5438\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.3508 - accuracy: 0.5267 - val_loss: 1.1647 - val_accuracy: 0.5904\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2629 - accuracy: 0.5615 - val_loss: 1.1081 - val_accuracy: 0.6181\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1995 - accuracy: 0.5877 - val_loss: 1.1163 - val_accuracy: 0.6167\n","Test loss: 1.116339921951294\n","Test accuracy: 0.6166999936103821\n"," 41% 14/34 [03:14\u003c06:50, 20.54s/it]Epoch 1/4\n","391/391 [==============================] - 6s 14ms/step - loss: 1.5648 - accuracy: 0.4459 - val_loss: 1.2556 - val_accuracy: 0.5561\n","Epoch 2/4\n","391/391 [==============================] - 6s 14ms/step - loss: 1.2564 - accuracy: 0.5605 - val_loss: 1.1272 - val_accuracy: 0.6110\n","Epoch 3/4\n","391/391 [==============================] - 6s 14ms/step - loss: 1.1653 - accuracy: 0.5946 - val_loss: 1.1160 - val_accuracy: 0.6136\n","Epoch 4/4\n","391/391 [==============================] - 5s 14ms/step - loss: 1.1179 - accuracy: 0.6138 - val_loss: 0.9978 - val_accuracy: 0.6552\n","Test loss: 0.9977515339851379\n","Test accuracy: 0.6552000045776367\n"," 44% 15/34 [03:39\u003c06:54, 21.83s/it]Epoch 1/4\n","391/391 [==============================] - 6s 13ms/step - loss: 1.7134 - accuracy: 0.3761 - val_loss: 1.3239 - val_accuracy: 0.5198\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.3936 - accuracy: 0.5072 - val_loss: 1.1877 - val_accuracy: 0.5806\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.2997 - accuracy: 0.5477 - val_loss: 1.1089 - val_accuracy: 0.6124\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.2329 - accuracy: 0.5739 - val_loss: 1.1447 - val_accuracy: 0.6030\n","Test loss: 1.1447460651397705\n","Test accuracy: 0.6029999852180481\n"," 47% 16/34 [04:03\u003c06:43, 22.44s/it]Epoch 1/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.7086 - accuracy: 0.4000 - val_loss: 1.4276 - val_accuracy: 0.5066\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.4484 - accuracy: 0.4918 - val_loss: 1.3194 - val_accuracy: 0.5354\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3503 - accuracy: 0.5293 - val_loss: 1.2371 - val_accuracy: 0.5688\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2834 - accuracy: 0.5549 - val_loss: 1.2214 - val_accuracy: 0.5735\n","Test loss: 1.221375823020935\n","Test accuracy: 0.5734999775886536\n"," 50% 17/34 [04:17\u003c05:40, 20.02s/it]Epoch 1/4\n","391/391 [==============================] - 5s 10ms/step - loss: 2.3228 - accuracy: 0.1014 - val_loss: 2.3027 - val_accuracy: 0.1000\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 2.3032 - accuracy: 0.0995 - val_loss: 2.3026 - val_accuracy: 0.1000\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 2.3036 - accuracy: 0.0998 - val_loss: 2.3049 - val_accuracy: 0.1000\n","Test loss: 2.304912567138672\n","Test accuracy: 0.10000000149011612\n"," 53% 18/34 [04:40\u003c05:35, 20.97s/it]Epoch 1/4\n","391/391 [==============================] - 5s 10ms/step - loss: 1.5800 - accuracy: 0.4390 - val_loss: 1.2545 - val_accuracy: 0.5711\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2770 - accuracy: 0.5540 - val_loss: 1.1321 - val_accuracy: 0.6098\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1883 - accuracy: 0.5871 - val_loss: 1.0689 - val_accuracy: 0.6269\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1328 - accuracy: 0.6091 - val_loss: 1.0570 - val_accuracy: 0.6345\n","Test loss: 1.0570366382598877\n","Test accuracy: 0.6345000267028809\n"," 56% 19/34 [04:59\u003c05:06, 20.43s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.5853 - accuracy: 0.4367 - val_loss: 1.2653 - val_accuracy: 0.5617\n","Epoch 2/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.2867 - accuracy: 0.5548 - val_loss: 1.1595 - val_accuracy: 0.6045\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1918 - accuracy: 0.5900 - val_loss: 1.1459 - val_accuracy: 0.6072\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.1430 - accuracy: 0.6085 - val_loss: 1.0619 - val_accuracy: 0.6345\n","Test loss: 1.0619333982467651\n","Test accuracy: 0.6345000267028809\n"," 59% 20/34 [05:22\u003c04:58, 21.29s/it]Epoch 1/4\n","391/391 [==============================] - 3s 7ms/step - loss: 2.1507 - accuracy: 0.2076 - val_loss: 1.9759 - val_accuracy: 0.3192\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.9330 - accuracy: 0.3064 - val_loss: 1.7970 - val_accuracy: 0.3821\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.7887 - accuracy: 0.3612 - val_loss: 1.6566 - val_accuracy: 0.4261\n","Epoch 4/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.7053 - accuracy: 0.3926 - val_loss: 1.6062 - val_accuracy: 0.4334\n","Test loss: 1.6062244176864624\n","Test accuracy: 0.4334000051021576\n"," 62% 21/34 [05:46\u003c04:46, 22.00s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.7511 - accuracy: 0.3676 - val_loss: 1.4282 - val_accuracy: 0.5031\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4652 - accuracy: 0.4816 - val_loss: 1.2261 - val_accuracy: 0.5800\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3619 - accuracy: 0.5216 - val_loss: 1.1604 - val_accuracy: 0.6009\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3192 - accuracy: 0.5383 - val_loss: 1.1167 - val_accuracy: 0.6168\n","Test loss: 1.1166938543319702\n","Test accuracy: 0.6168000102043152\n"," 65% 22/34 [06:10\u003c04:30, 22.54s/it]Epoch 1/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.6946 - accuracy: 0.3935 - val_loss: 1.3611 - val_accuracy: 0.5286\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3969 - accuracy: 0.5081 - val_loss: 1.2845 - val_accuracy: 0.5517\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3028 - accuracy: 0.5472 - val_loss: 1.1506 - val_accuracy: 0.6099\n","Epoch 4/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2408 - accuracy: 0.5731 - val_loss: 1.1240 - val_accuracy: 0.6218\n","Test loss: 1.1239935159683228\n","Test accuracy: 0.6218000054359436\n"," 68% 23/34 [06:34\u003c04:11, 22.91s/it]Epoch 1/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.6608 - accuracy: 0.4065 - val_loss: 1.2983 - val_accuracy: 0.5535\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.3538 - accuracy: 0.5262 - val_loss: 1.1415 - val_accuracy: 0.6108\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2632 - accuracy: 0.5614 - val_loss: 1.1404 - val_accuracy: 0.6094\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2137 - accuracy: 0.5803 - val_loss: 1.0501 - val_accuracy: 0.6376\n","Test loss: 1.0501102209091187\n","Test accuracy: 0.6376000046730042\n"," 71% 24/34 [06:57\u003c03:51, 23.12s/it]Epoch 1/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.7444 - accuracy: 0.3756 - val_loss: 1.4306 - val_accuracy: 0.5005\n","Epoch 2/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.4302 - accuracy: 0.4983 - val_loss: 1.1993 - val_accuracy: 0.5905\n","Epoch 3/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3185 - accuracy: 0.5401 - val_loss: 1.1284 - val_accuracy: 0.6183\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2643 - accuracy: 0.5604 - val_loss: 1.0720 - val_accuracy: 0.6336\n","Test loss: 1.0720114707946777\n","Test accuracy: 0.6335999965667725\n"," 74% 25/34 [07:21\u003c03:28, 23.19s/it]Epoch 1/4\n","391/391 [==============================] - 4s 8ms/step - loss: 1.6740 - accuracy: 0.3995 - val_loss: 1.3819 - val_accuracy: 0.5093\n","Epoch 2/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.3749 - accuracy: 0.5186 - val_loss: 1.2054 - val_accuracy: 0.5803\n","Epoch 3/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.2634 - accuracy: 0.5592 - val_loss: 1.1159 - val_accuracy: 0.6126\n","Epoch 4/4\n","391/391 [==============================] - 3s 8ms/step - loss: 1.2147 - accuracy: 0.5778 - val_loss: 1.0916 - val_accuracy: 0.6185\n","Test loss: 1.091564416885376\n","Test accuracy: 0.6184999942779541\n"," 76% 26/34 [07:44\u003c03:06, 23.36s/it]Epoch 1/4\n","391/391 [==============================] - 6s 13ms/step - loss: 1.6866 - accuracy: 0.4034 - val_loss: 1.3893 - val_accuracy: 0.5020\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.3589 - accuracy: 0.5253 - val_loss: 1.1889 - val_accuracy: 0.5788\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.2580 - accuracy: 0.5610 - val_loss: 1.0995 - val_accuracy: 0.6150\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1957 - accuracy: 0.5830 - val_loss: 1.1549 - val_accuracy: 0.5937\n","Test loss: 1.1548535823822021\n","Test accuracy: 0.5936999917030334\n"," 79% 27/34 [08:06\u003c02:40, 22.88s/it]Epoch 1/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.6792 - accuracy: 0.4002 - val_loss: 1.3417 - val_accuracy: 0.5270\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.3662 - accuracy: 0.5219 - val_loss: 1.1695 - val_accuracy: 0.6005\n","Epoch 3/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.2741 - accuracy: 0.5585 - val_loss: 1.0987 - val_accuracy: 0.6190\n","Epoch 4/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2194 - accuracy: 0.5786 - val_loss: 1.1007 - val_accuracy: 0.6222\n","Test loss: 1.100712537765503\n","Test accuracy: 0.6222000122070312\n"," 82% 28/34 [08:30\u003c02:19, 23.22s/it]Epoch 1/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.5850 - accuracy: 0.4390 - val_loss: 1.3127 - val_accuracy: 0.5391\n","Epoch 2/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.2755 - accuracy: 0.5565 - val_loss: 1.1900 - val_accuracy: 0.5835\n","Epoch 3/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.1894 - accuracy: 0.5918 - val_loss: 1.0755 - val_accuracy: 0.6299\n","Epoch 4/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.1338 - accuracy: 0.6103 - val_loss: 1.0581 - val_accuracy: 0.6402\n","Test loss: 1.0580699443817139\n","Test accuracy: 0.6402000188827515\n"," 85% 29/34 [08:48\u003c01:47, 21.45s/it]Epoch 1/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.6639 - accuracy: 0.4092 - val_loss: 1.4128 - val_accuracy: 0.4953\n","Epoch 2/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.3642 - accuracy: 0.5229 - val_loss: 1.2126 - val_accuracy: 0.5767\n","Epoch 3/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.2677 - accuracy: 0.5576 - val_loss: 1.1825 - val_accuracy: 0.5810\n","Epoch 4/4\n","391/391 [==============================] - 2s 5ms/step - loss: 1.2146 - accuracy: 0.5783 - val_loss: 1.1051 - val_accuracy: 0.6162\n","Test loss: 1.1050913333892822\n","Test accuracy: 0.6161999702453613\n"," 88% 30/34 [09:00\u003c01:14, 18.66s/it]Epoch 1/4\n","391/391 [==============================] - 5s 11ms/step - loss: 1.6944 - accuracy: 0.3927 - val_loss: 1.3083 - val_accuracy: 0.5411\n","Epoch 2/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.3650 - accuracy: 0.5224 - val_loss: 1.2141 - val_accuracy: 0.5789\n","Epoch 3/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.2714 - accuracy: 0.5565 - val_loss: 1.1408 - val_accuracy: 0.6184\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.2137 - accuracy: 0.5799 - val_loss: 1.1157 - val_accuracy: 0.6126\n","Test loss: 1.1156738996505737\n","Test accuracy: 0.6126000285148621\n"," 91% 31/34 [09:20\u003c00:57, 19.22s/it]Epoch 1/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.6163 - accuracy: 0.4216 - val_loss: 1.2886 - val_accuracy: 0.5518\n","Epoch 2/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.2986 - accuracy: 0.5458 - val_loss: 1.2081 - val_accuracy: 0.5695\n","Epoch 3/4\n","391/391 [==============================] - 5s 12ms/step - loss: 1.1995 - accuracy: 0.5824 - val_loss: 1.0660 - val_accuracy: 0.6338\n","Epoch 4/4\n","391/391 [==============================] - 4s 11ms/step - loss: 1.1464 - accuracy: 0.5996 - val_loss: 1.0769 - val_accuracy: 0.6308\n","Test loss: 1.0768605470657349\n","Test accuracy: 0.6308000087738037\n"," 94% 32/34 [09:44\u003c00:40, 20.46s/it]Epoch 1/4\n","391/391 [==============================] - 3s 7ms/step - loss: 1.6358 - accuracy: 0.4164 - val_loss: 1.2992 - val_accuracy: 0.5501\n","Epoch 2/4\n","391/391 [==============================] - 2s 6ms/step - loss: 1.3261 - accuracy: 0.5359 - val_loss: 1.2062 - val_accuracy: 0.5736\n","Epoch 3/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.2282 - accuracy: 0.5726 - val_loss: 1.1787 - val_accuracy: 0.5771\n","Epoch 4/4\n","391/391 [==============================] - 3s 6ms/step - loss: 1.1832 - accuracy: 0.5877 - val_loss: 1.1141 - val_accuracy: 0.6058\n","Test loss: 1.1140891313552856\n","Test accuracy: 0.6057999730110168\n"," 97% 33/34 [10:07\u003c00:21, 21.30s/it]Epoch 1/4\n","391/391 [==============================] - 4s 10ms/step - loss: 1.8139 - accuracy: 0.3460 - val_loss: 1.4261 - val_accuracy: 0.4844\n","Epoch 2/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.5163 - accuracy: 0.4578 - val_loss: 1.2468 - val_accuracy: 0.5753\n","Epoch 3/4\n","391/391 [==============================] - 4s 9ms/step - loss: 1.4182 - accuracy: 0.4982 - val_loss: 1.2116 - val_accuracy: 0.5884\n","Epoch 4/4\n","391/391 [==============================] - 3s 9ms/step - loss: 1.3717 - accuracy: 0.5174 - val_loss: 1.1399 - val_accuracy: 0.6148\n","Test loss: 1.1399040222167969\n","Test accuracy: 0.614799976348877\n","100% 34/34 [10:31\u003c00:00, 18.56s/it]\n"]}],"source":["!python DeepEvolve/main.py"]},{"cell_type":"markdown","metadata":{"id":"OeFaymLsHqZZ"},"source":["Y os recomiendo que le echéis un ojo a estos dos enlaces en los que evolucionan una red neuronal con un GA. Aquí no nos da tiempo, pero son muy interesantes:\n","\n","### Ejemplo GA para evolucionar NN: \n","\n","* https://blog.coast.ai/lets-evolve-a-neural-network-with-a-genetic-algorithm-code-included-8809bece164\n","* https://github.com/harvitronix/neural-network-genetic-algorithm"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}